{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c80e79f7",
   "metadata": {
    "_cell_guid": "9cf7fcc7-f8d3-4f9a-9128-f94e5a717ff3",
    "_uuid": "00713b04-49ef-4f25-9036-4177259b53e4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009301,
     "end_time": "2025-11-14T21:08:40.864319",
     "exception": false,
     "start_time": "2025-11-14T21:08:40.855018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FDS Challenge\n",
    "\n",
    "This notebook will guide you through the first steps of the competition. Our goal here is to show you how to:\n",
    "\n",
    "1.  Load the `train.jsonl` and `test.jsonl` files from the competition data.\n",
    "2.  Create a very simple set of features from the data.\n",
    "3.  Train a basic model.\n",
    "4.  Generate a `submission.csv` file in the correct format.\n",
    "5.  Submit your results.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031bca92",
   "metadata": {
    "_cell_guid": "b7c3e856-84d8-4080-97ee-7570902defbc",
    "_uuid": "30695d23-3c14-4ded-ac54-0da74eab1161",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.006895,
     "end_time": "2025-11-14T21:08:40.878484",
     "exception": false,
     "start_time": "2025-11-14T21:08:40.871589",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Loading and Inspecting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932decc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Define the path to our data ---\n",
    "COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "DATA_PATH = os.path.join('../input', COMPETITION_NAME)\n",
    "train_file_path = os.path.join(DATA_PATH, 'train.jsonl')\n",
    "test_file_path = os.path.join(DATA_PATH, 'test.jsonl')\n",
    "\n",
    "train_data = []\n",
    "test_data  = []\n",
    "\n",
    "# --- Load TRAIN data ---\n",
    "print(f\"üì¶ Loading data from '{train_file_path}'...\")\n",
    "try:\n",
    "    with open(train_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            train_data.append(json.loads(line))\n",
    "    print(f\"‚úÖ Successfully loaded {len(train_data)} battles from train.\")\n",
    "    \n",
    "    # Show structure of first train battle\n",
    "    if train_data:\n",
    "        print(\"\\n--- Structure of the first train battle: ---\")\n",
    "        first_battle = train_data[0]\n",
    "        battle_for_display = first_battle.copy()\n",
    "        battle_for_display['battle_timeline'] = first_battle.get('battle_timeline', [])[:2]\n",
    "        print(json.dumps(battle_for_display, indent=4))\n",
    "        if len(first_battle.get('battle_timeline', [])) > 3:\n",
    "            print(\"    ...\")\n",
    "            print(\"    (battle_timeline has been truncated for display)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")\n",
    "\n",
    "\n",
    "# --- Load TEST data ---\n",
    "print(f\"\\nüì¶ Loading data from '{test_file_path}'...\")\n",
    "try:\n",
    "    with open(test_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            test_data.append(json.loads(line))\n",
    "    print(f\"‚úÖ Successfully loaded {len(test_data)} battles from test.\")\n",
    "    \n",
    "    if test_data:\n",
    "        print(\"\\n--- Structure of the first test battle: ---\")\n",
    "        first_test_battle = test_data[0]\n",
    "        test_display = first_test_battle.copy()\n",
    "        test_display['battle_timeline'] = test_display.get('battle_timeline', [])[:2]\n",
    "        print(json.dumps(test_display, indent=4))\n",
    "        if len(first_test_battle.get('battle_timeline', [])) > 3:\n",
    "            print(\"    ...\")\n",
    "            print(\"    (battle_timeline has been truncated for display)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: Could not find the test file at '{test_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7399ce86",
   "metadata": {
    "_cell_guid": "0e496703-c5aa-4a03-8262-f8f9c1d2f386",
    "_uuid": "3a8ee9c9-3a1f-441a-9c71-6bd1445de82f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.006969,
     "end_time": "2025-11-14T21:08:50.794883",
     "exception": false,
     "start_time": "2025-11-14T21:08:50.787914",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8263be47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T21:08:50.818216Z",
     "iopub.status.busy": "2025-11-14T21:08:50.817761Z",
     "iopub.status.idle": "2025-11-14T21:09:53.898510Z",
     "shell.execute_reply": "2025-11-14T21:09:53.897579Z"
    },
    "papermill": {
     "duration": 63.097665,
     "end_time": "2025-11-14T21:09:53.900222",
     "exception": false,
     "start_time": "2025-11-14T21:08:50.802557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b7f9795d2d4f59a486ece2066be948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da1127082f8440db10e79ff716231f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training features preview:\n",
      "[FeatureEng] Added 10 engineered features. Bad values -> train: 0, test: 0\n",
      "\n",
      "Preview (raw):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_team_size</th>\n",
       "      <th>p2_team_size</th>\n",
       "      <th>p1_unique_types</th>\n",
       "      <th>p2_unique_types</th>\n",
       "      <th>p1_team_stat_sum</th>\n",
       "      <th>p2_team_stat_sum</th>\n",
       "      <th>p1_team_stat_avg</th>\n",
       "      <th>p2_team_stat_avg</th>\n",
       "      <th>diff_team_size</th>\n",
       "      <th>diff_unique_types</th>\n",
       "      <th>...</th>\n",
       "      <th>atk_def_ratio</th>\n",
       "      <th>spd_gap</th>\n",
       "      <th>hp_ratio</th>\n",
       "      <th>survival_score</th>\n",
       "      <th>momentum_index</th>\n",
       "      <th>power_acc_gap</th>\n",
       "      <th>offensive_balance</th>\n",
       "      <th>defensive_efficiency</th>\n",
       "      <th>status_influence</th>\n",
       "      <th>speed_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3190.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>88.611111</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.564148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>83.888889</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.866543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3155.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>87.638889</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.966488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>91.250000</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.889786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>89.444444</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.130913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1_team_size  p2_team_size  p1_unique_types  p2_unique_types  \\\n",
       "0             6             1                5                2   \n",
       "1             6             1                6                2   \n",
       "2             6             1                8                2   \n",
       "3             6             1                8                2   \n",
       "4             6             1                6                2   \n",
       "\n",
       "   p1_team_stat_sum  p2_team_stat_sum  p1_team_stat_avg  p2_team_stat_avg  \\\n",
       "0            3190.0             535.0         88.611111         89.166667   \n",
       "1            3020.0             540.0         83.888889         90.000000   \n",
       "2            3155.0             520.0         87.638889         86.666667   \n",
       "3            3285.0             520.0         91.250000         86.666667   \n",
       "4            3220.0             535.0         89.444444         89.166667   \n",
       "\n",
       "   diff_team_size  diff_unique_types  ...  atk_def_ratio  spd_gap  hp_ratio  \\\n",
       "0               5                  3  ...            0.0      0.0       0.0   \n",
       "1               5                  4  ...            0.0      0.0       0.0   \n",
       "2               5                  6  ...            0.0      0.0       0.0   \n",
       "3               5                  6  ...            0.0      0.0       0.0   \n",
       "4               5                  4  ...            0.0      0.0       0.0   \n",
       "\n",
       "   survival_score  momentum_index  power_acc_gap  offensive_balance  \\\n",
       "0             0.0             0.0     -14.564148                0.0   \n",
       "1             0.0             0.0      22.866543                0.0   \n",
       "2             0.0             0.0     -17.966488                0.0   \n",
       "3             0.0             0.0     -19.889786                0.0   \n",
       "4             0.0             0.0     -11.130913                0.0   \n",
       "\n",
       "   defensive_efficiency  status_influence  speed_ratio  \n",
       "0                   0.0               0.0          0.0  \n",
       "1                   0.0               0.0          0.0  \n",
       "2                   0.0               0.0          0.0  \n",
       "3                   0.0               0.0          0.0  \n",
       "4                   0.0               0.0          0.0  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scaling completed. Preview (scaled):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_team_size</th>\n",
       "      <th>p2_team_size</th>\n",
       "      <th>p1_unique_types</th>\n",
       "      <th>p2_unique_types</th>\n",
       "      <th>p1_team_stat_sum</th>\n",
       "      <th>p2_team_stat_sum</th>\n",
       "      <th>p1_team_stat_avg</th>\n",
       "      <th>p2_team_stat_avg</th>\n",
       "      <th>diff_team_size</th>\n",
       "      <th>diff_unique_types</th>\n",
       "      <th>...</th>\n",
       "      <th>atk_def_ratio</th>\n",
       "      <th>spd_gap</th>\n",
       "      <th>hp_ratio</th>\n",
       "      <th>survival_score</th>\n",
       "      <th>momentum_index</th>\n",
       "      <th>power_acc_gap</th>\n",
       "      <th>offensive_balance</th>\n",
       "      <th>defensive_efficiency</th>\n",
       "      <th>status_influence</th>\n",
       "      <th>speed_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.377566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.631579</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.631579</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.210526</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.210526</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.469716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.157895</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.521807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.284580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 243 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1_team_size  p2_team_size  p1_unique_types  p2_unique_types  \\\n",
       "0           0.0           0.0             -1.0              0.0   \n",
       "1           0.0           0.0             -0.5              0.0   \n",
       "2           0.0           0.0              0.5              0.0   \n",
       "3           0.0           0.0              0.5              0.0   \n",
       "4           0.0           0.0             -0.5              0.0   \n",
       "\n",
       "   p1_team_stat_sum  p2_team_stat_sum  p1_team_stat_avg  p2_team_stat_avg  \\\n",
       "0          0.157895             -0.25          0.157895             -0.25   \n",
       "1         -1.631579              0.00         -1.631579              0.00   \n",
       "2         -0.210526             -1.00         -0.210526             -1.00   \n",
       "3          1.157895             -1.00          1.157895             -1.00   \n",
       "4          0.473684             -0.25          0.473684             -0.25   \n",
       "\n",
       "   diff_team_size  diff_unique_types  ...  atk_def_ratio  spd_gap  hp_ratio  \\\n",
       "0             0.0               -1.0  ...            0.0      0.0       0.0   \n",
       "1             0.0               -0.5  ...            0.0      0.0       0.0   \n",
       "2             0.0                0.5  ...            0.0      0.0       0.0   \n",
       "3             0.0                0.5  ...            0.0      0.0       0.0   \n",
       "4             0.0               -0.5  ...            0.0      0.0       0.0   \n",
       "\n",
       "   survival_score  momentum_index  power_acc_gap  offensive_balance  \\\n",
       "0             0.0             0.0      -0.377566                0.0   \n",
       "1             0.0             0.0       0.636215                0.0   \n",
       "2             0.0             0.0      -0.469716                0.0   \n",
       "3             0.0             0.0      -0.521807                0.0   \n",
       "4             0.0             0.0      -0.284580                0.0   \n",
       "\n",
       "   defensive_efficiency  status_influence  speed_ratio  \n",
       "0                   0.0               0.0          0.0  \n",
       "1                   0.0               0.0          0.0  \n",
       "2                   0.0               0.0          0.0  \n",
       "3                   0.0               0.0          0.0  \n",
       "4                   0.0               0.0          0.0  \n",
       "\n",
       "[5 rows x 243 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================\n",
    "# CELLA 2 ‚Äî Feature Engineering \n",
    "# =========================\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Base stat keys used throughout the feature extraction\n",
    "# ---------------------------------------------\n",
    "BASE_STAT_KEYS = [\"base_hp\",\"base_atk\",\"base_def\",\"base_spa\",\"base_spd\",\"base_spe\"]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Static team composition and stats\n",
    "# ---------------------------------------------\n",
    "def unique_types(team: List[Dict[str, Any]]) -> int:\n",
    "    collected=[]\n",
    "    for p in team or []:\n",
    "        ts=p.get(\"types\") or []\n",
    "        if isinstance(ts,str): ts=[ts]\n",
    "        collected.extend([t for t in ts if t])\n",
    "    return len(set(collected))\n",
    "\n",
    "def sum_stats_of_team(team: List[Dict[str, Any]]) -> float:\n",
    "    total=0.0\n",
    "    for p in team or []:\n",
    "        for k in BASE_STAT_KEYS:\n",
    "            v=p.get(k)\n",
    "            if isinstance(v,(int,float)):\n",
    "                total+=float(v)\n",
    "    return total\n",
    "\n",
    "def avg_stats_of_team(team: List[Dict[str, Any]]) -> float:\n",
    "    if not team:\n",
    "        return 0.0\n",
    "    per=[]\n",
    "    for p in team:\n",
    "        vals=[p.get(k) for k in BASE_STAT_KEYS if isinstance(p.get(k),(int,float))]\n",
    "        if vals:\n",
    "            per.append(sum(vals)/len(vals))\n",
    "    return float(sum(per)/len(per)) if per else 0.0\n",
    "\n",
    "def sum_and_avg_of_single(poke: dict) -> Tuple[float, float]:\n",
    "    vals = [poke.get(k) for k in BASE_STAT_KEYS if isinstance(poke.get(k), (int, float))]\n",
    "    if not vals:\n",
    "        return 0.0, 0.0\n",
    "    total = float(sum(vals))\n",
    "    return total, total / len(vals)\n",
    "\n",
    "def team_stat_variance(team: List[Dict[str,Any]]) -> float:\n",
    "    if not team:\n",
    "        return 0.0\n",
    "    per=[]\n",
    "    for p in team:\n",
    "        vals=[p.get(k) for k in BASE_STAT_KEYS if isinstance(p.get(k),(int,float))]\n",
    "        if vals:\n",
    "            per.append(sum(vals)/len(vals))\n",
    "    if len(per)<2:\n",
    "        return 0.0\n",
    "    return float(pd.Series(per).var())\n",
    "\n",
    "def _team_speed_stats(team):\n",
    "    \"\"\"Return mean and max base speed over a team.\"\"\"\n",
    "    sp = [p.get(\"base_spe\", 0.0) for p in team or [] if isinstance(p.get(\"base_spe\", None), (int, float))]\n",
    "    if not sp:\n",
    "        return 0.0, 0.0\n",
    "    return float(np.mean(sp)), float(np.max(sp))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# General numeric helpers\n",
    "# ---------------------------------------------\n",
    "def _safe_mean(arr): \n",
    "    return float(np.mean(arr)) if arr else 0.0\n",
    "\n",
    "def _safe_ratio(a,b,cap=10.0):\n",
    "    r=a/(b+1e-6)\n",
    "    if r < 0: r = 0.0\n",
    "    if r > cap: r = cap\n",
    "    if not np.isfinite(r): r = 0.0\n",
    "    return float(r)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Timeline-based HP feature extraction\n",
    "# ---------------------------------------------\n",
    "def get_timeline(r: Dict[str,Any], max_turns: int = 30):\n",
    "    tl = r.get(\"battle_timeline\",[]) or []\n",
    "    return tl[:max_turns] if isinstance(tl,list) else []\n",
    "\n",
    "def _extract_hp_series(tl):\n",
    "    p1=[]; p2=[]\n",
    "    for t in tl:\n",
    "        if not isinstance(t,dict): \n",
    "            continue\n",
    "        s1=t.get(\"p1_pokemon_state\") or {}\n",
    "        s2=t.get(\"p2_pokemon_state\") or {}\n",
    "        v1=s1.get(\"hp_pct\"); v2=s2.get(\"hp_pct\")\n",
    "        if isinstance(v1,(int,float)) and isinstance(v2,(int,float)):\n",
    "            p1.append(float(v1)); p2.append(float(v2))\n",
    "    return p1,p2\n",
    "\n",
    "def _mean_last_std_min(arr):\n",
    "    if not arr:\n",
    "        return 0.0,0.0,0.0,0.0\n",
    "    x=np.array(arr,dtype=float)\n",
    "    return float(x.mean()), float(x[-1]), float(x.std(ddof=0)), float(x.min())\n",
    "\n",
    "def _window(arr,n): return arr[:n] if arr else []\n",
    "def _frac_positive(arr): return float((np.array(arr)>0).mean()) if arr else 0.0\n",
    "def _slope(arr):\n",
    "    if len(arr)<2: return 0.0\n",
    "    x=np.arange(len(arr))\n",
    "    m,_=np.polyfit(x,np.array(arr),1)\n",
    "    return float(m)\n",
    "def _auc_pct(arr): return float(np.sum(arr)/(100.0*len(arr))) if arr else 0.0\n",
    "def _status_count(tl,who):\n",
    "    cnt=0\n",
    "    k=f\"{who}_pokemon_state\"\n",
    "    for t in tl:\n",
    "        if not isinstance(t,dict): continue\n",
    "        st=(t.get(k) or {}).get(\"status\",None)\n",
    "        if st not in (None,\"\",\"none\",\"NONE\"):\n",
    "            cnt+=1\n",
    "    return float(cnt)\n",
    "def _ko_count(arr): return float(sum(1 for v in arr if v==0))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Move-related statistics from timeline\n",
    "# ---------------------------------------------\n",
    "def _move_stats_for_side(tl, who, window=None):\n",
    "    key=f\"{who}_move_details\"\n",
    "    seq = tl if window is None else tl[:window]\n",
    "    pw, ac, pr = [], [], []\n",
    "    for t in seq:\n",
    "        md=t.get(key) or {}\n",
    "        bp=md.get(\"base_power\"); acc=md.get(\"accuracy\"); pri=md.get(\"priority\")\n",
    "        if isinstance(bp,(int,float)): pw.append(float(bp))\n",
    "        if isinstance(acc,(int,float)): ac.append(float(acc))\n",
    "        if isinstance(pri,(int,float)): pr.append(float(pri))\n",
    "    suf=\"\" if window is None else f\"_{window}\"\n",
    "    return {\n",
    "        f\"mv_{who}_power_mean{suf}\": _safe_mean(pw),\n",
    "        f\"mv_{who}_acc_mean{suf}\":   _safe_mean(ac),\n",
    "        f\"mv_{who}_priority_mean{suf}\": _safe_mean(pr),\n",
    "    }\n",
    "# ---------------------------------------------\n",
    "# Type effectiveness helpers (uppercase canonical)\n",
    "# ---------------------------------------------\n",
    "_TYPE_CHART = {\n",
    "    \"NORMAL\":   {\"ROCK\":0.5, \"GHOST\":0.0, \"STEEL\":0.5},\n",
    "    \"FIRE\":     {\"FIRE\":0.5, \"WATER\":0.5, \"GRASS\":2.0, \"ICE\":2.0, \"BUG\":2.0, \"ROCK\":0.5, \"DRAGON\":0.5, \"STEEL\":2.0},\n",
    "    \"WATER\":    {\"FIRE\":2.0, \"WATER\":0.5, \"GRASS\":0.5, \"GROUND\":2.0, \"ROCK\":2.0, \"DRAGON\":0.5},\n",
    "    \"ELECTRIC\": {\"WATER\":2.0, \"ELECTRIC\":0.5, \"GRASS\":0.5, \"GROUND\":0.0, \"FLYING\":2.0, \"DRAGON\":0.5},\n",
    "    \"GRASS\":    {\"FIRE\":0.5, \"WATER\":2.0, \"GRASS\":0.5, \"POISON\":0.5, \"GROUND\":2.0, \"FLYING\":0.5, \"BUG\":0.5, \"ROCK\":2.0, \"DRAGON\":0.5, \"STEEL\":0.5},\n",
    "    \"ICE\":      {\"FIRE\":0.5, \"WATER\":0.5, \"GRASS\":2.0, \"GROUND\":2.0, \"FLYING\":2.0, \"DRAGON\":2.0, \"STEEL\":0.5},\n",
    "    \"FIGHTING\": {\"NORMAL\":2.0, \"ICE\":2.0, \"POISON\":0.5, \"FLYING\":0.5, \"PSYCHIC\":0.5, \"BUG\":0.5, \"ROCK\":2.0, \"GHOST\":0.0, \"DARK\":2.0, \"STEEL\":2.0, \"FAIRY\":0.5},\n",
    "    \"POISON\":   {\"GRASS\":2.0, \"POISON\":0.5, \"GROUND\":0.5, \"ROCK\":0.5, \"GHOST\":0.5, \"STEEL\":0.0, \"FAIRY\":2.0},\n",
    "    \"GROUND\":   {\"FIRE\":2.0, \"ELECTRIC\":2.0, \"GRASS\":0.5, \"POISON\":2.0, \"FLYING\":0.0, \"BUG\":0.5, \"ROCK\":2.0, \"STEEL\":2.0},\n",
    "    \"FLYING\":   {\"ELECTRIC\":0.5, \"GRASS\":2.0, \"FIGHTING\":2.0, \"BUG\":2.0, \"ROCK\":0.5, \"STEEL\":0.5},\n",
    "    \"PSYCHIC\":  {\"FIGHTING\":2.0, \"POISON\":2.0, \"PSYCHIC\":0.5, \"DARK\":0.0, \"STEEL\":0.5},\n",
    "    \"BUG\":      {\"FIRE\":0.5, \"GRASS\":2.0, \"FIGHTING\":0.5, \"POISON\":0.5, \"FLYING\":0.5, \"PSYCHIC\":2.0, \"GHOST\":0.5, \"DARK\":2.0, \"STEEL\":0.5, \"FAIRY\":0.5},\n",
    "    \"ROCK\":     {\"FIRE\":2.0, \"ICE\":2.0, \"FIGHTING\":0.5, \"GROUND\":0.5, \"FLYING\":2.0, \"BUG\":2.0, \"STEEL\":0.5},\n",
    "    \"GHOST\":    {\"NORMAL\":0.0, \"PSYCHIC\":2.0, \"GHOST\":2.0, \"DARK\":0.5},\n",
    "    \"DRAGON\":   {\"DRAGON\":2.0, \"STEEL\":0.5, \"FAIRY\":0.0},\n",
    "    \"DARK\":     {\"FIGHTING\":0.5, \"PSYCHIC\":2.0, \"GHOST\":2.0, \"DARK\":0.5, \"FAIRY\":0.5},\n",
    "    \"STEEL\":    {\"FIRE\":0.5, \"WATER\":0.5, \"ELECTRIC\":0.5, \"ICE\":2.0, \"ROCK\":2.0, \"FAIRY\":2.0, \"STEEL\":0.5},\n",
    "    \"FAIRY\":    {\"FIRE\":0.5, \"FIGHTING\":2.0, \"POISON\":0.5, \"DRAGON\":2.0, \"DARK\":2.0, \"STEEL\":0.5},\n",
    "}\n",
    "\n",
    "def _type_multiplier(move_type: str, target_types: List[str] | set) -> float:\n",
    "    \"\"\"Effectiveness multiplier for move_type against mono/dual target types.\"\"\"\n",
    "    if not move_type:\n",
    "        return 1.0\n",
    "    mt = move_type.strip().upper()\n",
    "    mult = 1.0\n",
    "    for tt in target_types or []:\n",
    "        tt_up = str(tt).strip().upper()\n",
    "        mult *= _TYPE_CHART.get(mt, {}).get(tt_up, 1.0)\n",
    "    return float(mult) if np.isfinite(mult) else 1.0\n",
    "\n",
    "def _avg_type_eff_p1_vs_p2lead(tl: list[dict], p2_lead_types: List[str] | set, window: int | None = None) -> float:\n",
    "    \"\"\"Mean effectiveness of P1 used moves vs P2 lead types over full/early window.\"\"\"\n",
    "    seq = tl if window is None else tl[:window]\n",
    "    vals = []\n",
    "    for t in seq:\n",
    "        md = t.get(\"p1_move_details\") or {}\n",
    "        mv_t = md.get(\"type\")\n",
    "        if isinstance(mv_t, str) and p2_lead_types:\n",
    "            vals.append(_type_multiplier(mv_t, p2_lead_types))\n",
    "    return float(np.mean(vals)) if vals else 1.0  # neutral if unknown\n",
    "\n",
    "# ---------------------------------------------\n",
    "# STAB features (Same-Type Attack Bonus)\n",
    "# ---------------------------------------------\n",
    "def _name_to_types_map_p1(record: Dict[str, Any]) -> Dict[str, set]:\n",
    "    mp = {}\n",
    "    for p in record.get(\"p1_team_details\", []) or []:\n",
    "        nm = (p.get(\"name\") or \"\").strip().lower()\n",
    "        ts = p.get(\"types\") or []\n",
    "        if isinstance(ts, str):\n",
    "            ts = [ts]\n",
    "        ts_norm = {str(t).strip().upper() for t in ts if t and str(t).strip().upper() != \"NOTYPE\"}\n",
    "        if nm:\n",
    "            mp[nm] = ts_norm\n",
    "    return mp\n",
    "\n",
    "def _active_name_and_move_type(turn: Dict[str, Any], who: str) -> tuple[str, str]:\n",
    "    state = turn.get(f\"{who}_pokemon_state\") or {}\n",
    "    md    = turn.get(f\"{who}_move_details\") or {}\n",
    "    nm = (state.get(\"name\") or \"\").strip().lower()\n",
    "    mv_t = (md.get(\"type\") or \"\").strip().upper()\n",
    "    return nm, mv_t\n",
    "\n",
    "def _stab_features(record: Dict[str, Any], max_turns: int = 30) -> Dict[str, float]:\n",
    "    tl = get_timeline(record, max_turns=max_turns)\n",
    "\n",
    "    # type maps of P1 (name -> set(types))\n",
    "    p1_types_map = _name_to_types_map_p1(record)\n",
    "\n",
    "    # ratio & diff - helpers\n",
    "    def _accumulate(seq):\n",
    "        p1_total = p1_stab = 0\n",
    "        p2_total = p2_stab = 0  \n",
    "\n",
    "        for t in seq:\n",
    "            # P1\n",
    "            nm1, mv1_type = _active_name_and_move_type(t, \"p1\")\n",
    "            if mv1_type:\n",
    "                p1_total += 1\n",
    "                types1 = p1_types_map.get(nm1, set())\n",
    "                is_stab = (mv1_type in types1) if types1 else False\n",
    "                if is_stab:\n",
    "                    p1_stab += 1\n",
    "\n",
    "        p1_ratio = (p1_stab / p1_total) if p1_total > 0 else 0.0\n",
    "        p2_ratio = 0.0\n",
    "\n",
    "        return {\n",
    "            \"stab_stab_ratio_diff\": float(p1_ratio - p2_ratio),\n",
    "            \"stab_stab_ratio_ratio\": _safe_ratio(p1_ratio, p2_ratio if p2_ratio > 0 else 1e-6, cap=10.0),\n",
    "        }\n",
    "\n",
    "    full = _accumulate(tl)\n",
    "    w5   = _accumulate(tl[:5])\n",
    "\n",
    "    return {\n",
    "        \"stab_stab_ratio_diff_full\":  float(full[\"stab_stab_ratio_diff\"]),\n",
    "        \"stab_stab_ratio_ratio_full\": float(full[\"stab_stab_ratio_ratio\"]),\n",
    "        \"stab_stab_ratio_diff_w5\":    float(w5[\"stab_stab_ratio_diff\"]),\n",
    "        \"stab_stab_ratio_ratio_w5\":   float(w5[\"stab_stab_ratio_ratio\"]),\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Early momentum (first 3 turns)\n",
    "# ---------------------------------------------\n",
    "def _first_ko_flag(hp_series: list[float]) -> int:\n",
    "    for v in hp_series:\n",
    "        if isinstance(v, (int, float)) and float(v) == 0.0:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def _first_status_advantage(tl: list[dict], first_n: int = 3) -> float:\n",
    "    p1 = p2 = 0\n",
    "    for t in tl[:first_n]:\n",
    "        s1 = (t.get(\"p1_pokemon_state\") or {}).get(\"status\", None)\n",
    "        s2 = (t.get(\"p2_pokemon_state\") or {}).get(\"status\", None)\n",
    "        if s1 not in (None, \"\", \"none\", \"NONE\"): p1 += 1\n",
    "        if s2 not in (None, \"\", \"none\", \"NONE\"): p2 += 1\n",
    "    return float(p1 - p2)\n",
    "\n",
    "def _early_momentum_features(record: Dict[str, Any], first_n: int = 3) -> Dict[str, float]:\n",
    "    tl = get_timeline(record, max_turns=30)\n",
    "    p1, p2 = _extract_hp_series(tl)\n",
    "    p1w, p2w = _window(p1, first_n), _window(p2, first_n)\n",
    "\n",
    "    diffw = [a - b for a, b in zip(p1w, p2w)] if p1w and p2w and len(p1w) == len(p2w) else []\n",
    "    mean_diff_first = float(np.mean(diffw)) if diffw else 0.0\n",
    "\n",
    "    p1_first_ko = _first_ko_flag(p2w)\n",
    "    p2_first_ko = _first_ko_flag(p1w)\n",
    "    first_ko_score = float(p1_first_ko - p2_first_ko)\n",
    "\n",
    "    status_adv = _first_status_advantage(tl, first_n=first_n)\n",
    "\n",
    "    return {\n",
    "        f\"early_hp_diff_mean_{first_n}\": mean_diff_first,\n",
    "        f\"early_first_ko_score_{first_n}\": first_ko_score,\n",
    "        f\"early_status_advantage_{first_n}\": status_adv,\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Priority counts and advantage (full / 5 / 10)\n",
    "# ---------------------------------------------\n",
    "def _priority_counts(record: Dict[str, Any], max_turns: int = 30, window: int | None = None) -> Dict[str, float]:\n",
    "    tl = get_timeline(record, max_turns=max_turns)\n",
    "    turns = tl if window is None else tl[:window]\n",
    "\n",
    "    p1_count = 0.0\n",
    "    p2_count = 0.0\n",
    "    for t in turns:\n",
    "        md1 = t.get(\"p1_move_details\") or {}\n",
    "        md2 = t.get(\"p2_move_details\") or {}\n",
    "        pri1 = md1.get(\"priority\")\n",
    "        pri2 = md2.get(\"priority\")\n",
    "        if isinstance(pri1, (int, float)) and float(pri1) > 0: p1_count += 1.0\n",
    "        if isinstance(pri2, (int, float)) and float(pri2) > 0: p2_count += 1.0\n",
    "\n",
    "    suf = \"\" if window is None else f\"_{window}\"\n",
    "    return {\n",
    "        f\"mv_p1_priority_count{suf}\": p1_count,\n",
    "        f\"mv_p2_priority_count{suf}\": p2_count,\n",
    "        f\"mv_priority_count_diff{suf}\": p1_count - p2_count,\n",
    "    }\n",
    "\n",
    "def _priority_feature_block(record: Dict[str, Any]) -> Dict[str, float]:\n",
    "    f = {}\n",
    "    f.update(_priority_counts(record, max_turns=30, window=None))\n",
    "    f.update(_priority_counts(record, max_turns=30, window=5))\n",
    "    return f\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Extra strong engineered features (top-5, safe, no NaN)\n",
    "# ---------------------------------------------\n",
    "def extra_strong_features(record, tl, p1, p2, t1, lead):\n",
    "    \"\"\"\n",
    "    Extra high-signal features built on top of existing blocks.\n",
    "    Assumes:\n",
    "      - tl  : battle_timeline (<=30 turns)\n",
    "      - p1  : HP series for player 1\n",
    "      - p2  : HP series for player 2\n",
    "      - t1  : p1_team_details (list of dict)\n",
    "      - lead: p2_lead_details (dict)\n",
    "    Returns: dict of 5 new numeric features (float).\n",
    "    \"\"\"\n",
    "    f = {}\n",
    "\n",
    "    # --- Helper: safe list ops ---\n",
    "    def _safe_mean(arr):\n",
    "        return float(np.mean(arr)) if arr else 0.0\n",
    "\n",
    "    # ---------------------------------\n",
    "    # 1) Lead type coverage score\n",
    "    #    \"How many team attacking types hit the lead super effectively?\"\n",
    "    # ---------------------------------\n",
    "    # Collect attacking types from P1 moves (first 10 turns) and team composition\n",
    "    atk_types = set()\n",
    "    for t in tl[:10]:\n",
    "        if not isinstance(t, dict):\n",
    "            continue\n",
    "        md = t.get(\"p1_move_details\") or {}\n",
    "        mt = md.get(\"type\")\n",
    "        if isinstance(mt, str) and mt.strip():\n",
    "            atk_types.add(mt.strip().upper())\n",
    "\n",
    "    for p in t1 or []:\n",
    "        ts = p.get(\"types\") or []\n",
    "        if isinstance(ts, str):\n",
    "            ts = [ts]\n",
    "        for tt in ts:\n",
    "            if tt:\n",
    "                atk_types.add(str(tt).strip().upper())\n",
    "\n",
    "    lead_types = lead.get(\"types\") or []\n",
    "    if isinstance(lead_types, str):\n",
    "        lead_types = [lead_types]\n",
    "    lead_types = [str(t).strip().upper() for t in lead_types if t]\n",
    "\n",
    "    super_eff = 0\n",
    "    for at in atk_types:\n",
    "        mult = _type_multiplier(at, lead_types)\n",
    "        if mult > 1.0:\n",
    "            super_eff += 1\n",
    "    f[\"lead_type_coverage_score\"] = float(super_eff)\n",
    "\n",
    "    # ---------------------------------\n",
    "    # 2) Lead bulk index gap\n",
    "    #    \"How much bulkier is P1 team compared to the opponent lead?\"\n",
    "    # ---------------------------------\n",
    "    p1_def_vals = []\n",
    "    p1_spd_vals = []\n",
    "    for p in t1 or []:\n",
    "        if isinstance(p, dict):\n",
    "            d = p.get(\"base_def\", 0)\n",
    "            s = p.get(\"base_spd\", 0)\n",
    "            if isinstance(d, (int, float)):\n",
    "                p1_def_vals.append(float(d))\n",
    "            if isinstance(s, (int, float)):\n",
    "                p1_spd_vals.append(float(s))\n",
    "    p1_bulk = _safe_mean(p1_def_vals) + _safe_mean(p1_spd_vals)\n",
    "\n",
    "    lead_def = float(lead.get(\"base_def\", 0.0) or 0.0)\n",
    "    lead_spd = float(lead.get(\"base_spd\", 0.0) or 0.0)\n",
    "    lead_bulk = lead_def + lead_spd\n",
    "\n",
    "    f[\"lead_bulk_index_gap\"] = float(p1_bulk - lead_bulk)\n",
    "\n",
    "    # ---------------------------------\n",
    "    # 3) Early HP domination ratio (first 5 turns)\n",
    "    #    \"How often is P1 ahead in HP in the early game?\"\n",
    "    # ---------------------------------\n",
    "    k = 5\n",
    "    p1_5 = p1[:k]\n",
    "    p2_5 = p2[:k]\n",
    "    if p1_5 and p2_5 and len(p1_5) == len(p2_5):\n",
    "        ahead = sum(1 for a, b in zip(p1_5, p2_5) if a > b)\n",
    "        f[\"early_hp_domination_ratio_5\"] = float(ahead) / max(1, len(p1_5))\n",
    "    else:\n",
    "        f[\"early_hp_domination_ratio_5\"] = 0.0\n",
    "\n",
    "    # ---------------------------------\n",
    "    # 4) HP swing between early and mid game (first 5 vs last 5 turns)\n",
    "    #    \"Did the HP advantage improve or deteriorate over time?\"\n",
    "    # ---------------------------------\n",
    "    if p1 and p2 and len(p1) == len(p2) and len(p1) >= 6:\n",
    "        diff = [float(a) - float(b) for a, b in zip(p1, p2)]\n",
    "        first_5 = diff[:5]\n",
    "        last_5  = diff[-5:]\n",
    "        swing = _safe_mean(last_5) - _safe_mean(first_5)\n",
    "        f[\"hp_swing_10\"] = float(swing)\n",
    "    else:\n",
    "        f[\"hp_swing_10\"] = 0.0\n",
    "\n",
    "    # ---------------------------------\n",
    "    # 5) Speed coverage margin\n",
    "    #    \"How many of P1's mons outspeed the lead by >10 base speed?\"\n",
    "    # ---------------------------------\n",
    "    lead_spe = float(lead.get(\"base_spe\", 0.0) or 0.0)\n",
    "    faster_strict = 0\n",
    "    for p in t1 or []:\n",
    "        if not isinstance(p, dict):\n",
    "            continue\n",
    "        v = p.get(\"base_spe\", None)\n",
    "        if isinstance(v, (int, float)) and float(v) > lead_spe + 10.0:\n",
    "            faster_strict += 1\n",
    "    f[\"speed_coverage_margin\"] = float(faster_strict)\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# LEAD MATCHUP / DAMAGE-INDEX HELPERS\n",
    "# ====================================\n",
    "def _simple_damage_index(base_power: float, stab: bool, eff: float, atk_proxy: float, def_proxy: float) -> float:\n",
    "    if not isinstance(base_power, (int, float)) or base_power <= 0:\n",
    "        return 0.0\n",
    "    s = 1.5 if stab else 1.0\n",
    "    ratio = (float(atk_proxy) + 1e-3) / (float(def_proxy) + 1e-3)\n",
    "    val = float(base_power) * s * float(eff) * ratio\n",
    "    return float(val) if np.isfinite(val) else 0.0\n",
    "\n",
    "def _p1_vs_p2lead_matchup_index(record: dict, tl: list[dict]) -> dict:\n",
    "    p1_team = record.get(\"p1_team_details\", []) or []\n",
    "    p1_mean_atk = float(np.mean([p.get(\"base_atk\", 0) for p in p1_team])) if p1_team else 0.0\n",
    "    p1_mean_spa = float(np.mean([p.get(\"base_spa\", 0) for p in p1_team])) if p1_team else 0.0\n",
    "\n",
    "    lead = record.get(\"p2_lead_details\") or {}\n",
    "    p2_types = lead.get(\"types\") or []\n",
    "    if isinstance(p2_types, str): p2_types = [p2_types]\n",
    "    p2_types = [t for t in p2_types if t]\n",
    "    p2_def = float(lead.get(\"base_def\", 0.0) or 0.0)\n",
    "    p2_spd = float(lead.get(\"base_spd\", 0.0) or 0.0)\n",
    "\n",
    "    p1map = {}\n",
    "    for p in p1_team:\n",
    "        nm = (p.get(\"name\") or \"\").strip().lower()\n",
    "        ts = p.get(\"types\") or []\n",
    "        if isinstance(ts, str): ts = [ts]\n",
    "        p1map[nm] = {str(x).strip().upper() for x in ts if x}\n",
    "\n",
    "    def _acc(window=None):\n",
    "        seq = tl if window is None else tl[:window]\n",
    "        vals = []\n",
    "        for t in seq:\n",
    "            md = t.get(\"p1_move_details\") or {}\n",
    "            bp = md.get(\"base_power\"); cat = md.get(\"category\"); mtype = md.get(\"type\")\n",
    "            if not isinstance(bp, (int, float)) or bp <= 0: \n",
    "                continue\n",
    "            nm = (t.get(\"p1_pokemon_state\") or {}).get(\"name\", \"\")\n",
    "            nm = (nm or \"\").strip().lower()\n",
    "            is_stab = str(mtype or \"\").strip().upper() in p1map.get(nm, set())\n",
    "            eff = _type_multiplier(mtype, p2_types)\n",
    "            if (cat or \"\").upper() == \"PHYSICAL\":\n",
    "                idx = _simple_damage_index(bp, is_stab, eff, p1_mean_atk, p2_def)\n",
    "            elif (cat or \"\").upper() == \"SPECIAL\":\n",
    "                idx = _simple_damage_index(bp, is_stab, eff, p1_mean_spa, p2_spd)\n",
    "            else:\n",
    "                idx = 0.0\n",
    "            vals.append(idx)\n",
    "        return float(np.mean(vals)) if vals else 0.0\n",
    "\n",
    "    return {\n",
    "        \"lead_matchup_p1_index_full\": _acc(None),\n",
    "        \"lead_matchup_p1_index_5\":    _acc(5),\n",
    "    }\n",
    "\n",
    "# ==========================\n",
    "# SWITCH / HAZARD / MOMENTUM\n",
    "# ==========================\n",
    "def _switch_count(tl: list[dict], who: str) -> float:\n",
    "    last = None\n",
    "    cnt = 0\n",
    "    key = f\"{who}_pokemon_state\"\n",
    "    for t in tl:\n",
    "        nm = (t.get(key) or {}).get(\"name\")\n",
    "        if nm is None:\n",
    "            continue\n",
    "        if last is not None and nm != last:\n",
    "            cnt += 1\n",
    "        last = nm\n",
    "    return float(cnt)\n",
    "\n",
    "HAZARD_MOVES = {\"stealthrock\", \"spikes\", \"toxicspikes\", \"stickyweb\"}\n",
    "\n",
    "def _hazard_flags(tl: list[dict]) -> dict:\n",
    "    p1 = p2 = 0.0\n",
    "    for t in tl:\n",
    "        m1 = (t.get(\"p1_move_details\") or {}).get(\"name\")\n",
    "        m2 = (t.get(\"p2_move_details\") or {}).get(\"name\")\n",
    "        if m1 and str(m1).strip().lower() in HAZARD_MOVES: p1 = 1.0\n",
    "        if m2 and str(m2).strip().lower() in HAZARD_MOVES: p2 = 1.0\n",
    "    return {\"hazard_p1_flag\": p1, \"hazard_p2_flag\": p2, \"hazard_flag_diff\": p1 - p2}\n",
    "\n",
    "def _momentum_shift(tl: list[dict], t1: int = 3, t2: int = 10) -> dict:\n",
    "    def _hp_diff_mean(win):\n",
    "        p1, p2 = _extract_hp_series(win)\n",
    "        if not p1 or not p2 or len(p1) != len(p2): return 0.0\n",
    "        d = [a-b for a,b in zip(p1,p2)]\n",
    "        return float(np.mean(d)) if d else 0.0\n",
    "    d1 = _hp_diff_mean(tl[:t1]); d2 = _hp_diff_mean(tl[:t2])\n",
    "    return {\"momentum_shift_3_10\": float(d1 - d2), \"momentum_shift_abs_3_10\": float(abs(d1 - d2))}\n",
    "\n",
    "HEAL_MOVES = {\"recover\",\"roost\",\"softboiled\",\"rest\",\"wish\",\"synthesis\",\"morningsun\",\"moonlight\",\"drainpunch\",\"leechseed\"}\n",
    "\n",
    "def _recovery_pressure(tl: list[dict]) -> dict:\n",
    "    p1 = p2 = 0.0\n",
    "    for t in tl:\n",
    "        m1 = (t.get(\"p1_move_details\") or {}).get(\"name\")\n",
    "        m2 = (t.get(\"p2_move_details\") or {}).get(\"name\")\n",
    "        if m1 and str(m1).strip().lower() in HEAL_MOVES: p1 += 1.0\n",
    "        if m2 and str(m2).strip().lower() in HEAL_MOVES: p2 += 1.0\n",
    "    return {\"recover_p1_count\": p1, \"recover_p2_count\": p2, \"recover_count_diff\": p1 - p2}\n",
    "\n",
    "# ---------------------------------------------\n",
    "# NEW FEATURES \n",
    "# ---------------------------------------------\n",
    "def new_features(r):\n",
    "    tl = get_timeline(r, max_turns=30)\n",
    "    p1, p2 = _extract_hp_series(tl)\n",
    "    t1 = r.get(\"p1_team_details\", []) or []\n",
    "    lead = r.get(\"p2_lead_details\", {}) or {}\n",
    "\n",
    "    f = {}\n",
    "    if len(p1) >= 3 and len(p2) >= 3:\n",
    "        f['early_hp_winner'] = 1.0 if np.mean(p1[:3]) > np.mean(p2[:3]) else 0.0\n",
    "        f['early_hp_difference'] = np.mean(p1[:3]) - np.mean(p2[:3])\n",
    "\n",
    "    if p1 and p2:\n",
    "        f['final_hp_winner'] = 1.0 if p1[-1] > p2[-1] else 0.0\n",
    "        f['final_hp_difference'] = p1[-1] - p2[-1]\n",
    "\n",
    "    p1_total_stats = sum(p.get(k, 0) for p in t1 for k in BASE_STAT_KEYS)\n",
    "    p2_total_stats = sum(lead.get(k, 0) for k in BASE_STAT_KEYS)\n",
    "    f['stronger_team'] = 1.0 if p1_total_stats > p2_total_stats else 0.0\n",
    "    f['team_strength_gap'] = p1_total_stats - p2_total_stats\n",
    "\n",
    "    p1_speeds = [p.get('base_spe', 0) for p in t1]\n",
    "    p2_speed = lead.get('base_spe', 0)\n",
    "    f['faster_team'] = 1.0 if max(p1_speeds, default=0) > p2_speed else 0.0\n",
    "    f['speed_advantage'] = max(p1_speeds, default=0) - p2_speed\n",
    "    f['num_faster_pokemon'] = sum(1 for s in p1_speeds if s > p2_speed)\n",
    "\n",
    "    f['p1_danger_count'] = sum(1 for hp in p1 if 0 < hp < 25)\n",
    "    f['p2_danger_count'] = sum(1 for hp in p2 if 0 < hp < 25)\n",
    "    f['survived_more_danger'] = 1.0 if f['p1_danger_count'] < f['p2_danger_count'] else 0.0\n",
    "    return f\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Mirko & Deb\n",
    "# ---------------------------------------------\n",
    "def get_defensive_profile(types):\n",
    "    \"\"\"\n",
    "    Combined defensive multipliers for a defender with 'types' against every attack type.\n",
    "    Fixed: use attacking type first, then multiply by defender types.\n",
    "    \"\"\"\n",
    "    types = types or []\n",
    "    if isinstance(types, str): types = [types]\n",
    "    types_up = [str(t).strip().upper() for t in types if t]\n",
    "\n",
    "    combined = {}\n",
    "    for atk_type in _TYPE_CHART.keys():\n",
    "        mult = 1.0\n",
    "        for tdef in types_up:\n",
    "            mult *= _TYPE_CHART.get(atk_type, {}).get(tdef, 1.0)\n",
    "        combined[atk_type] = float(mult)\n",
    "    return combined\n",
    "def _team_max_eff_vs_lead(team: list[dict], lead_types_raw) -> float:\n",
    "    \"\"\"\n",
    "    For a given P1 team and the P2 lead types, compute the maximum\n",
    "    type effectiveness multiplier the team can theoretically have\n",
    "    against that lead, using each Pok√©mon's own typing as proxy\n",
    "    for its offensive coverage.\n",
    "    \"\"\"\n",
    "    # Normalize lead types\n",
    "    lead_types = lead_types_raw or []\n",
    "    if isinstance(lead_types, str):\n",
    "        lead_types = [lead_types]\n",
    "    lead_types = [t for t in lead_types if t]\n",
    "\n",
    "    if not team or not lead_types:\n",
    "        return 1.0  # neutral\n",
    "\n",
    "    best = 1.0\n",
    "    for p in team:\n",
    "        if not isinstance(p, dict):\n",
    "            continue\n",
    "        ts = p.get(\"types\") or []\n",
    "        if isinstance(ts, str):\n",
    "            ts = [ts]\n",
    "        ts = [str(t).strip().upper() for t in ts if t]\n",
    "        if not ts:\n",
    "            continue\n",
    "        # for each offensive type (we approximate using its own typing)\n",
    "        local_best = 1.0\n",
    "        for atk_type in ts:\n",
    "            eff = _type_multiplier(atk_type, lead_types)\n",
    "            if eff > local_best:\n",
    "                local_best = eff\n",
    "        if local_best > best:\n",
    "            best = local_best\n",
    "    return float(best)\n",
    "\n",
    "def new_features_mirko(battle):\n",
    "    features = {}\n",
    "    # Player 1 Team aggregate\n",
    "    p1_team = battle.get('p1_team_details', []) or []\n",
    "    if p1_team:\n",
    "        ratios = []\n",
    "        v_hp=[]; v_spe=[]; v_atk=[]; v_def=[]\n",
    "        all_types=[]\n",
    "        weaknesses=[]; resistances=[]; immunities=[]\n",
    "        for p in p1_team:\n",
    "            if not isinstance(p, dict): \n",
    "                continue\n",
    "            off = (p.get(\"base_atk\",0) + p.get(\"base_spa\",0))\n",
    "            deff = (p.get(\"base_def\",0) + p.get(\"base_spd\",0))\n",
    "            ratios.append(off / deff if deff > 0 else 0.0)\n",
    "\n",
    "            v_hp.append(p.get('base_hp',0)); v_spe.append(p.get('base_spe',0))\n",
    "            v_atk.append(p.get('base_atk',0)); v_def.append(p.get('base_def',0))\n",
    "\n",
    "            ts = p.get(\"types\") or []\n",
    "            if isinstance(ts,str): ts=[ts]\n",
    "            all_types.extend([t for t in ts if str(t).lower()!='notype'])\n",
    "\n",
    "            prof = get_defensive_profile(ts)\n",
    "            w = sum(1 for m in prof.values() if m > 1)\n",
    "            r = sum(1 for m in prof.values() if 0 < m < 1)\n",
    "            i = sum(1 for m in prof.values() if m == 0)\n",
    "            weaknesses.append(w); resistances.append(r); immunities.append(i)\n",
    "\n",
    "        features[\"avg_type_role_ratio\"] = float(np.mean(ratios)) if ratios else 0.0\n",
    "        features['p1_var_hp']  = float(np.std(v_hp)) if v_hp else 0.0\n",
    "        features['p1_var_spe'] = float(np.std(v_spe)) if v_spe else 0.0\n",
    "        features['p1_var_atk'] = float(np.std(v_atk)) if v_atk else 0.0\n",
    "        features['p1_var_def'] = float(np.std(v_def)) if v_def else 0.0\n",
    "\n",
    "        unique_types = len(set(all_types))\n",
    "        features['diversity_ratio'] = unique_types / 6.0\n",
    "\n",
    "        features[\"avg_weaknesses\"] = float(np.mean(weaknesses))  if weaknesses  else 0.0\n",
    "        features[\"avg_resistances\"] = float(np.mean(resistances)) if resistances else 0.0\n",
    "        features[\"avg_immunities\"] = float(np.mean(immunities))  if immunities  else 0.0\n",
    "\n",
    "    # P2 lead raw stats\n",
    "    p2_lead = battle.get('p2_lead_details') or {}\n",
    "    if isinstance(p2_lead, dict) and p2_lead:\n",
    "        features['p2_lead_hp']  = p2_lead.get('base_hp', 0)\n",
    "        features['p2_lead_spe'] = p2_lead.get('base_spe', 0)\n",
    "        features['p2_lead_atk'] = p2_lead.get('base_atk', 0)\n",
    "        features['p2_lead_def'] = p2_lead.get('base_def', 0)\n",
    "\n",
    "    # Voluntary leave counters (None move_details ~ skipped)\n",
    "    tl = battle.get('battle_timeline', []) or []\n",
    "    idx_none_p2 = [i+1 for i,e in enumerate(tl) if e.get('p2_move_details') is None]\n",
    "    idx_none_p1 = [i+1 for i,e in enumerate(tl) if e.get('p1_move_details') is None]\n",
    "    def _bucket_count(idxs,a,b): return len([x for x in idxs if a<=x<=b])\n",
    "    features['vol_leave_diff_1'] = _bucket_count(idx_none_p1,1,10)  - _bucket_count(idx_none_p2,1,10)\n",
    "    features['vol_leave_diff_2'] = _bucket_count(idx_none_p1,11,20) - _bucket_count(idx_none_p2,11,20)\n",
    "    features['vol_leave_diff_3'] = _bucket_count(idx_none_p1,21,10**9) - _bucket_count(idx_none_p2,21,10**9)\n",
    "\n",
    "    # Forced leave heuristics (name change + action executed)\n",
    "    def _forced_counts(side_key, move_key):\n",
    "        lst=[]\n",
    "        for t in tl:\n",
    "            lst.append([ (t.get(side_key) or {}).get(\"name\"), (t.get(move_key) is None) ])\n",
    "        c1=c2=c3=0\n",
    "        for i in range(len(lst)-1):\n",
    "            changed = (lst[i+1][0] != lst[i][0])\n",
    "            acted   = (lst[i+1][1] == False)\n",
    "            turn_idx = i+1\n",
    "            if changed and acted:\n",
    "                if 1<=turn_idx<=10: c1+=1\n",
    "                elif 11<=turn_idx<=20: c2+=1\n",
    "                else: c3+=1\n",
    "        return c1,c2,c3\n",
    "    p1c1,p1c2,p1c3 = _forced_counts(\"p1_pokemon_state\",\"p1_move_details\")\n",
    "    p2c1,p2c2,p2c3 = _forced_counts(\"p2_pokemon_state\",\"p2_move_details\")\n",
    "    features['forced_leave_diff_1'] = float(p1c1 - p2c1)\n",
    "    features['forced_leave_diff_2'] = float(p1c2 - p2c2)\n",
    "    features['forced_leave_diff_3'] = float(p1c3 - p2c3)\n",
    "\n",
    "    # IDs / target\n",
    "    features['battle_id'] = battle.get('battle_id')\n",
    "    if 'player_won' in battle: features['player_won'] = int(battle['player_won'])\n",
    "    return features\n",
    "\n",
    "# ======= helpers for team & HP & damage stats =======\n",
    "def _pnames_from_p1_team(record):\n",
    "    team = record.get(\"p1_team_details\", []) or []\n",
    "    names = []\n",
    "    for p in team:\n",
    "        if isinstance(p, dict):\n",
    "            nm = (p.get(\"name\") or \"\").strip().lower()\n",
    "            if nm: names.append(nm)\n",
    "    return names\n",
    "\n",
    "def _pname_from_p2_lead(record):\n",
    "    lead = record.get(\"p2_lead_details\") or {}\n",
    "    if isinstance(lead, dict):\n",
    "        nm = (lead.get(\"name\") or \"\").strip().lower()\n",
    "        return nm if nm else None\n",
    "    return None\n",
    "\n",
    "def build_pokemon_win_stats(train_data, alpha=1.0):\n",
    "    games = defaultdict(int); wins = defaultdict(int)\n",
    "    for r in train_data:\n",
    "        p1_names = _pnames_from_p1_team(r)\n",
    "        p2_lead  = _pname_from_p2_lead(r)\n",
    "        p1_won   = bool(r.get(\"player_won\", False))\n",
    "        for nm in p1_names: games[nm]+=1\n",
    "        if p2_lead: games[p2_lead]+=1\n",
    "        if p1_won:\n",
    "            for nm in p1_names: wins[nm]+=1\n",
    "        else:\n",
    "            if p2_lead: wins[p2_lead]+=1\n",
    "    winrate={}\n",
    "    for nm in games:\n",
    "        g=games[nm]; w=wins[nm]\n",
    "        wr=(w+alpha)/(g+2*alpha)\n",
    "        winrate[nm]={\"games\":g,\"wins\":w,\"winrate\":wr}\n",
    "    return winrate\n",
    "\n",
    "def team_score_from_stats(team_names, stats, default_wr=0.5):\n",
    "    vals=[stats.get((nm or \"\").strip().lower(),{}).get(\"winrate\",default_wr) for nm in team_names if nm]\n",
    "    return float(np.mean(vals)) if vals else default_wr\n",
    "\n",
    "def predict_from_stats(test_record, stats, threshold=0.5):\n",
    "    p1_names = _pnames_from_p1_team(test_record)\n",
    "    score = team_score_from_stats(p1_names, stats, default_wr=0.5)\n",
    "    return (score > threshold), score\n",
    "\n",
    "def build_pokemon_hp_stats(train_data):\n",
    "    hp_sum=defaultdict(float); hp_count=defaultdict(int)\n",
    "    for r in train_data:\n",
    "        timeline = r.get(\"battle_timeline\", []) or []\n",
    "        if not timeline: continue\n",
    "        last_turn = timeline[-1]\n",
    "        for player_key in [\"p1_pokemon_state\", \"p2_pokemon_state\"]:\n",
    "            name = (last_turn.get(player_key, {}).get(\"name\") or \"\").strip().lower()\n",
    "            hp   = last_turn.get(player_key, {}).get(\"hp_pct\", None)\n",
    "            if name and isinstance(hp,(int,float)):\n",
    "                hp_sum[name]+=float(hp); hp_count[name]+=1\n",
    "    stats = {name: {\"count\": hp_count[name], \"hp_mean\": hp_sum[name]/hp_count[name]} for name in hp_sum}\n",
    "    return stats\n",
    "\n",
    "def team_hp_score(team_names, hp_stats, default_hp=50.0):\n",
    "    vals=[]\n",
    "    for name in team_names:\n",
    "        n=(name or \"\").strip().lower()\n",
    "        vals.append(hp_stats.get(n,{}).get(\"hp_mean\", default_hp))\n",
    "    return float(np.mean(vals)) if vals else default_hp\n",
    "\n",
    "def build_pokemon_avg_damage(train_data):\n",
    "    total_damage=defaultdict(float); battles_count=defaultdict(int)\n",
    "    for battle in train_data:\n",
    "        timeline = battle.get(\"battle_timeline\", []) or []\n",
    "        p1_names = [(p.get(\"name\") or \"\").lower() for p in (battle.get(\"p1_team_details\", []) or []) if isinstance(p,dict)]\n",
    "        p2_lead  = battle.get(\"p2_lead_details\", {})\n",
    "        p2_name  = (p2_lead.get(\"name\") or \"\").lower() if isinstance(p2_lead,dict) else None\n",
    "\n",
    "        for name in p1_names: battles_count[name]+=1\n",
    "        if p2_name: battles_count[p2_name]+=1\n",
    "\n",
    "        for i in range(1,len(timeline)):\n",
    "            prev, curr = timeline[i-1], timeline[i]\n",
    "            hp2b = (prev.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\", None)\n",
    "            hp2a = (curr.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\", None)\n",
    "            if isinstance(hp2b,(int,float)) and isinstance(hp2a,(int,float)):\n",
    "                dmg=max(0,hp2b-hp2a)\n",
    "                if p1_names and dmg>0:\n",
    "                    for name in p1_names: total_damage[name]+=dmg\n",
    "            hp1b = (prev.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\", None)\n",
    "            hp1a = (curr.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\", None)\n",
    "            if isinstance(hp1b,(int,float)) and isinstance(hp1a,(int,float)):\n",
    "                dmg=max(0,hp1b-hp1a)\n",
    "                if p2_name and dmg>0:\n",
    "                    total_damage[p2_name]+=dmg\n",
    "    avg_damage = {name: total_damage[name]/battles_count[name] for name in battles_count if battles_count[name]>0}\n",
    "    return avg_damage\n",
    "\n",
    "def damage_feature_for_battle(record, avg_damage):\n",
    "    p1_names = [(p.get(\"name\") or \"\").lower() for p in (record.get(\"p1_team_details\",[]) or []) if isinstance(p,dict)]\n",
    "    p1_damage_score = sum(avg_damage.get(name, 0.0) for name in p1_names)\n",
    "    p2_lead = record.get(\"p2_lead_details\", {}) or {}\n",
    "    p2_name = (p2_lead.get(\"name\") or \"\").lower() if isinstance(p2_lead,dict) else None\n",
    "    p2_damage_score = avg_damage.get(p2_name,0.0) if p2_name else 0.0\n",
    "    diff = p1_damage_score - p2_damage_score\n",
    "    return {\"avg_damage_p1\": p1_damage_score, \"avg_damage_p2\": p2_damage_score, \"avg_damage_diff\": diff, \"damage_prediction\": 1.0 if diff>0 else 0.0}\n",
    "\n",
    "# ======= Deb's feature block (kept) =======\n",
    "def new_features_deb(r):\n",
    "    tl = get_timeline(r, max_turns=30)\n",
    "    p1, p2 = _extract_hp_series(tl)\n",
    "    t1 = r.get(\"p1_team_details\", []) or []\n",
    "    lead = r.get(\"p2_lead_details\", {}) or {}\n",
    "    f = {}\n",
    "\n",
    "    if len(p1) >= 3 and len(p2) >= 3:\n",
    "        media_p1 = float(np.mean(p1[:3])); media_p2 = float(np.mean(p2[:3]))\n",
    "        f['is_p1_higher_avg_hp_after_3_turns'] = 1.0 if media_p1 > media_p2 else 0.0\n",
    "        f['avg_hp_difference_after_3_turns'] = media_p1 - media_p2\n",
    "\n",
    "    if p1 and p2:\n",
    "        f['is_player1_final_hp_winner'] = 1.0 if p1[-1] > p2[-1] else 0.0\n",
    "        f['final_hp_difference'] = p1[-1] - p2[-1]\n",
    "\n",
    "    if len(p1) >= 6 and len(p2) >= 6:\n",
    "        f['comeback_happened'] = float((np.mean(p1[:3]) > np.mean(p2[:3])) != (np.mean(p1[-3:]) > np.mean(p2[-3:])))\n",
    "\n",
    "    p1_total_stats = sum(p.get('base_hp',0)+p.get('base_atk',0)+p.get('base_def',0)+p.get('base_spa',0)+p.get('base_spd',0)+p.get('base_spe',0) for p in t1 if isinstance(p,dict))\n",
    "    p2_total_stats = (lead.get('base_hp',0)+lead.get('base_atk',0)+lead.get('base_def',0)+lead.get('base_spa',0)+lead.get('base_spd',0)+lead.get('base_spe',0))\n",
    "    f['stronger_team'] = 1.0 if p1_total_stats > p2_total_stats else 0.0\n",
    "    f['team_strength_gap'] = p1_total_stats - p2_total_stats\n",
    "\n",
    "    p1_speeds = [p.get('base_spe', 0) for p in t1 if isinstance(p,dict)]\n",
    "    p2_speed = lead.get('base_spe', 0) if isinstance(lead,dict) else 0\n",
    "    if p1_speeds:\n",
    "        f['faster_team'] = 1.0 if max(p1_speeds) > p2_speed else 0.0\n",
    "        f['speed_advantage'] = max(p1_speeds) - p2_speed\n",
    "        f['num_faster_pokemon'] = sum(1 for s in p1_speeds if s > p2_speed)\n",
    "    else:\n",
    "        f['faster_team'] = 0.0; f['speed_advantage'] = 0.0; f['num_faster_pokemon'] = 0.0\n",
    "\n",
    "    p1_powers=[]; p2_powers=[]\n",
    "    for t in tl:\n",
    "        if not isinstance(t,dict): continue\n",
    "        md1=t.get('p1_move_details'); md2=t.get('p2_move_details')\n",
    "        bp1 = md1.get('base_power') if isinstance(md1,dict) else None\n",
    "        bp2 = md2.get('base_power') if isinstance(md2,dict) else None\n",
    "        if isinstance(bp1,(int,float)) and bp1>0: p1_powers.append(float(bp1))\n",
    "        if isinstance(bp2,(int,float)) and bp2>0: p2_powers.append(float(bp2))\n",
    "    if p1_powers and p2_powers:\n",
    "        f['most_avg_powerful_move'] = 1.0 if np.mean(p1_powers) > np.mean(p2_powers) else 0.0\n",
    "        f['avg_move_power_difference'] = float(np.mean(p1_powers) - np.mean(p2_powers))\n",
    "    else:\n",
    "        f['most_avg_powerful_move'] = 0.0; f['avg_move_power_difference'] = 0.0\n",
    "\n",
    "    f['p1_low_hp_count'] = sum(1 for hp in p1 if 0 < hp < 25)\n",
    "    f['p2_low_hp_count'] = sum(1 for hp in p2 if 0 < hp < 25)\n",
    "    f['is_player1_less_time_in_danger'] = 1.0 if f['p1_low_hp_count'] < f['p2_low_hp_count'] else 0.0\n",
    "    f['battle_length'] = len(tl)\n",
    "    f['long_battle'] = 1.0 if len(tl) > 15 else 0.0\n",
    "\n",
    "    if len(p1) > 1 and len(p2) > 1:\n",
    "        p1_changes=[abs(p1[i]-p1[i-1]) for i in range(1,len(p1))]\n",
    "        p2_changes=[abs(p2[i]-p2[i-1]) for i in range(1,len(p2))]\n",
    "        f['p1_hp_stability'] = -float(np.mean(p1_changes)) if p1_changes else 0.0\n",
    "        f['p2_hp_stability'] = -float(np.mean(p2_changes)) if p2_changes else 0.0\n",
    "        f['more_stable_hp'] = 1.0 if (p1_changes and p2_changes and np.mean(p1_changes) < np.mean(p2_changes)) else 0.0\n",
    "    else:\n",
    "        f['p1_hp_stability']=0.0; f['p2_hp_stability']=0.0; f['more_stable_hp']=0.0\n",
    "\n",
    "    p1_first_ko=0.0; p2_first_ko=0.0\n",
    "    for hp1,hp2 in zip(p1,p2):\n",
    "        if hp2==0 and p2_first_ko==0.0: p2_first_ko=1.0; break\n",
    "        if hp1==0 and p1_first_ko==0.0: p1_first_ko=1.0; break\n",
    "    f['player1_got_first_ko']=p2_first_ko\n",
    "    f['player1_suffered_first_ko']=p1_first_ko\n",
    "\n",
    "    p1_types=set()\n",
    "    for p in t1:\n",
    "        if not isinstance(p,dict): continue\n",
    "        types=p.get('types',[])\n",
    "        if isinstance(types,str): types=[types]\n",
    "        p1_types.update(t for t in types if t)\n",
    "    f['number_different_types']=len(p1_types)\n",
    "    f['team_has_type_variety']=1.0 if len(p1_types)>=4 else 0.0\n",
    "\n",
    "    if p1 and p2:\n",
    "        p1_healthy_ratio = sum(1 for hp in p1 if hp>50)/len(p1)\n",
    "        p2_healthy_ratio = sum(1 for hp in p2 if hp>50)/len(p2)\n",
    "        f['p1_hp_over_50_ratio']=p1_healthy_ratio\n",
    "        f['p2_hp_over_50_ratio']=p2_healthy_ratio\n",
    "        f['is_player1_healthier']=1.0 if p1_healthy_ratio>p2_healthy_ratio else 0.0\n",
    "    else:\n",
    "        f['p1_hp_over_50_ratio']=0.0; f['p2_hp_over_50_ratio']=0.0; f['is_player1_healthier']=0.0\n",
    "\n",
    "    if len(p1)==len(p2) and p1:\n",
    "        turns_ahead=sum(1 for a,b in zip(p1,p2) if a>b)\n",
    "        f['turns_in_lead']=float(turns_ahead)\n",
    "        f['lead_ratio']=turns_ahead/len(p1)\n",
    "        f['dominated_battle']=1.0 if turns_ahead>len(p1)*0.7 else 0.0\n",
    "    else:\n",
    "        f['turns_in_lead']=0.0; f['lead_ratio']=0.0; f['dominated_battle']=0.0\n",
    "\n",
    "    p_leave = r.get('battle_timeline', []) or []\n",
    "    if p_leave:\n",
    "        lst=[]; c1=c2=0\n",
    "        for turn in p_leave:\n",
    "            lst.append([\n",
    "                (turn.get(\"p1_pokemon_state\") or {}).get(\"name\"),\n",
    "                (turn.get('p1_move_details') is None),\n",
    "                (turn.get(\"p2_pokemon_state\") or {}).get(\"name\"),\n",
    "                (turn.get('p2_move_details') is None)\n",
    "            ])\n",
    "        for i in range(len(lst)-1):\n",
    "            if lst[i+1][0]!=lst[i][0] and lst[i+1][1]==False: c1+=1\n",
    "            elif lst[i+1][2]!=lst[i][2] and lst[i+1][3]==False: c2+=1\n",
    "        f['forced_pokemon_switch_diff']=float(c1-c2)\n",
    "    else:\n",
    "        f['forced_pokemon_switch_diff']=0.0\n",
    "\n",
    "    if p_leave:\n",
    "        p1_names=set([ (t.get(\"p1_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p1_pokemon_state\") or {}).get(\"name\") ])\n",
    "        p2_names=set([ (t.get(\"p2_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p2_pokemon_state\") or {}).get(\"name\") ])\n",
    "        f['used_pokemon_diff']=float(len(p1_names)-len(p2_names))\n",
    "    else:\n",
    "        f['used_pokemon_diff']=0.0\n",
    "\n",
    "    if p_leave:\n",
    "        recent=p_leave[-5:] if len(p_leave)>=5 else p_leave\n",
    "        p1r=[(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0) for t in recent]\n",
    "        p2r=[(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0) for t in recent]\n",
    "        f['avg_hp_recent_diff']=float(np.mean(p1r)-np.mean(p2r)) if p1r and p2r else 0.0\n",
    "    else:\n",
    "        f['avg_hp_recent_diff']=0.0\n",
    "\n",
    "    if p_leave:\n",
    "        p1_status=sum(1 for t in p_leave if (t.get(\"p1_pokemon_state\") or {}).get(\"status\",\"nostatus\")!=\"nostatus\")\n",
    "        p2_status=sum(1 for t in p_leave if (t.get(\"p2_pokemon_state\") or {}).get(\"status\",\"nostatus\")!=\"nostatus\")\n",
    "        f['num_bad_status_diff']=float(p2_status-p1_status)\n",
    "    else:\n",
    "        f['num_bad_status_diff']=0.0\n",
    "\n",
    "    if p_leave:\n",
    "        last=p_leave[-1]\n",
    "        p1f=(last.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "        p2f=(last.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "        f['final_hp_diff']=float(p1f-p2f)\n",
    "        p1_alive = 1 if p1f>0 else 0\n",
    "        p2_alive = 1 if p2f>0 else 0\n",
    "        p1_used=len(set([(t.get(\"p1_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p1_pokemon_state\") or {}).get(\"name\")]))\n",
    "        p2_used=len(set([(t.get(\"p2_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p2_pokemon_state\") or {}).get(\"name\")]))\n",
    "        team_size=6\n",
    "        p1_remaining = team_size - p1_used + p1_alive\n",
    "        p2_remaining = team_size - p2_used + p2_alive\n",
    "        f['pokemon_remaining_diff']=float(p1_remaining - p2_remaining)\n",
    "    else:\n",
    "        f['final_hp_diff']=0.0; f['pokemon_remaining_diff']=0.0\n",
    "\n",
    "    if p_leave and len(p_leave)>=2:\n",
    "        total_dmg_dealt=0.0; total_dmg_taken=0.0\n",
    "        for i in range(1,len(p_leave)):\n",
    "            prev, curr = p_leave[i-1], p_leave[i]\n",
    "            p2b=(prev.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            p2a=(curr.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            total_dmg_dealt += max(0,p2b-p2a)\n",
    "            p1b=(prev.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            p1a=(curr.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            total_dmg_taken += max(0,p1b-p1a)\n",
    "        f['damage_ratio'] = float(total_dmg_dealt/total_dmg_taken) if total_dmg_taken>0 else (total_dmg_dealt*10 if total_dmg_dealt>0 else 1.0)\n",
    "        f['tot_damage_diff']=float(total_dmg_dealt-total_dmg_taken)\n",
    "    else:\n",
    "        f['damage_ratio']=1.0; f['tot_damage_diff']=0.0\n",
    "\n",
    "    if p_leave and len(p_leave)>=6:\n",
    "        mid=len(p_leave)//2\n",
    "        first=p_leave[:mid]; second=p_leave[mid:]\n",
    "        p1e=[(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0) for t in first]\n",
    "        p2e=[(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0) for t in first]\n",
    "        p1l=[(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0) for t in second]\n",
    "        p2l=[(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0) for t in second]\n",
    "        early_adv = float(np.mean(p1e)-np.mean(p2e)) if p1e and p2e else 0.0\n",
    "        late_adv  = float(np.mean(p1l)-np.mean(p2l)) if p1l and p2l else 0.0\n",
    "        f['late_game_improvement']=late_adv - early_adv\n",
    "        f['late_game_hp_adv']=late_adv\n",
    "        f['early_game_hp_adv']=early_adv\n",
    "    else:\n",
    "        f['late_game_improvement']=0.0; f['late_game_hp_adv']=0.0; f['early_game_hp_adv']=0.0\n",
    "\n",
    "    if len(p1)>=10 and len(p2)>=10:\n",
    "        f['avg_hp_diff_gap'] = float( (np.mean(p1[5:10]) - np.mean(p2[5:10])) - (np.mean(p1[:5]) - np.mean(p2[:5])) )\n",
    "\n",
    "    if len(p1)>3 and len(p2)>3:\n",
    "        f['p1_hp_std']=float(np.std(np.diff(p1)))\n",
    "        f['p2_hp_std']=float(np.std(np.diff(p2)))\n",
    "\n",
    "    if p1 and p2:\n",
    "        f['max_hp_deficit_player1'] = float(max(0, max(p2) - min(p1)))\n",
    "\n",
    "    total_dealt=total_taken=0.0\n",
    "    for i in range(1,len(tl)):\n",
    "        prev, curr = tl[i-1], tl[i]\n",
    "        if not (isinstance(prev,dict) and isinstance(curr,dict)): continue\n",
    "        weight = 1.0 + (i/len(tl))*0.5\n",
    "        p2_prev=(prev.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",100)\n",
    "        p2_curr=(curr.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",100)\n",
    "        total_dealt += max(0,p2_prev-p2_curr)*weight\n",
    "        p1_prev=(prev.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",100)\n",
    "        p1_curr=(curr.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",100)\n",
    "        total_taken += max(0,p1_prev-p1_curr)*weight\n",
    "    f['damage_trade_ratio_weighted'] = float(total_dealt/max(1,total_taken))\n",
    "\n",
    "    if tl:\n",
    "        last=tl[-1]\n",
    "        p1f=(last.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "        p2f=(last.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "        f['final_hp_advantage']=float(p1f-p2f)\n",
    "        f['final_hp_ratio']=float(p1f/max(1,p2f))\n",
    "        p1_last_pow=(last.get(\"p1_move_details\") or {}).get(\"base_power\",0)\n",
    "        p2_last_pow=(last.get(\"p2_move_details\") or {}).get(\"base_power\",0)\n",
    "        f['final_power_advantage']=float(p1_last_pow - p2_last_pow)\n",
    "        p1_status=(last.get(\"p1_pokemon_state\") or {}).get(\"status\",\"\")\n",
    "        p2_status=(last.get(\"p2_pokemon_state\") or {}).get(\"status\",\"\")\n",
    "        f['final_status_advantage']=0.0\n",
    "        if p2_status and str(p2_status).lower() not in [\"\",\"none\",\"nostatus\"]: f['final_status_advantage'] += 1.0\n",
    "        if p1_status and str(p1_status).lower() not in [\"\",\"none\",\"nostatus\"]: f['final_status_advantage'] -= 1.0\n",
    "\n",
    "        final_score = 0.0\n",
    "        final_score += (p1f - p2f) * 0.5\n",
    "        if p1f>0 and p2f==0: final_score += 30.0\n",
    "        elif p2f>0 and p1f==0: final_score -= 30.0\n",
    "        final_score += (p1_last_pow - p2_last_pow) * 0.15\n",
    "        final_score += f['final_status_advantage'] * 5.0\n",
    "        f['final_battle_score']=final_score\n",
    "        f['final_winning_prob']=1.0/(1.0+np.exp(-final_score/10.0))\n",
    "\n",
    "        recent=tl[-5:] if len(tl)>=5 else tl\n",
    "        diffs=[]\n",
    "        for t in recent:\n",
    "            p1h=(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            p2h=(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            diffs.append(p1h-p2h)\n",
    "        if diffs:\n",
    "            f['recent_avg_hp_advantage']=float(np.mean(diffs))\n",
    "            f['recent_hp_improving']=1.0 if len(diffs)>1 and diffs[-1]>diffs[0] else 0.0\n",
    "\n",
    "    if 'final_hp_advantage' in f and len(tl)>=5:\n",
    "        hp_gap=f['final_hp_advantage']\n",
    "        turns=len(tl)\n",
    "        comeback=0.35\n",
    "        if abs(hp_gap)>50: comeback=0.95\n",
    "        elif abs(hp_gap)>30: comeback=0.75\n",
    "        elif abs(hp_gap)>15: comeback=0.55\n",
    "        if turns<10: comeback*=0.8\n",
    "        elif turns>20: comeback*=1.2\n",
    "        comeback=min(1.0, comeback)\n",
    "        win_prob = 0.5 + (comeback*0.5) if hp_gap>0 else 0.5 - (comeback*0.5)\n",
    "        f['comeback_difficulty']=float(comeback)\n",
    "        f['predicted_win_prob']=float(win_prob)\n",
    "\n",
    "    if p1 and p2 and len(tl)>=3:\n",
    "        p1_current_hp=p1[-1]; p2_current_hp=p2[-1]\n",
    "        pattern_score=0.0\n",
    "        p1_kos=sum(1 for hp in p2 if hp==0); p2_kos=sum(1 for hp in p1 if hp==0)\n",
    "        ko_adv = p1_kos - p2_kos\n",
    "        if ko_adv>=2: pattern_score+=0.3\n",
    "        elif ko_adv==1: pattern_score+=0.15\n",
    "        elif ko_adv==-1: pattern_score-=0.15\n",
    "        elif ko_adv<=-2: pattern_score-=0.3\n",
    "        if len(p1)>=5 and len(p2)>=5:\n",
    "            p1_trend = np.mean(p1[-3:]) - np.mean(p1[-5:-2])\n",
    "            p2_trend = np.mean(p2[-3:]) - np.mean(p2[-5:-2])\n",
    "            if p1_trend>5 and p2_trend<-5: pattern_score+=0.2\n",
    "            elif p1_trend<-5 and p2_trend>5: pattern_score-=0.2\n",
    "\n",
    "        p1_used=set(); p2_used=set()\n",
    "        for t in tl:\n",
    "            if isinstance(t,dict):\n",
    "                p1n=(t.get(\"p1_pokemon_state\") or {}).get(\"name\",\"\")\n",
    "                p2n=(t.get(\"p2_pokemon_state\") or {}).get(\"name\",\"\")\n",
    "                if p1n: p1_used.add(p1n)\n",
    "                if p2n: p2_used.add(p2n)\n",
    "        team_size=6\n",
    "        p1_rem=team_size - len(p1_used) + (1 if p1_current_hp>0 else 0)\n",
    "        p2_rem=team_size - len(p2_used) + (1 if p2_current_hp>0 else 0)\n",
    "        pokemon_adv = p1_rem - p2_rem\n",
    "        if pokemon_adv>=2: pattern_score+=0.35\n",
    "        elif pokemon_adv==1: pattern_score+=0.20\n",
    "        elif pokemon_adv==-1: pattern_score-=0.20\n",
    "        elif pokemon_adv<=-2: pattern_score-=0.35\n",
    "\n",
    "        f['ko_advantage']=float(ko_adv)\n",
    "        f['estimated_pokemon_remaining_p1']=float(p1_rem)\n",
    "        f['estimated_pokemon_remaining_p2']=float(p2_rem)\n",
    "        f['pokemon_advantage']=float(pokemon_adv)\n",
    "        base_prob=0.5\n",
    "        if 'final_hp_advantage' in f: base_prob += (f['final_hp_advantage']/100.0)*0.3\n",
    "        base_prob += pattern_score*0.4\n",
    "        if 'predicted_win_prob' in f: base_prob = base_prob*0.7 + f['predicted_win_prob']*0.3\n",
    "        f['final_win_probability']=max(0.0,min(1.0,base_prob))\n",
    "\n",
    "    if 'final_win_probability' in f:\n",
    "        prob=f['final_win_probability']\n",
    "        confidence = abs(prob-0.5)*2\n",
    "        if f.get('p1_alive_final',0)==1 and f.get('p2_alive_final',0)==0: confidence=0.95\n",
    "        elif f.get('p1_alive_final',0)==0 and f.get('p2_alive_final',0)==1: confidence=0.95\n",
    "        f['prediction_confidence']=float(confidence)\n",
    "        if prob>0.75 and confidence>0.6: f['outcome_prediction']=2.0\n",
    "        elif prob>0.6: f['outcome_prediction']=1.0\n",
    "        elif prob<0.25 and confidence>0.6: f['outcome_prediction']=-2.0\n",
    "        elif prob<0.4: f['outcome_prediction']=-1.0\n",
    "        else: f['outcome_prediction']=0.0\n",
    "    return f\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Global stats built on train_data \n",
    "# ---------------------------------------------\n",
    "POKEMON_STATS    = build_pokemon_win_stats(train_data, alpha=1.0)\n",
    "POKEMON_HP_STATS = build_pokemon_hp_stats(train_data)\n",
    "pokemon_avg_damage = build_pokemon_avg_damage(train_data)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Full feature set (static + timeline + moves + Mirko & Deb)\n",
    "# ---------------------------------------------\n",
    "def _one_record_features(r):\n",
    "    # Static team features\n",
    "    t1 = r.get(\"p1_team_details\", []) or []\n",
    "    lead = r.get(\"p2_lead_details\", {}) or {}\n",
    "    t2 = [lead] if isinstance(lead, dict) and lead else []\n",
    "\n",
    "    p1sz = len(t1); p2sz = len(t2)\n",
    "    p1u  = unique_types(t1); p2u = unique_types(t2)\n",
    "    p1s  = sum_stats_of_team(t1); p2s = sum_stats_of_team(t2)\n",
    "    p1a  = avg_stats_of_team(t1); p2a = avg_stats_of_team(t2)\n",
    "    p2_ls, p2_la = sum_and_avg_of_single(lead) if lead else (0.0, 0.0)\n",
    "    p1v  = team_stat_variance(t1)\n",
    "\n",
    "    f = {\n",
    "        \"p1_team_size\": p1sz, \"p2_team_size\": p2sz,\n",
    "        \"p1_unique_types\": p1u, \"p2_unique_types\": p2u,\n",
    "        \"p1_team_stat_sum\": p1s, \"p2_team_stat_sum\": p2s,\n",
    "        \"p1_team_stat_avg\": p1a, \"p2_team_stat_avg\": p2a,\n",
    "        \"diff_team_size\": p1sz - p2sz,\n",
    "        \"diff_unique_types\": p1u - p2u,\n",
    "        \"diff_team_stat_sum\": p1s - p2s,\n",
    "        \"diff_team_stat_avg\": p1a - p2a,\n",
    "        \"p2_lead_stat_sum\": p2_ls, \"p2_lead_stat_avg\": p2_la,\n",
    "        \"p1_sum_minus_p2_lead_sum\": p1s - p2_ls,\n",
    "        \"p1_avg_minus_p2_lead_avg\": p1a - p2_la,\n",
    "        \"p1_team_stat_var\": p1v,\n",
    "        \"ratio_p1_avg_over_p2_lead_avg\": _safe_ratio(p1a, p2_la),\n",
    "    }\n",
    "\n",
    "    # Speed advantage vs p2 lead\n",
    "    p1_mean_spe, p1_max_spe = _team_speed_stats(t1)\n",
    "    p2_lead_spe = float(lead.get(\"base_spe\", 0.0)) if lead else 0.0\n",
    "    faster_cnt = sum(1 for p in t1 if isinstance(p.get(\"base_spe\"),(int,float)) and float(p[\"base_spe\"])>p2_lead_spe)\n",
    "    frac_faster = float(faster_cnt)/max(1,len(t1))\n",
    "    f.update({\n",
    "        \"p1_mean_spe\": p1_mean_spe, \"p1_max_spe\": p1_max_spe, \"p2_lead_spe\": p2_lead_spe,\n",
    "        \"spe_mean_adv\": p1_mean_spe - p2_lead_spe, \"spe_max_adv\": p1_max_spe - p2_lead_spe,\n",
    "        \"p1_frac_faster_than_p2lead\": frac_faster,\n",
    "    })\n",
    "\n",
    "    # Timeline HP features\n",
    "    tl = get_timeline(r, max_turns=30)\n",
    "    p1, p2 = _extract_hp_series(tl)\n",
    "    diff = [a-b for a,b in zip(p1,p2)] if p1 and p2 and len(p1)==len(p2) else []\n",
    "\n",
    "    p1m,p1l,p1s_,p1mn = _mean_last_std_min(p1)\n",
    "    p2m,p2l,p2s_,p2mn = _mean_last_std_min(p2)\n",
    "    dm,dl,ds,dmn = _mean_last_std_min(diff)\n",
    "\n",
    "    f.update({\n",
    "        \"tl_turns_used\": float(len(tl)),\n",
    "        \"tl_p1_hp_mean\": p1m, \"tl_p1_hp_last\": p1l, \"tl_p1_hp_std\": p1s_, \"tl_p1_hp_min\": p1mn,\n",
    "        \"tl_p2_hp_mean\": p2m, \"tl_p2_hp_last\": p2l, \"tl_p2_hp_std\": p2s_, \"tl_p2_hp_min\": p2mn,\n",
    "        \"tl_hp_diff_mean\": dm, \"tl_hp_diff_last\": dl, \"tl_hp_diff_std\": ds, \"tl_hp_diff_min\": dmn,\n",
    "        \"tl_p1_hp_slope\": _slope(p1), \"tl_p2_hp_slope\": _slope(p2), \"tl_hp_diff_slope\": _slope(diff),\n",
    "        \"tl_p1_hp_auc\": _auc_pct(p1), \"tl_p2_hp_auc\": _auc_pct(p2),\n",
    "        \"tl_frac_turns_advantage\": _frac_positive(diff),\n",
    "        \"tl_p1_status_count\": _status_count(tl,\"p1\"),\n",
    "        \"tl_p2_status_count\": _status_count(tl,\"p2\"),\n",
    "    })\n",
    "    f[\"tl_status_count\"] = f[\"tl_p1_status_count\"] + f[\"tl_p2_status_count\"]\n",
    "    f[\"tl_p1_ko_count\"]  = _ko_count(p1)\n",
    "    f[\"tl_p2_ko_count\"]  = _ko_count(p2)\n",
    "    f[\"tl_ko_count\"]     = f[\"tl_p1_ko_count\"] + f[\"tl_p2_ko_count\"]\n",
    "\n",
    "    # Type effectiveness P1 ‚Üí P2 lead\n",
    "    p2_types = lead.get(\"types\") or []\n",
    "    if isinstance(p2_types,str): p2_types=[p2_types]\n",
    "    p2_types=[t for t in p2_types if t]\n",
    "    f.update({\n",
    "        \"ter_p1_vs_p2lead_full\": _avg_type_eff_p1_vs_p2lead(tl, p2_types, window=None),\n",
    "        \"ter_p1_vs_p2lead_5\":    _avg_type_eff_p1_vs_p2lead(tl, p2_types, window=5),\n",
    "        \"ter_p1_vs_p2lead_10\":   _avg_type_eff_p1_vs_p2lead(tl, p2_types, window=10),\n",
    "    })\n",
    "    # ------------------------------------------------------------------\n",
    "    # Extra matchup & tempo features (NEW)\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    # 1) Lead vs lead speed ‚Äî who is faster?\n",
    "    # Try to use p1_lead_details if available, otherwise fallback to fastest team member.\n",
    "    p1_lead = r.get(\"p1_lead_details\") or {}\n",
    "    if isinstance(p1_lead, dict) and p1_lead:\n",
    "        lead_spe_p1 = float(p1_lead.get(\"base_spe\", 0.0) or 0.0)\n",
    "    else:\n",
    "        # fallback: use max speed in P1 team as \"effective lead speed\"\n",
    "        lead_spe_p1 = float(max([p.get(\"base_spe\", 0.0) for p in t1 if isinstance(p, dict)], default=0.0))\n",
    "\n",
    "    lead_spe_p2 = float(lead.get(\"base_spe\", 0.0) or 0.0) if lead else 0.0\n",
    "    f[\"lead_spe_p1\"] = lead_spe_p1\n",
    "    f[\"lead_spe_p2\"] = lead_spe_p2\n",
    "    f[\"lead_speed_adv\"] = lead_spe_p1 - lead_spe_p2\n",
    "    f[\"lead_is_faster\"] = 1.0 if lead_spe_p1 > lead_spe_p2 else 0.0\n",
    "\n",
    "    # 2) Hard counter vs P2 lead: maximum type effectiveness the P1 team\n",
    "    #    can theoretically achieve against the opponent lead.\n",
    "    max_eff_vs_lead = _team_max_eff_vs_lead(t1, p2_types)\n",
    "    f[\"team_max_eff_vs_p2lead\"] = max_eff_vs_lead\n",
    "    f[\"has_hard_counter_vs_lead\"] = 1.0 if max_eff_vs_lead >= 2.0 else 0.0\n",
    "    f[\"has_soft_counter_vs_lead\"] = 1.0 if max_eff_vs_lead >= 1.5 else 0.0\n",
    "\n",
    "    # 3) Late‚Äìgame HP advantage (last 5 turns)\n",
    "    last_n = 5\n",
    "    if p1 and p2:\n",
    "        # slice last N turns safely\n",
    "        p1_lastN = p1[-last_n:] if len(p1) >= last_n else p1\n",
    "        p2_lastN = p2[-last_n:] if len(p2) >= last_n else p2\n",
    "        if p1_lastN and p2_lastN:\n",
    "            p1_lastN_mean = float(np.mean(p1_lastN))\n",
    "            p2_lastN_mean = float(np.mean(p2_lastN))\n",
    "            late_adv = p1_lastN_mean - p2_lastN_mean\n",
    "        else:\n",
    "            p1_lastN_mean = p2_lastN_mean = late_adv = 0.0\n",
    "    else:\n",
    "        p1_lastN_mean = p2_lastN_mean = late_adv = 0.0\n",
    "\n",
    "    f[\"late_hp_mean_p1_5\"] = p1_lastN_mean\n",
    "    f[\"late_hp_mean_p2_5\"] = p2_lastN_mean\n",
    "    f[\"late_game_hp_adv_5\"] = late_adv\n",
    "    f[\"late_game_domination_5\"] = 1.0 if late_adv > 0.0 else 0.0\n",
    "\n",
    "    # 4) Hazard pressure per turn (normalized)\n",
    "    # Requires that hazard flags and switch counts have been computed somewhere\n",
    "    # in the feature pipeline. If not yet, we'll default to zero.\n",
    "    haz_sw_diff = float(f.get(\"hazard_switch_pressure_diff\", 0.0))\n",
    "    turns_used = float(len(tl)) if tl else 1.0\n",
    "    f[\"hazard_pressure_per_turn\"] = haz_sw_diff / max(1.0, turns_used)\n",
    "\n",
    "    # --- New safe, bounded features (add near the end of _one_record_features) ---\n",
    "\n",
    "    # 1) Team offensive tilt: physical vs special (bounded, finite)\n",
    "    p1_sum_atk = float(sum(p.get(\"base_atk\", 0) for p in t1 if isinstance(p, dict)))\n",
    "    p1_sum_spa = float(sum(p.get(\"base_spa\", 0) for p in t1 if isinstance(p, dict)))\n",
    "    f[\"p1_offense_bias_ratio\"] = (p1_sum_atk + 1e-3) / (p1_sum_spa + 1e-3)  # >1 => more physical tilt\n",
    "    f[\"p1_offense_balance_gap\"] = p1_sum_atk - p1_sum_spa\n",
    "    \n",
    "    # 2) Defensive overlap: shared-weakness burden (small integers / means)\n",
    "    def _count_weaknesses_of_types(types):\n",
    "        prof = get_defensive_profile(types or [])\n",
    "        return float(sum(1 for m in prof.values() if m > 1.0))\n",
    "    \n",
    "    p1_weak_counts = []\n",
    "    for p in t1:\n",
    "        if isinstance(p, dict):\n",
    "            p1_weak_counts.append(_count_weaknesses_of_types(p.get(\"types\", [])))\n",
    "    \n",
    "    f[\"p1_weakness_mean\"] = float(np.mean(p1_weak_counts)) if p1_weak_counts else 0.0\n",
    "    f[\"p1_weakness_max\"]  = float(np.max(p1_weak_counts))  if p1_weak_counts else 0.0\n",
    "    \n",
    "    # 3) Breadth of resistances (unique resistances union)\n",
    "    def _unique_resistances(types):\n",
    "        prof = get_defensive_profile(types or [])\n",
    "        return {atk for atk, mult in prof.items() if 0.0 < mult < 1.0}\n",
    "    \n",
    "    res_sets = []\n",
    "    for p in t1:\n",
    "        if isinstance(p, dict):\n",
    "            res_sets.append(_unique_resistances(p.get(\"types\", [])))\n",
    "    union_res = set().union(*res_sets) if res_sets else set()\n",
    "    f[\"p1_unique_resistances\"] = float(len(union_res))\n",
    "    \n",
    "    # 4) Early HP volatility (first 5 turns), bounded by [0,100] deltas\n",
    "    def _safe_clip_hp(seq):\n",
    "        return [max(0.0, min(100.0, float(x))) for x in seq]\n",
    "    \n",
    "    def _mean_abs_step(arr):\n",
    "        return float(np.mean([abs(arr[i] - arr[i-1]) for i in range(1, len(arr))])) if len(arr) > 1 else 0.0\n",
    "    \n",
    "    p1_hp5 = _safe_clip_hp(_window(p1, 5))\n",
    "    p2_hp5 = _safe_clip_hp(_window(p2, 5))\n",
    "    f[\"p1_hp_abs_step_5\"] = _mean_abs_step(p1_hp5)\n",
    "    f[\"p2_hp_abs_step_5\"] = _mean_abs_step(p2_hp5)\n",
    "    f[\"hp_abs_step_gap_5\"] = f[\"p1_hp_abs_step_5\"] - f[\"p2_hp_abs_step_5\"]\n",
    "    \n",
    "    # 5) Hazards effectiveness given switches (difference version; robust via f.get)\n",
    "    haz_p1 = float(f.get(\"hazard_p1_flag\", 0.0))\n",
    "    haz_p2 = float(f.get(\"hazard_p2_flag\", 0.0))\n",
    "    sw_p1  = float(f.get(\"switch_p1_count\", 0.0))\n",
    "    sw_p2  = float(f.get(\"switch_p2_count\", 0.0))\n",
    "    haz_sw_p1 = haz_p1 * sw_p2\n",
    "    haz_sw_p2 = haz_p2 * sw_p1\n",
    "    f[\"hazard_switch_pressure_diff\"] = haz_sw_p1 - haz_sw_p2\n",
    "    \n",
    "    # 6) Late-game move accuracy advantage (last 5 turns), safe mean\n",
    "    def _avg_acc_lastN(timeline, who, n=5):\n",
    "        seq = timeline[-n:] if len(timeline) >= n else timeline\n",
    "        accs = []\n",
    "        for t in seq:\n",
    "            md = (t.get(f\"{who}_move_details\") or {})\n",
    "            a = md.get(\"accuracy\", None)\n",
    "            if isinstance(a, (int, float)):\n",
    "                accs.append(float(a))\n",
    "        return float(np.mean(accs)) if accs else 0.0\n",
    "    \n",
    "    f[\"late_acc_adv_5\"] = _avg_acc_lastN(tl, \"p1\", 5) - _avg_acc_lastN(tl, \"p2\", 5)\n",
    "\n",
    "    # --- Move-based features (full & 5 turns) ---\n",
    "    mv1_full = _move_stats_for_side(tl, \"p1\", None)\n",
    "    mv2_full = _move_stats_for_side(tl, \"p2\", None)\n",
    "    f.update(mv1_full); f.update(mv2_full)\n",
    "    f[\"mv_power_mean_ratio\"]  = _safe_ratio(mv1_full[\"mv_p1_power_mean\"], mv2_full[\"mv_p2_power_mean\"])\n",
    "    mv1_5 = _move_stats_for_side(tl, \"p1\", 5)\n",
    "    mv2_5 = _move_stats_for_side(tl, \"p2\", 5)\n",
    "    f.update(mv1_5); f.update(mv2_5)\n",
    "    \n",
    "    f[\"mv_power_mean_ratio_5\"] = _safe_ratio(mv1_5[\"mv_p1_power_mean_5\"], mv2_5[\"mv_p2_power_mean_5\"])\n",
    "    \n",
    "    # Matchup / switches / hazards / momentum / recovery / STAB / early / priority\n",
    "    f.update(_p1_vs_p2lead_matchup_index(r, tl))\n",
    "    f[\"switch_p1_count\"]=_switch_count(tl,\"p1\"); f[\"switch_p2_count\"]=_switch_count(tl,\"p2\")\n",
    "    f[\"switch_count_diff\"]=f[\"switch_p1_count\"]-f[\"switch_p2_count\"]\n",
    "    f.update(_hazard_flags(tl))\n",
    "    f.update(_recovery_pressure(tl))\n",
    "    f.update(_stab_features(r, max_turns=30))\n",
    "    f.update(_early_momentum_features(r, first_n=3))\n",
    "    f.update(_priority_feature_block(r))\n",
    "    f.update(new_features(r))\n",
    "    f.update(new_features_deb(r))\n",
    "    f.update(new_features_mirko(r))\n",
    "    # Extra strong engineered features (top-5)\n",
    "    f.update(extra_strong_features(r, tl, p1, p2, t1, lead))\n",
    "    # --- Top-5 extra engineered features (ratios & composite scores) ---\n",
    "    # 1) Final HP ratio: who ends higher, on a smooth scale\n",
    "    p1_last_hp = f.get(\"tl_p1_hp_last\", 0.0)\n",
    "    p2_last_hp = f.get(\"tl_p2_hp_last\", 0.0)\n",
    "    f[\"hp_final_ratio\"] = (p1_last_hp + 1.0) / (p2_last_hp + 1.0)\n",
    "\n",
    "    # 2) HP AUC ratio: sustained HP advantage over the whole battle\n",
    "    p1_auc = f.get(\"tl_p1_hp_auc\", 0.0)\n",
    "    p2_auc = f.get(\"tl_p2_hp_auc\", 0.0)\n",
    "    f[\"hp_auc_ratio\"] = (p1_auc + 1e-3) / (p2_auc + 1e-3)\n",
    "\n",
    "    # 3) Max speed ratio: fastest P1 vs P2 lead\n",
    "    p1_max_spe = f.get(\"p1_max_spe\", 0.0) if \"p1_max_spe\" in f else 0.0\n",
    "    p2_lead_spe = f.get(\"p2_lead_spe\", 0.0) if \"p2_lead_spe\" in f else 0.0\n",
    "    f[\"max_speed_ratio\"] = (p1_max_spe + 1.0) / (p2_lead_spe + 1.0)\n",
    "\n",
    "    # 4) Early momentum composite: early HP diff √ó priority advantage (first 5 turns)\n",
    "    early_hp_diff = f.get(\"early_hp_diff_mean_3\", 0.0)\n",
    "    prio_diff_5   = f.get(\"mv_priority_count_diff_5\", 0.0)\n",
    "    f[\"early_momentum_combo\"] = early_hp_diff * (1.0 + prio_diff_5)\n",
    "\n",
    "    # 5) Matchup √ó HP dominance: lead matchup index combined with HP diff\n",
    "    lead_match_full = f.get(\"lead_matchup_p1_index_full\", 0.0)\n",
    "    hp_diff_mean    = f.get(\"tl_hp_diff_mean\", 0.0)\n",
    "    # small scaling by 1/100 to keep the magnitude reasonable\n",
    "    f[\"matchup_hp_combo\"] = lead_match_full * (hp_diff_mean / 100.0)\n",
    "\n",
    "\n",
    "    # Team Winrate / HP resilience / Avg damage\n",
    "    try:\n",
    "        p1_team_names=_pnames_from_p1_team(r)\n",
    "        f[\"p1_team_winrate_score\"]=team_score_from_stats(p1_team_names, POKEMON_STATS, default_wr=0.5)\n",
    "    except Exception:\n",
    "        f[\"p1_team_winrate_score\"]=0.5\n",
    "    p1_names=_pnames_from_p1_team(r)\n",
    "    p2_name=_pname_from_p2_lead(r)\n",
    "    f[\"p1_team_avg_hp_score\"]=team_hp_score(p1_names, POKEMON_HP_STATS)\n",
    "    f[\"p2_lead_avg_hp\"]=POKEMON_HP_STATS.get(p2_name,{}).get(\"hp_mean\",50.0)\n",
    "    f[\"hp_resilience_diff\"]=f[\"p1_team_avg_hp_score\"] - f[\"p2_lead_avg_hp\"]\n",
    "    f[\"predicted_win_by_hp\"]=1.0 if f[\"hp_resilience_diff\"]>0 else 0.0\n",
    "\n",
    "    f.update(damage_feature_for_battle(r, pokemon_avg_damage))\n",
    "    \n",
    "    # Extra global strength features from POKEMON_STATS (if available)\n",
    "    try:\n",
    "        winrates = [\n",
    "            POKEMON_STATS.get((nm or \"\").strip().lower(), {}).get(\"winrate\", 0.5)\n",
    "            for nm in p1_team_names\n",
    "            if nm\n",
    "        ]\n",
    "        if winrates:\n",
    "            f[\"p1_team_max_winrate\"] = float(np.max(winrates))\n",
    "            f[\"p1_team_min_winrate\"] = float(np.min(winrates))\n",
    "            f[\"p1_team_winspread\"]   = f[\"p1_team_max_winrate\"] - f[\"p1_team_min_winrate\"]\n",
    "            f[\"p1_weaklink_gap\"]     = f[\"p1_team_winrate_score\"] - f[\"p1_team_min_winrate\"]\n",
    "        else:\n",
    "            f[\"p1_team_max_winrate\"] = 0.5\n",
    "            f[\"p1_team_min_winrate\"] = 0.5\n",
    "            f[\"p1_team_winspread\"]   = 0.0\n",
    "            f[\"p1_weaklink_gap\"]     = 0.0\n",
    "    except Exception:\n",
    "        f[\"p1_team_max_winrate\"] = 0.5\n",
    "        f[\"p1_team_min_winrate\"] = 0.5\n",
    "        f[\"p1_team_winspread\"]   = 0.0\n",
    "        f[\"p1_weaklink_gap\"]     = 0.0\n",
    "\n",
    "    # IDs / target\n",
    "    f[\"battle_id\"]=r.get(\"battle_id\")\n",
    "    if \"player_won\" in r:\n",
    "        f[\"player_won\"]= int(r[\"player_won\"]) if isinstance(r[\"player_won\"], bool) else r[\"player_won\"]\n",
    "    return f\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Public API (same name & return type as starter)\n",
    "# ---------------------------------------------\n",
    "def create_simple_features(data: list[dict]) -> pd.DataFrame:\n",
    "    rows=[]\n",
    "    for battle in tqdm(data, desc=\"Extracting features\"):\n",
    "        rows.append(_one_record_features(battle))\n",
    "    return pd.DataFrame(rows).fillna(0)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Run feature extraction\n",
    "# ---------------------------------------------\n",
    "print(\"Processing training data...\")\n",
    "train_df = create_simple_features(train_data)\n",
    "\n",
    "print(\"\\nProcessing test data...\")\n",
    "test_data = []\n",
    "with open(test_file_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n",
    "test_df = create_simple_features(test_data)\n",
    "\n",
    "print(\"\\nTraining features preview:\")\n",
    "\n",
    "# --- Manual interactions (robust to missing columns) ---\n",
    "def _maybe_add_interactions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def safe_mul(a, b, name):\n",
    "        if a in df.columns and b in df.columns:\n",
    "            df[name] = df[a] * df[b]\n",
    "\n",
    "    # Team strength √ó move power (full)\n",
    "    safe_mul(\"p1_team_stat_avg\", \"mv_p1_power_mean\", \"ix_p1avg_x_p1pow\")\n",
    "    # Speed √ó priority advantage (first 5 turns if available)\n",
    "    if \"spe_max_adv\" in df.columns and \"mv_priority_count_diff_5\" in df.columns:\n",
    "        df[\"ix_speed_x_prio5\"] = df[\"spe_max_adv\"] * df[\"mv_priority_count_diff_5\"]\n",
    "    # HP momentum √ó fraction of advantaged turns\n",
    "    safe_mul(\"tl_hp_diff_mean\", \"tl_frac_turns_advantage\", \"ix_hpmean_x_fracadv\")\n",
    "    # Early momentum √ó priority diff (first 5)\n",
    "    if \"early_hp_diff_mean_3\" in df.columns and \"mv_priority_count_diff_5\" in df.columns:\n",
    "        df[\"ix_early3_x_prio5\"] = df[\"early_hp_diff_mean_3\"] * df[\"mv_priority_count_diff_5\"]\n",
    "    # STAB advantage √ó early KO score\n",
    "    if \"stab_stab_ratio_diff_full\" in df.columns and \"early_first_ko_score_3\" in df.columns:\n",
    "        df[\"ix_stabdiff_x_firstko\"] = df[\"stab_stab_ratio_diff_full\"] * df[\"early_first_ko_score_3\"]\n",
    "    # Type effectiveness √ó STAB (full)\n",
    "    if \"ter_p1_vs_p2lead_full\" in df.columns and \"stab_stab_ratio_diff_full\" in df.columns:\n",
    "        df[\"ix_ter_x_stab_full\"] = df[\"ter_p1_vs_p2lead_full\"] * df[\"stab_stab_ratio_diff_full\"]\n",
    "    # Type effectiveness √ó early momentum (first 3)\n",
    "    if \"ter_p1_vs_p2lead_5\" in df.columns and \"early_hp_diff_mean_3\" in df.columns:\n",
    "        df[\"ix_ter5_x_early3\"] = df[\"ter_p1_vs_p2lead_5\"] * df[\"early_hp_diff_mean_3\"]\n",
    "    # Lead matchup √ó early momentum\n",
    "    if \"lead_matchup_p1_index_5\" in df.columns and \"early_hp_diff_mean_3\" in df.columns:\n",
    "        df[\"ix_leadmatch5_x_early3\"] = df[\"lead_matchup_p1_index_5\"] * df[\"early_hp_diff_mean_3\"]\n",
    "    # Hazards advantage √ó priority pressure\n",
    "    if \"hazard_flag_diff\" in df.columns and \"mv_priority_count_diff_5\" in df.columns:\n",
    "        df[\"ix_hazards_x_prio5\"] = df[\"hazard_flag_diff\"] * df[\"mv_priority_count_diff_5\"]\n",
    "    return df\n",
    "\n",
    "train_df = _maybe_add_interactions(train_df)\n",
    "test_df  = _maybe_add_interactions(test_df)\n",
    "\n",
    "# === 2.x Custom predictive features (safe: no NaN, no div-by-zero) ===\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "EPS = 1e-6\n",
    "REPLACE_EXISTING = True  # set to False to skip creation if a feature name already exists\n",
    "\n",
    "def _pick_first(df: pd.DataFrame, candidates, default_value=0.0):\n",
    "    \"\"\"Return the first existing column from candidates; else a float32 Series filled with default_value.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return df[c].astype(\"float32\")\n",
    "    return pd.Series(default_value, index=df.index, dtype=\"float32\")\n",
    "\n",
    "def _safe_div(a: pd.Series, b: pd.Series):\n",
    "    \"\"\"Elementwise safe division a/(b+EPS) with finite output.\"\"\"\n",
    "    out = a.astype(\"float32\") / (b.astype(\"float32\") + EPS)\n",
    "    out = out.replace([np.inf, -np.inf], 0.0).fillna(0.0).astype(\"float32\")\n",
    "    return out\n",
    "\n",
    "def _ensure_float32(s: pd.Series):\n",
    "    return s.astype(\"float32\").replace([np.inf, -np.inf], 0.0).fillna(0.0)\n",
    "\n",
    "def _normalize_acc(s: pd.Series):\n",
    "    \"\"\"If accuracy looks like [0..100], scale to [0..1].\"\"\"\n",
    "    s = _ensure_float32(s)\n",
    "    if len(s):\n",
    "        maxv = float(np.nanmax(s.values))\n",
    "    else:\n",
    "        maxv = 0.0\n",
    "    if maxv > 1.5:  # heuristically assume it's a percentage\n",
    "        s = s / 100.0\n",
    "    return s.clip(0.0, 1.0)\n",
    "\n",
    "def _add_feature_pair(train_df, test_df, name, train_series, test_series):\n",
    "    \"\"\"Attach float32 features to both train and test with final sanitation.\"\"\"\n",
    "    if (not REPLACE_EXISTING) and (name in train_df.columns or name in test_df.columns):\n",
    "        return\n",
    "    train_df[name] = _ensure_float32(train_series)\n",
    "    test_df[name]  = _ensure_float32(test_series)\n",
    "\n",
    "# --- Robust base columns (try multiple candidates, fall back to zeros) ---\n",
    "\n",
    "# Attack / Defense (means)\n",
    "atk_p1 = _pick_first(train_df, [\"atk_p1_mean\",\"atk_p1\",\"atk_p1_full\"], 0.0)\n",
    "atk_p2 = _pick_first(train_df, [\"atk_p2_mean\",\"atk_p2\",\"atk_p2_full\"], 0.0)\n",
    "def_p1 = _pick_first(train_df, [\"def_p1_mean\",\"def_p1\",\"def_p1_full\"], 0.0)\n",
    "def_p2 = _pick_first(train_df, [\"def_p2_mean\",\"def_p2\",\"def_p2_full\"], 0.0)\n",
    "\n",
    "atk_p1_te = _pick_first(test_df, [\"atk_p1_mean\",\"atk_p1\",\"atk_p1_full\"], 0.0)\n",
    "atk_p2_te = _pick_first(test_df, [\"atk_p2_mean\",\"atk_p2\",\"atk_p2_full\"], 0.0)\n",
    "def_p1_te = _pick_first(test_df, [\"def_p1_mean\",\"def_p1\",\"def_p1_full\"], 0.0)\n",
    "def_p2_te = _pick_first(test_df, [\"def_p2_mean\",\"def_p2\",\"def_p2_full\"], 0.0)\n",
    "\n",
    "# Special Attack / Defense (means)\n",
    "sp_atk_p1 = _pick_first(train_df, [\"sp_atk_p1_mean\",\"spatk_p1_mean\",\"spa_p1_mean\",\"sp_atk_p1\"], 0.0)\n",
    "sp_atk_p2 = _pick_first(train_df, [\"sp_atk_p2_mean\",\"spatk_p2_mean\",\"spa_p2_mean\",\"sp_atk_p2\"], 0.0)\n",
    "sp_def_p1 = _pick_first(train_df, [\"sp_def_p1_mean\",\"spdef_p1_mean\",\"spd_p1_mean_def\",\"sp_def_p1\"], 0.0)\n",
    "sp_def_p2 = _pick_first(train_df, [\"sp_def_p2_mean\",\"spdef_p2_mean\",\"spd_p2_mean_def\",\"sp_def_p2\"], 0.0)\n",
    "\n",
    "sp_atk_p1_te = _pick_first(test_df, [\"sp_atk_p1_mean\",\"spatk_p1_mean\",\"spa_p1_mean\",\"sp_atk_p1\"], 0.0)\n",
    "sp_atk_p2_te = _pick_first(test_df, [\"sp_atk_p2_mean\",\"spatk_p2_mean\",\"spa_p2_mean\",\"sp_atk_p2\"], 0.0)\n",
    "sp_def_p1_te = _pick_first(test_df, [\"sp_def_p1_mean\",\"spdef_p1_mean\",\"spd_p1_mean_def\",\"sp_def_p1\"], 0.0)\n",
    "sp_def_p2_te = _pick_first(test_df, [\"sp_def_p2_mean\",\"spdef_p2_mean\",\"spd_p2_mean_def\",\"sp_def_p2\"], 0.0)\n",
    "\n",
    "# Speed (means)\n",
    "spd_p1 = _pick_first(train_df, [\"spd_p1_mean\",\"speed_p1_mean\",\"spd_p1\"], 0.0)\n",
    "spd_p2 = _pick_first(train_df, [\"spd_p2_mean\",\"speed_p2_mean\",\"spd_p2\"], 0.0)\n",
    "spd_p1_te = _pick_first(test_df,  [\"spd_p1_mean\",\"speed_p1_mean\",\"spd_p1\"], 0.0)\n",
    "spd_p2_te = _pick_first(test_df,  [\"spd_p2_mean\",\"speed_p2_mean\",\"spd_p2\"], 0.0)\n",
    "\n",
    "# HP current / max\n",
    "hp1_cur = _pick_first(train_df, [\"hp_p1_remain\",\"hp_p1_curr\",\"hp_p1\"], 0.0)\n",
    "hp2_cur = _pick_first(train_df, [\"hp_p2_remain\",\"hp_p2_curr\",\"hp_p2\"], 0.0)\n",
    "hp1_max = _pick_first(train_df, [\"hp_p1_max\",\"hp_p1_base\",\"hp_p1_total\"], 1.0)\n",
    "hp2_max = _pick_first(train_df, [\"hp_p2_max\",\"hp_p2_base\",\"hp_p2_total\"], 1.0)\n",
    "\n",
    "hp1_cur_te = _pick_first(test_df, [\"hp_p1_remain\",\"hp_p1_curr\",\"hp_p1\"], 0.0)\n",
    "hp2_cur_te = _pick_first(test_df, [\"hp_p2_remain\",\"hp_p2_curr\",\"hp_p2\"], 0.0)\n",
    "hp1_max_te = _pick_first(test_df, [\"hp_p1_max\",\"hp_p1_base\",\"hp_p1_total\"], 1.0)\n",
    "hp2_max_te = _pick_first(test_df, [\"hp_p2_max\",\"hp_p2_base\",\"hp_p2_total\"], 1.0)\n",
    "\n",
    "# Move power / accuracy\n",
    "pwr_p1 = _pick_first(train_df, [\"mv_p1_power_mean_full\",\"mv_p1_power_mean\",\"mv_power_p1_mean\"], 0.0)\n",
    "pwr_p2 = _pick_first(train_df, [\"mv_p2_power_mean_full\",\"mv_p2_power_mean\",\"mv_power_p2_mean\"], 0.0)\n",
    "acc_p1 = _normalize_acc(_pick_first(train_df, [\"mv_p1_acc_mean_full\",\"mv_p1_acc_mean\",\"mv_acc_p1_mean\"], 0.0))\n",
    "acc_p2 = _normalize_acc(_pick_first(train_df, [\"mv_p2_acc_mean_full\",\"mv_p2_acc_mean\",\"mv_acc_p2_mean\"], 0.0))\n",
    "\n",
    "pwr_p1_te = _pick_first(test_df, [\"mv_p1_power_mean_full\",\"mv_p1_power_mean\",\"mv_power_p1_mean\"], 0.0)\n",
    "pwr_p2_te = _pick_first(test_df, [\"mv_p2_power_mean_full\",\"mv_p2_power_mean\",\"mv_power_p2_mean\"], 0.0)\n",
    "acc_p1_te = _normalize_acc(_pick_first(test_df, [\"mv_p1_acc_mean_full\",\"mv_p1_acc_mean\",\"mv_acc_p1_mean\"], 0.0))\n",
    "acc_p2_te = _normalize_acc(_pick_first(test_df, [\"mv_p2_acc_mean_full\",\"mv_p2_acc_mean\",\"mv_acc_p2_mean\"], 0.0))\n",
    "\n",
    "# Move type counts (STATUS / PHYSICAL / SPECIAL) ‚Äî safe fallbacks\n",
    "st_p1 = _pick_first(train_df, [\"mv_p1_count_STATUS_full\",\"mv_p1_count_STATUS\",\"status_moves_p1\"], 0.0)\n",
    "ph_p1 = _pick_first(train_df, [\"mv_p1_count_PHYSICAL_full\",\"mv_p1_count_PHYSICAL\",\"physical_moves_p1\"], 0.0)\n",
    "sp_p1 = _pick_first(train_df, [\"mv_p1_count_SPECIAL_full\",\"mv_p1_count_SPECIAL\",\"special_moves_p1\"], 0.0)\n",
    "st_p2 = _pick_first(train_df, [\"mv_p2_count_STATUS_full\",\"mv_p2_count_STATUS\",\"status_moves_p2\"], 0.0)\n",
    "ph_p2 = _pick_first(train_df, [\"mv_p2_count_PHYSICAL_full\",\"mv_p2_count_PHYSICAL\",\"physical_moves_p2\"], 0.0)\n",
    "sp_p2 = _pick_first(train_df, [\"mv_p2_count_SPECIAL_full\",\"mv_p2_count_SPECIAL\",\"special_moves_p2\"], 0.0)\n",
    "\n",
    "st_p1_te = _pick_first(test_df, [\"mv_p1_count_STATUS_full\",\"mv_p1_count_STATUS\",\"status_moves_p1\"], 0.0)\n",
    "ph_p1_te = _pick_first(test_df, [\"mv_p1_count_PHYSICAL_full\",\"mv_p1_count_PHYSICAL\",\"physical_moves_p1\"], 0.0)\n",
    "sp_p1_te = _pick_first(test_df, [\"mv_p1_count_SPECIAL_full\",\"mv_p1_count_SPECIAL\",\"special_moves_p1\"], 0.0)\n",
    "st_p2_te = _pick_first(test_df, [\"mv_p2_count_STATUS_full\",\"mv_p2_count_STATUS\",\"status_moves_p2\"], 0.0)\n",
    "ph_p2_te = _pick_first(test_df, [\"mv_p2_count_PHYSICAL_full\",\"mv_p2_count_PHYSICAL\",\"physical_moves_p2\"], 0.0)\n",
    "sp_p2_te = _pick_first(test_df, [\"mv_p2_count_SPECIAL_full\",\"mv_p2_count_SPECIAL\",\"special_moves_p2\"], 0.0)\n",
    "\n",
    "# ===============================\n",
    "# 10 SAFE, HIGH-SIGNAL FEATURES\n",
    "# ===============================\n",
    "\n",
    "# 1) atk_def_ratio: P1 attack vs P2 defense\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"atk_def_ratio\",\n",
    "    _safe_div(atk_p1, def_p2),\n",
    "    _safe_div(atk_p1_te, def_p2_te)\n",
    ")\n",
    "\n",
    "# 2) spd_gap: P1 speed minus P2 speed\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"spd_gap\",\n",
    "    (spd_p1 - spd_p2),\n",
    "    (spd_p1_te - spd_p2_te)\n",
    ")\n",
    "\n",
    "# 3) hp_ratio: P1 current HP vs P2 current HP\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"hp_ratio\",\n",
    "    _safe_div(hp1_cur, hp2_cur),\n",
    "    _safe_div(hp1_cur_te, hp2_cur_te)\n",
    ")\n",
    "\n",
    "# 4) survival_score: (P1 HP%) - (P2 HP%)\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"survival_score\",\n",
    "    _safe_div(hp1_cur, hp1_max) - _safe_div(hp2_cur, hp2_max),\n",
    "    _safe_div(hp1_cur_te, hp1_max_te) - _safe_div(hp2_cur_te, hp2_max_te)\n",
    ")\n",
    "\n",
    "# 5) momentum_index: (atk*spd)_P1 / (atk*spd)_P2\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"momentum_index\",\n",
    "    _safe_div(atk_p1 * spd_p1, atk_p2 * spd_p2),\n",
    "    _safe_div(atk_p1_te * spd_p1_te, atk_p2_te * spd_p2_te)\n",
    ")\n",
    "\n",
    "# 6) power_acc_gap: (avg power weighted by acc) P1 - P2\n",
    "pwa_p1 = _ensure_float32(pwr_p1 * acc_p1)\n",
    "pwa_p2 = _ensure_float32(pwr_p2 * acc_p2)\n",
    "pwa_p1_te = _ensure_float32(pwr_p1_te * acc_p1_te)\n",
    "pwa_p2_te = _ensure_float32(pwr_p2_te * acc_p2_te)\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"power_acc_gap\",\n",
    "    (pwa_p1 - pwa_p2),\n",
    "    (pwa_p1_te - pwa_p2_te)\n",
    ")\n",
    "\n",
    "# 7) offensive_balance: (atk + sp_atk) P1 / P2\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"offensive_balance\",\n",
    "    _safe_div(atk_p1 + sp_atk_p1, atk_p2 + sp_atk_p2),\n",
    "    _safe_div(atk_p1_te + sp_atk_p1_te, atk_p2_te + sp_atk_p2_te)\n",
    ")\n",
    "\n",
    "# 8) defensive_efficiency: (def + sp_def) P1 / P2\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"defensive_efficiency\",\n",
    "    _safe_div(def_p1 + sp_def_p1, def_p2 + sp_def_p2),\n",
    "    _safe_div(def_p1_te + sp_def_p1_te, def_p2_te + sp_def_p2_te)\n",
    ")\n",
    "\n",
    "# 9) status_influence: share STATUS moves P1 - P2\n",
    "tot_p1 = _ensure_float32(st_p1 + ph_p1 + sp_p1).replace(0.0, 1.0)\n",
    "tot_p2 = _ensure_float32(st_p2 + ph_p2 + sp_p2).replace(0.0, 1.0)\n",
    "tot_p1_te = _ensure_float32(st_p1_te + ph_p1_te + sp_p1_te).replace(0.0, 1.0)\n",
    "tot_p2_te = _ensure_float32(st_p2_te + ph_p2_te + sp_p2_te).replace(0.0, 1.0)\n",
    "\n",
    "status_share_p1 = _safe_div(st_p1, tot_p1)\n",
    "status_share_p2 = _safe_div(st_p2, tot_p2)\n",
    "status_share_p1_te = _safe_div(st_p1_te, tot_p1_te)\n",
    "status_share_p2_te = _safe_div(st_p2_te, tot_p2_te)\n",
    "\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"status_influence\",\n",
    "    (status_share_p1 - status_share_p2),\n",
    "    (status_share_p1_te - status_share_p2_te)\n",
    ")\n",
    "\n",
    "# 10) speed_ratio: P1 speed / P2 speed\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"speed_ratio\",\n",
    "    _safe_div(spd_p1, spd_p2),\n",
    "    _safe_div(spd_p1_te, spd_p2_te)\n",
    ")\n",
    "\n",
    "# --- Quick validation: no NaN/Inf and report how many were added ---\n",
    "new_cols = [\n",
    "    \"atk_def_ratio\",\"spd_gap\",\"hp_ratio\",\"survival_score\",\"momentum_index\",\n",
    "    \"power_acc_gap\",\"offensive_balance\",\"defensive_efficiency\",\"status_influence\",\"speed_ratio\"\n",
    "]\n",
    "bad_train = train_df[new_cols].isna().sum().sum() + np.isinf(train_df[new_cols].to_numpy()).sum()\n",
    "bad_test  = test_df[new_cols].isna().sum().sum()  + np.isinf(test_df[new_cols].to_numpy()).sum()\n",
    "print(f\"[FeatureEng] Added {len(new_cols)} engineered features. Bad values -> train: {bad_train}, test: {bad_test}\")\n",
    "\n",
    "# Keep a raw copy for inspection\n",
    "train_df_raw = train_df.copy()\n",
    "test_df_raw = test_df.copy()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 17. SCALING (ROBUST SCALER)\n",
    "# -------------------------------------------------\n",
    "\n",
    "# Identify numeric columns (all except ID and target)\n",
    "num_cols = [c for c in train_df.columns if c not in (\"battle_id\", \"player_won\")]\n",
    "\n",
    "# Fit the scaler on training numeric features only\n",
    "scaler = RobustScaler().fit(train_df[num_cols])\n",
    "\n",
    "# Apply transform\n",
    "train_df[num_cols] = scaler.transform(train_df[num_cols])\n",
    "test_df[num_cols] = scaler.transform(test_df[num_cols])\n",
    "\n",
    "print(\"\\nPreview (raw):\")\n",
    "display(train_df_raw.head())\n",
    "\n",
    "print(\"\\nScaling completed. Preview (scaled):\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9de6b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T21:09:53.917628Z",
     "iopub.status.busy": "2025-11-14T21:09:53.917138Z",
     "iopub.status.idle": "2025-11-14T21:09:53.987793Z",
     "shell.execute_reply": "2025-11-14T21:09:53.986348Z"
    },
    "papermill": {
     "duration": 0.081492,
     "end_time": "2025-11-14T21:09:53.989611",
     "exception": false,
     "start_time": "2025-11-14T21:09:53.908119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Advanced Top-5] Added 5 features to train_df: ['feat_lead_matchup_enh', 'feat_team_synergy', 'feat_early_momentum_refined', 'feat_kill_pressure', 'feat_switch_pressure']\n",
      "[Advanced Top-5] Added 5 features to test_df: ['feat_lead_matchup_enh', 'feat_team_synergy', 'feat_early_momentum_refined', 'feat_kill_pressure', 'feat_switch_pressure']\n",
      "[Cell 2] Added 5 extra stack features: ['clutch_win_index', 'dominant_win_index', 'status_efficiency', 'ko_efficiency', 'team_winrate_spread']\n",
      "\n",
      "[Advanced Top-5] train_df shape: (10000, 258)\n",
      "[Advanced Top-5] test_df  shape: (5000, 257)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3073731177.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"feat_lead_matchup_enh\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"feat_team_synergy\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"feat_early_momentum_refined\"] = early_hp_diff * frac_adv\n",
      "/tmp/ipykernel_13/3073731177.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"feat_kill_pressure\"] = mv_p1_pow5 * mv_pow_ratio5\n",
      "/tmp/ipykernel_13/3073731177.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"feat_switch_pressure\"] = switch_diff * dmg_ratio\n",
      "/tmp/ipykernel_13/3073731177.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"feat_lead_matchup_enh\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:37: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"feat_team_synergy\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:44: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"feat_early_momentum_refined\"] = early_hp_diff * frac_adv\n",
      "/tmp/ipykernel_13/3073731177.py:49: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"feat_kill_pressure\"] = mv_p1_pow5 * mv_pow_ratio5\n",
      "/tmp/ipykernel_13/3073731177.py:54: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"feat_switch_pressure\"] = switch_diff * dmg_ratio\n",
      "/tmp/ipykernel_13/3073731177.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"clutch_win_index\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dominant_win_index\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"status_efficiency\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ko_efficiency\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:111: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"ko_efficiency\"].replace([np.inf, -np.inf], 0.0, inplace=True)\n",
      "/tmp/ipykernel_13/3073731177.py:115: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"team_winrate_spread\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:89: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"clutch_win_index\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:95: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"dominant_win_index\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:101: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"status_efficiency\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:108: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"ko_efficiency\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:111: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"ko_efficiency\"].replace([np.inf, -np.inf], 0.0, inplace=True)\n",
      "/tmp/ipykernel_13/3073731177.py:115: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"team_winrate_spread\"] = (\n",
      "/tmp/ipykernel_13/3073731177.py:134: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"signed_log_tot_damage_diff\"] = _signed_log(df[\"tot_damage_diff\"])\n",
      "/tmp/ipykernel_13/3073731177.py:140: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"signed_log_ko_advantage\"] = _signed_log(df[\"ko_advantage\"])\n",
      "/tmp/ipykernel_13/3073731177.py:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"damage_x_status_adv\"] = df[\"damage_trade_ratio_weighted\"] * (1.0 + df[\"final_status_advantage\"])\n",
      "/tmp/ipykernel_13/3073731177.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"damage_x_team_winrate\"] = df[\"damage_trade_ratio_weighted\"] * df[\"p1_team_winrate_score\"]\n",
      "/tmp/ipykernel_13/3073731177.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"early_pressure_index\"] = df[\"vol_leave_diff_3\"] + 0.5 * df[\"recover_count_diff\"]\n",
      "/tmp/ipykernel_13/3073731177.py:134: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"signed_log_tot_damage_diff\"] = _signed_log(df[\"tot_damage_diff\"])\n",
      "/tmp/ipykernel_13/3073731177.py:140: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"signed_log_ko_advantage\"] = _signed_log(df[\"ko_advantage\"])\n",
      "/tmp/ipykernel_13/3073731177.py:146: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"damage_x_status_adv\"] = df[\"damage_trade_ratio_weighted\"] * (1.0 + df[\"final_status_advantage\"])\n",
      "/tmp/ipykernel_13/3073731177.py:152: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"damage_x_team_winrate\"] = df[\"damage_trade_ratio_weighted\"] * df[\"p1_team_winrate_score\"]\n",
      "/tmp/ipykernel_13/3073731177.py:158: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"early_pressure_index\"] = df[\"vol_leave_diff_3\"] + 0.5 * df[\"recover_count_diff\"]\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 2B ‚Äî Add 5 advanced meta-features\n",
    "# ============================\n",
    "# Assumes: train_df, test_df are already created in Cell 2.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _ensure_col(df: pd.DataFrame, col: str):\n",
    "    \"\"\"\n",
    "    If column 'col' is missing in df, create it filled with 0.0.\n",
    "    Returns the column as a Series (float32-compatible).\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0.0\n",
    "    return df[col]\n",
    "\n",
    "def add_advanced_top5_features(df: pd.DataFrame, name: str = \"df\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add 5 highly predictive meta-features on top of existing ones.\n",
    "    All constructed from already computed features -> no NaN, no div by 0.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Enhanced lead matchup score\n",
    "    #    Combines lead matchup index, type effectiveness and STAB edge in early turns.\n",
    "    lead_idx_5   = _ensure_col(df, \"lead_matchup_p1_index_5\")\n",
    "    ter_5        = _ensure_col(df, \"ter_p1_vs_p2lead_5\")\n",
    "    stab_diff_5  = _ensure_col(df, \"stab_stab_ratio_diff_w5\")\n",
    "    df[\"feat_lead_matchup_enh\"] = (\n",
    "        lead_idx_5 * ter_5 * (1.0 + stab_diff_5)\n",
    "    )\n",
    "\n",
    "    # 2) Team synergy score (winrate √ó resistances / weaknesses)\n",
    "    team_wr      = _ensure_col(df, \"p1_team_winrate_score\")\n",
    "    uniq_res     = _ensure_col(df, \"p1_unique_resistances\")\n",
    "    weak_mean    = _ensure_col(df, \"p1_weakness_mean\")\n",
    "    df[\"feat_team_synergy\"] = (\n",
    "        team_wr * (1.0 + uniq_res) / (1.0 + weak_mean)\n",
    "    )\n",
    "\n",
    "    # 3) Refined early momentum (HP diff √ó fraction of advantaged turns)\n",
    "    early_hp_diff = _ensure_col(df, \"early_hp_diff_mean_3\")\n",
    "    frac_adv      = _ensure_col(df, \"tl_frac_turns_advantage\")\n",
    "    df[\"feat_early_momentum_refined\"] = early_hp_diff * frac_adv\n",
    "\n",
    "    # 4) Kill pressure index (early power √ó relative power ratio)\n",
    "    mv_p1_pow5    = _ensure_col(df, \"mv_p1_power_mean_5\")\n",
    "    mv_pow_ratio5 = _ensure_col(df, \"mv_power_mean_ratio_5\")\n",
    "    df[\"feat_kill_pressure\"] = mv_p1_pow5 * mv_pow_ratio5\n",
    "\n",
    "    # 5) Switch disadvantage √ó damage trade ‚Üí \"switch pressure score\"\n",
    "    switch_diff   = _ensure_col(df, \"switch_count_diff\")\n",
    "    dmg_ratio     = _ensure_col(df, \"damage_ratio\")\n",
    "    df[\"feat_switch_pressure\"] = switch_diff * dmg_ratio\n",
    "\n",
    "    # Clean up types & infinities for the new columns\n",
    "    new_cols = [\n",
    "        \"feat_lead_matchup_enh\",\n",
    "        \"feat_team_synergy\",\n",
    "        \"feat_early_momentum_refined\",\n",
    "        \"feat_kill_pressure\",\n",
    "        \"feat_switch_pressure\",\n",
    "    ]\n",
    "\n",
    "    for c in new_cols:\n",
    "        if c in df.columns:\n",
    "            s = pd.to_numeric(df[c], errors=\"coerce\").astype(\"float32\")\n",
    "            arr = s.to_numpy()\n",
    "            arr[~np.isfinite(arr)] = 0.0\n",
    "            df[c] = arr\n",
    "\n",
    "    print(f\"[Advanced Top-5] Added 5 features to {name}: {new_cols}\")\n",
    "    return df\n",
    "\n",
    "train_df = add_advanced_top5_features(train_df, name=\"train_df\")\n",
    "test_df  = add_advanced_top5_features(test_df,  name=\"test_df\")\n",
    "# === Extra stack-oriented features (5 new columns) ===\n",
    "# Assumes these columns already exist in train_df / test_df:\n",
    "# final_hp_winner, tl_frac_turns_advantage,\n",
    "# final_status_advantage, damage_trade_ratio_weighted,\n",
    "# ko_advantage, tot_damage_diff,\n",
    "# p1_team_max_winrate, p1_team_min_winrate\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for df, name in [(train_df, \"train_df\"), (test_df, \"test_df\")]:\n",
    "\n",
    "    # 1) Clutch win: vince pur essendo stato spesso in svantaggio\n",
    "    df[\"clutch_win_index\"] = (\n",
    "        df[\"final_hp_winner\"].astype(float)\n",
    "        * (df[\"tl_frac_turns_advantage\"] < 0.4).astype(float)\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "    # 2) Dominant win: vince ed √® stato quasi sempre in vantaggio\n",
    "    df[\"dominant_win_index\"] = (\n",
    "        df[\"final_hp_winner\"].astype(float)\n",
    "        * (df[\"tl_frac_turns_advantage\"] > 0.7).astype(float)\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "    # 3) Status efficiency: quanto bene converte lo status in vantaggio\n",
    "    df[\"status_efficiency\"] = (\n",
    "        df[\"final_status_advantage\"].astype(float)\n",
    "        * df[\"damage_trade_ratio_weighted\"].astype(float)\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "    # 4) KO efficiency: KO advantage ‚Äúnormalizzato‚Äù per il danno totale\n",
    "    denom = 1.0 + df[\"tot_damage_diff\"].abs().astype(float)\n",
    "    df[\"ko_efficiency\"] = (\n",
    "        df[\"ko_advantage\"].astype(float) / denom\n",
    "    )\n",
    "    df[\"ko_efficiency\"].replace([np.inf, -np.inf], 0.0, inplace=True)\n",
    "    df[\"ko_efficiency\"] = df[\"ko_efficiency\"].fillna(0.0).astype(\"float32\")\n",
    "\n",
    "    # 5) Team winrate spread: quanto √® disomogeneo il team (carry vs compagni)\n",
    "    df[\"team_winrate_spread\"] = (\n",
    "        df[\"p1_team_max_winrate\"].astype(float)\n",
    "        - df[\"p1_team_min_winrate\"].astype(float)\n",
    "    ).astype(\"float32\")\n",
    "\n",
    "print(\"[Cell 2] Added 5 extra stack features:\",\n",
    "      [\"clutch_win_index\", \"dominant_win_index\",\n",
    "       \"status_efficiency\", \"ko_efficiency\", \"team_winrate_spread\"])\n",
    "\n",
    "# === Extra XGB-inspired features (added after base feature engineering) ===\n",
    "import numpy as np\n",
    "\n",
    "def _signed_log(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Signed log transform: sign(x) * log1p(|x|)\"\"\"\n",
    "    return np.sign(series) * np.log1p(np.abs(series))\n",
    "\n",
    "for df in (train_df, test_df):\n",
    "    # 1) Signed log of total damage diff\n",
    "    if \"tot_damage_diff\" in df.columns:\n",
    "        df[\"signed_log_tot_damage_diff\"] = _signed_log(df[\"tot_damage_diff\"])\n",
    "    else:\n",
    "        df[\"signed_log_tot_damage_diff\"] = 0.0\n",
    "\n",
    "    # 2) Signed log of KO advantage\n",
    "    if \"ko_advantage\" in df.columns:\n",
    "        df[\"signed_log_ko_advantage\"] = _signed_log(df[\"ko_advantage\"])\n",
    "    else:\n",
    "        df[\"signed_log_ko_advantage\"] = 0.0\n",
    "\n",
    "    # 3) Damage x status advantage\n",
    "    if (\"damage_trade_ratio_weighted\" in df.columns) and (\"final_status_advantage\" in df.columns):\n",
    "        df[\"damage_x_status_adv\"] = df[\"damage_trade_ratio_weighted\"] * (1.0 + df[\"final_status_advantage\"])\n",
    "    else:\n",
    "        df[\"damage_x_status_adv\"] = 0.0\n",
    "\n",
    "    # 4) Damage x pre-battle team winrate\n",
    "    if (\"damage_trade_ratio_weighted\" in df.columns) and (\"p1_team_winrate_score\" in df.columns):\n",
    "        df[\"damage_x_team_winrate\"] = df[\"damage_trade_ratio_weighted\"] * df[\"p1_team_winrate_score\"]\n",
    "    else:\n",
    "        df[\"damage_x_team_winrate\"] = 0.0\n",
    "\n",
    "    # 5) Early pressure index (voluntary leaves first 3 turns + recover diff)\n",
    "    if (\"vol_leave_diff_3\" in df.columns) and (\"recover_count_diff\" in df.columns):\n",
    "        df[\"early_pressure_index\"] = df[\"vol_leave_diff_3\"] + 0.5 * df[\"recover_count_diff\"]\n",
    "    else:\n",
    "        df[\"early_pressure_index\"] = 0.0\n",
    "\n",
    "print(\"\\n[Advanced Top-5] train_df shape:\", train_df.shape)\n",
    "print(\"[Advanced Top-5] test_df  shape:\", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd2a9b",
   "metadata": {
    "_cell_guid": "08ffc5f5-2dcb-437a-9e3a-62dafe9e3e9e",
    "_uuid": "bf65b3bb-827a-47f0-8dd3-f95e03651f9b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009643,
     "end_time": "2025-11-14T21:09:54.009350",
     "exception": false,
     "start_time": "2025-11-14T21:09:53.999707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6898231",
   "metadata": {
    "papermill": {
     "duration": 0.008658,
     "end_time": "2025-11-14T21:09:54.026533",
     "exception": false,
     "start_time": "2025-11-14T21:09:54.017875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.1 - Best Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d79cbc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T21:09:54.044377Z",
     "iopub.status.busy": "2025-11-14T21:09:54.043991Z",
     "iopub.status.idle": "2025-11-14T21:10:10.571892Z",
     "shell.execute_reply": "2025-11-14T21:10:10.570641Z"
    },
    "papermill": {
     "duration": 16.540117,
     "end_time": "2025-11-14T21:10:10.574850",
     "exception": false,
     "start_time": "2025-11-14T21:09:54.034733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] Starting with 256 features.\n",
      "\n",
      "[Pruning][A] Constant features removed (global): 41\n",
      "  -> Constant list (first 50): ['p1_team_size', 'p2_team_size', 'p2_unique_types', 'diff_team_size', 'tl_turns_used', 'tl_p1_status_count', 'tl_p2_status_count', 'tl_status_count', 'hazard_pressure_per_turn', 'hazard_switch_pressure_diff', 'hazard_p1_flag', 'hazard_p2_flag', 'hazard_flag_diff', 'early_status_advantage_3', 'mv_p1_priority_count', 'mv_p2_priority_count', 'mv_priority_count_diff', 'mv_p1_priority_count_5', 'mv_p2_priority_count_5', 'mv_priority_count_diff_5', 'stronger_team', 'battle_length', 'long_battle', 'team_has_type_variety', 'p1_hp_over_50_ratio', 'p2_hp_over_50_ratio', 'is_player1_healthier', 'comeback_difficulty', 'damage_prediction', 'ix_speed_x_prio5', 'ix_early3_x_prio5', 'ix_hazards_x_prio5', 'atk_def_ratio', 'spd_gap', 'hp_ratio', 'survival_score', 'momentum_index', 'offensive_balance', 'defensive_efficiency', 'status_influence', 'speed_ratio']\n",
      "[Pruning][A] After constant pruning: 215 features\n",
      "\n",
      "[Pruning][B] Correlation pruning for LR with |œÅ| > 0.95 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pruning][B] LR correlation-dropped: 56\n",
      "  -> LR correlated list (first 50): ['p1_team_stat_avg', 'p2_team_stat_avg', 'diff_unique_types', 'diff_team_stat_avg', 'p2_lead_stat_sum', 'p2_lead_stat_avg', 'p1_sum_minus_p2_lead_sum', 'p1_avg_minus_p2_lead_avg', 'ratio_p1_avg_over_p2_lead_avg', 'spe_max_adv', 'tl_p1_hp_auc', 'tl_p2_hp_auc', 'lead_spe_p1', 'lead_spe_p2', 'lead_speed_adv', 'has_hard_counter_vs_lead', 'has_soft_counter_vs_lead', 'p1_offense_balance_gap', 'early_hp_difference', 'final_hp_difference', 'team_strength_gap', 'faster_team', 'speed_advantage', 'num_faster_pokemon', 'p1_danger_count', 'p2_danger_count', 'is_p1_higher_avg_hp_after_3_turns', 'avg_hp_difference_after_3_turns', 'is_player1_final_hp_winner', 'p1_low_hp_count', 'p2_low_hp_count', 'is_player1_less_time_in_danger', 'number_different_types', 'turns_in_lead', 'lead_ratio', 'avg_hp_recent_diff', 'final_hp_diff', 'pokemon_remaining_diff', 'max_hp_deficit_player1', 'final_hp_advantage', 'final_hp_ratio', 'final_winning_prob', 'recent_avg_hp_advantage', 'predicted_win_prob', 'pokemon_advantage', 'diversity_ratio', 'avg_weaknesses', 'hp_final_ratio', 'hp_auc_ratio', 'early_momentum_combo']\n",
      "[Pruning][B] After LR correlation pruning: 159 LR features\n",
      "\n",
      "[FS][XGB] Fitting XGBoost for feature importance...\n",
      "[FS][RF ] Fitting RandomForest for feature importance...\n",
      "[FS][LR ] Fitting LogisticRegression for feature importance...\n",
      "\n",
      "[FS] Example top-10 by LR importance:\n",
      "                            feature    lr_imp   xgb_imp    rf_imp\n",
      "78              lead_bulk_index_gap  0.701484  0.002739  0.001351\n",
      "152                p2_team_stat_sum  0.636326  0.003287  0.000476\n",
      "211               used_pokemon_diff  0.527939  0.020339  0.033722\n",
      "146                      p2_lead_hp  0.492466  0.006328  0.000491\n",
      "141                 p2_hp_stability  0.487931  0.003949  0.007481\n",
      "106             num_bad_status_diff  0.462852  0.016754  0.035773\n",
      "46           final_status_advantage  0.461843  0.013051  0.012992\n",
      "32   estimated_pokemon_remaining_p2  0.437510  0.009059  0.011199\n",
      "143                     p2_lead_atk  0.397841  0.003048  0.000500\n",
      "2                     avg_damage_p2  0.316653  0.003361  0.000721\n",
      "\n",
      "[FS] Example top-10 by XGB importance:\n",
      "                         feature    lr_imp   xgb_imp    rf_imp\n",
      "209              tot_damage_diff  0.275270  0.063767  0.053835\n",
      "155            pokemon_advantage  0.000000  0.052509  0.045731\n",
      "47         final_win_probability  0.248066  0.039588  0.059607\n",
      "15           damage_x_status_adv  0.104553  0.036553  0.045098\n",
      "156       pokemon_remaining_diff  0.000000  0.035784  0.049893\n",
      "14   damage_trade_ratio_weighted  0.144699  0.030131  0.048511\n",
      "211            used_pokemon_diff  0.527939  0.020339  0.033722\n",
      "109           outcome_prediction  0.000750  0.016897  0.020840\n",
      "106          num_bad_status_diff  0.462852  0.016754  0.035773\n",
      "69                  ko_advantage  0.248115  0.013324  0.016539\n",
      "\n",
      "[FS] Example top-10 by RF importance:\n",
      "                         feature    lr_imp   xgb_imp    rf_imp\n",
      "47         final_win_probability  0.248066  0.039588  0.059607\n",
      "209              tot_damage_diff  0.275270  0.063767  0.053835\n",
      "168   signed_log_tot_damage_diff  0.000000  0.003836  0.052367\n",
      "156       pokemon_remaining_diff  0.000000  0.035784  0.049893\n",
      "14   damage_trade_ratio_weighted  0.144699  0.030131  0.048511\n",
      "155            pokemon_advantage  0.000000  0.052509  0.045731\n",
      "15           damage_x_status_adv  0.104553  0.036553  0.045098\n",
      "13                  damage_ratio  0.250060  0.010260  0.037229\n",
      "106          num_bad_status_diff  0.462852  0.016754  0.035773\n",
      "211            used_pokemon_diff  0.527939  0.020339  0.033722\n",
      "\n",
      "[FS] Selected for LR  (TOP_K_LR=90): 90 features\n",
      "     First 15 LR cols: ['lead_bulk_index_gap', 'p2_team_stat_sum', 'used_pokemon_diff', 'p2_lead_hp', 'p2_hp_stability', 'num_bad_status_diff', 'final_status_advantage', 'estimated_pokemon_remaining_p2', 'p2_lead_atk', 'avg_damage_p2', 'p2_lead_avg_hp', 'max_speed_ratio', 'p1_hp_stability', 'tot_damage_diff', 'diff_team_stat_sum']\n",
      "\n",
      "[FS] Selected for XGB (TOP_K_XGB=187): 187 features\n",
      "     First 15 XGB cols: ['tot_damage_diff', 'pokemon_advantage', 'final_win_probability', 'damage_x_status_adv', 'pokemon_remaining_diff', 'damage_trade_ratio_weighted', 'used_pokemon_diff', 'outcome_prediction', 'num_bad_status_diff', 'ko_advantage', 'final_status_advantage', 'p1_danger_count', 'tl_p1_ko_count', 'damage_ratio', 'is_player1_less_time_in_danger']\n",
      "\n",
      "[FS] Selected for RF  (TOP_K_RF=160): 160 features\n",
      "     First 15 RF cols: ['final_win_probability', 'tot_damage_diff', 'signed_log_tot_damage_diff', 'pokemon_remaining_diff', 'damage_trade_ratio_weighted', 'pokemon_advantage', 'damage_x_status_adv', 'damage_ratio', 'num_bad_status_diff', 'used_pokemon_diff', 'prediction_confidence', 'ko_efficiency', 'outcome_prediction', 'signed_log_ko_advantage', 'ko_advantage']\n",
      "\n",
      "[FS] Union of all selected cols (LR ‚à™ XGB ‚à™ RF): 198 features\n",
      "[Output] train_reduced shape: (10000, 200)\n",
      "[Output] test_reduced  shape: (5000, 199)\n",
      "[Features] Union selected_cols (198): first 25 -> ['avg_damage_diff', 'avg_damage_p1', 'avg_damage_p2', 'avg_hp_diff_gap', 'avg_hp_difference_after_3_turns', 'avg_hp_recent_diff', 'avg_immunities', 'avg_move_power_difference', 'avg_resistances', 'avg_type_role_ratio', 'avg_weaknesses', 'comeback_happened', 'damage_ratio', 'damage_trade_ratio_weighted', 'damage_x_status_adv', 'damage_x_team_winrate', 'diff_team_stat_avg', 'diff_team_stat_sum', 'diff_unique_types', 'diversity_ratio', 'dominant_win_index', 'early_first_ko_score_3', 'early_game_hp_adv', 'early_hp_diff_mean_3', 'early_hp_difference']\n"
     ]
    }
   ],
   "source": [
    "# === 3.1 Feature pruning (A+B) + per-model Top-K selection (LR, XGB, RF) ===\n",
    "# - A: drop constant features  (GLOBAL: all models)\n",
    "# - B: correlation pruning (|œÅ| > CORR_THRESHOLD) **ONLY for LR features**\n",
    "# - Then:\n",
    "#     * LR : top-K_LR by importance |coef|\n",
    "#     * XGB: top-K_XGB by feature_importances_\n",
    "#     * RF : top-K_RF  by feature_importances_\n",
    "# - Output:\n",
    "#     * selected_cols_lr, selected_cols_xgb, selected_cols_rf\n",
    "#     * train_reduced, test_reduced with the union of all selected columns\n",
    "#     * selected_cols (union) for compatibility with other cells\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "CORR_THRESHOLD = 0.95   # correlation pruning threshold (used ONLY for LR block)\n",
    "\n",
    "TOP_K_LR  = 90          # number of features for LR\n",
    "TOP_K_XGB = 187         # number of features for XGB\n",
    "TOP_K_RF  = 160         # number of features for RF\n",
    "\n",
    "assert \"train_df\" in globals() and \"test_df\" in globals(), \"Run Cell 2 before 3.1.\"\n",
    "\n",
    "TARGET_COL = \"player_won\"\n",
    "ID_COLS = [c for c in [\"battle_id\", \"player_id\"] if c in train_df.columns]\n",
    "\n",
    "feature_cols = [\n",
    "    c for c in train_df.columns\n",
    "    if c not in ID_COLS + [TARGET_COL]\n",
    "]\n",
    "\n",
    "# Base feature matrices (before pruning)\n",
    "X0 = train_df[feature_cols].copy()\n",
    "X0_test = test_df[feature_cols].copy()\n",
    "y = train_df[TARGET_COL].astype(int).values\n",
    "\n",
    "print(f\"[Init] Starting with {X0.shape[1]} features.\")\n",
    "\n",
    "# -----------------------\n",
    "# (A) Constant-feature pruning (GLOBAL, for all models)\n",
    "# -----------------------\n",
    "const_cols = [c for c in X0.columns if X0[c].nunique(dropna=True) <= 1]\n",
    "\n",
    "print(f\"\\n[Pruning][A] Constant features removed (global): {len(const_cols)}\")\n",
    "if const_cols:\n",
    "    print(\"  -> Constant list (first 50):\", const_cols[:50])\n",
    "\n",
    "if const_cols:\n",
    "    X_base = X0.drop(columns=const_cols, errors=\"ignore\")\n",
    "    X_base_test = X0_test.drop(columns=const_cols, errors=\"ignore\")\n",
    "else:\n",
    "    X_base = X0.copy()\n",
    "    X_base_test = X0_test.copy()\n",
    "\n",
    "print(f\"[Pruning][A] After constant pruning: {X_base.shape[1]} features\")\n",
    "\n",
    "# Separate views for each model:\n",
    "# - X_LR  will undergo correlation pruning\n",
    "# - X_XGB and X_RF keep all remaining features (no correlation pruning)\n",
    "X_LR  = X_base.copy()\n",
    "X_XGB = X_base.copy()\n",
    "X_RF  = X_base.copy()\n",
    "\n",
    "# -----------------------\n",
    "# (B) Correlation pruning (|œÅ| > CORR_THRESHOLD) ONLY for LR block\n",
    "# -----------------------\n",
    "print(f\"\\n[Pruning][B] Correlation pruning for LR with |œÅ| > {CORR_THRESHOLD} ...\")\n",
    "\n",
    "num_X_lr = X_LR.select_dtypes(include=[np.number])\n",
    "corr_matrix_lr = num_X_lr.corr().abs()\n",
    "\n",
    "upper_lr = corr_matrix_lr.where(\n",
    "    np.triu(np.ones(corr_matrix_lr.shape), k=1).astype(bool)\n",
    ")\n",
    "\n",
    "to_drop_corr_lr = [\n",
    "    col for col in upper_lr.columns\n",
    "    if any(upper_lr[col] > CORR_THRESHOLD)\n",
    "]\n",
    "\n",
    "print(f\"[Pruning][B] LR correlation-dropped: {len(to_drop_corr_lr)}\")\n",
    "if to_drop_corr_lr:\n",
    "    print(\"  -> LR correlated list (first 50):\", to_drop_corr_lr[:50])\n",
    "    # IMPORTANT: we only drop them for X_LR (LR feature block)\n",
    "    X_LR.drop(columns=to_drop_corr_lr, inplace=True, errors=\"ignore\")\n",
    "\n",
    "print(f\"[Pruning][B] After LR correlation pruning: {X_LR.shape[1]} LR features\")\n",
    "\n",
    "# -----------------------\n",
    "# Data preparation (simple imputation for LR & RF)\n",
    "# -----------------------\n",
    "# XGB natively handles NaN; for LR and RF we impute missing values with the median\n",
    "X_LR_imp = X_LR.fillna(X_LR.median(numeric_only=True))\n",
    "X_RF_imp = X_RF.fillna(X_RF.median(numeric_only=True))\n",
    "\n",
    "# XGB uses the non‚Äìcorrelation-pruned, non-imputed matrix\n",
    "X_XGB_imp = X_XGB\n",
    "\n",
    "# -----------------------\n",
    "# (1) XGBoost feature importance (on X_XGB_imp)\n",
    "# -----------------------\n",
    "print(\"\\n[FS][XGB] Fitting XGBoost for feature importance...\")\n",
    "\n",
    "xgb_fs = xgb.XGBClassifier(\n",
    "    n_estimators=400,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=11,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "xgb_fs.fit(X_XGB_imp, y)\n",
    "xgb_imp_raw = xgb_fs.feature_importances_\n",
    "xgb_imp_dict = {col: imp for col, imp in zip(X_XGB.columns, xgb_imp_raw)}\n",
    "\n",
    "# -----------------------\n",
    "# (2) Random Forest feature importance (on X_RF_imp)\n",
    "# -----------------------\n",
    "print(\"[FS][RF ] Fitting RandomForest for feature importance...\")\n",
    "\n",
    "rf_fs = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=10,\n",
    "    max_features=\"sqrt\",\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=99\n",
    ")\n",
    "rf_fs.fit(X_RF_imp, y)\n",
    "rf_imp_raw = rf_fs.feature_importances_\n",
    "rf_imp_dict = {col: imp for col, imp in zip(X_RF.columns, rf_imp_raw)}\n",
    "\n",
    "# -----------------------\n",
    "# (3) Logistic Regression feature importance (|coef|, on X_LR_imp)\n",
    "# -----------------------\n",
    "print(\"[FS][LR ] Fitting LogisticRegression for feature importance...\")\n",
    "\n",
    "sca = StandardScaler()\n",
    "X_lr_std = sca.fit_transform(X_LR_imp)\n",
    "\n",
    "lr_fs = LogisticRegression(\n",
    "    solver=\"liblinear\",\n",
    "    penalty=\"l2\",\n",
    "    C=0.5,\n",
    "    max_iter=3000,\n",
    "    random_state=13\n",
    ")\n",
    "lr_fs.fit(X_lr_std, y)\n",
    "lr_imp_raw = np.abs(lr_fs.coef_[0])\n",
    "\n",
    "lr_imp_dict = {col: imp for col, imp in zip(X_LR.columns, lr_imp_raw)}\n",
    "\n",
    "# -----------------------\n",
    "# Build importance DataFrame over ALL non-constant features\n",
    "# (LR importance = 0 for features dropped by LR correlation pruning)\n",
    "# -----------------------\n",
    "all_cols_after_A = sorted(X_base.columns)\n",
    "\n",
    "lr_imp_all  = [lr_imp_dict.get(c, 0.0)  for c in all_cols_after_A]\n",
    "xgb_imp_all = [xgb_imp_dict.get(c, 0.0) for c in all_cols_after_A]\n",
    "rf_imp_all  = [rf_imp_dict.get(c, 0.0)  for c in all_cols_after_A]\n",
    "\n",
    "imp_df = pd.DataFrame({\n",
    "    \"feature\": all_cols_after_A,\n",
    "    \"lr_imp\":  lr_imp_all,\n",
    "    \"xgb_imp\": xgb_imp_all,\n",
    "    \"rf_imp\":  rf_imp_all,\n",
    "})\n",
    "\n",
    "imp_df = imp_df.fillna(0.0)\n",
    "\n",
    "print(\"\\n[FS] Example top-10 by LR importance:\")\n",
    "print(imp_df.sort_values(\"lr_imp\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\n[FS] Example top-10 by XGB importance:\")\n",
    "print(imp_df.sort_values(\"xgb_imp\", ascending=False).head(10))\n",
    "\n",
    "print(\"\\n[FS] Example top-10 by RF importance:\")\n",
    "print(imp_df.sort_values(\"rf_imp\", ascending=False).head(10))\n",
    "\n",
    "# -----------------------\n",
    "# Top-K per model\n",
    "# -----------------------\n",
    "def _top_k(feat_df, col_name, k):\n",
    "    k_eff = min(k, len(feat_df))\n",
    "    return feat_df.sort_values(col_name, ascending=False)[\"feature\"].head(k_eff).tolist()\n",
    "\n",
    "selected_cols_lr  = _top_k(imp_df, \"lr_imp\",  TOP_K_LR)\n",
    "selected_cols_xgb = _top_k(imp_df, \"xgb_imp\", TOP_K_XGB)\n",
    "selected_cols_rf  = _top_k(imp_df, \"rf_imp\",  TOP_K_RF)\n",
    "\n",
    "print(f\"\\n[FS] Selected for LR  (TOP_K_LR={TOP_K_LR}): {len(selected_cols_lr)} features\")\n",
    "print(\"     First 15 LR cols:\", selected_cols_lr[:15])\n",
    "\n",
    "print(f\"\\n[FS] Selected for XGB (TOP_K_XGB={TOP_K_XGB}): {len(selected_cols_xgb)} features\")\n",
    "print(\"     First 15 XGB cols:\", selected_cols_xgb[:15])\n",
    "\n",
    "print(f\"\\n[FS] Selected for RF  (TOP_K_RF={TOP_K_RF}): {len(selected_cols_rf)} features\")\n",
    "print(\"     First 15 RF cols:\", selected_cols_rf[:15])\n",
    "\n",
    "# Union of all columns used by at least one model\n",
    "all_cols_union = sorted(set(selected_cols_lr) | set(selected_cols_xgb) | set(selected_cols_rf))\n",
    "\n",
    "print(f\"\\n[FS] Union of all selected cols (LR ‚à™ XGB ‚à™ RF): {len(all_cols_union)} features\")\n",
    "\n",
    "# -----------------------\n",
    "# Build reduced train/test frames\n",
    "# -----------------------\n",
    "train_reduced = pd.concat(\n",
    "    [train_df[ID_COLS + [TARGET_COL]], train_df[all_cols_union]],\n",
    "    axis=1\n",
    ")\n",
    "test_reduced = pd.concat(\n",
    "    [test_df[ID_COLS], test_df[all_cols_union]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# For compatibility with existing code:\n",
    "selected_cols = all_cols_union\n",
    "selected_cols_union = all_cols_union\n",
    "\n",
    "print(f\"[Output] train_reduced shape: {train_reduced.shape}\")\n",
    "print(f\"[Output] test_reduced  shape: {test_reduced.shape}\")\n",
    "print(f\"[Features] Union selected_cols ({len(selected_cols)}): first 25 -> {selected_cols[:25]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64618c3e",
   "metadata": {
    "_cell_guid": "c9df0ffe-ef6c-43d3-925a-f0ccce90af01",
    "_uuid": "a5923783-e209-48a4-b3a5-b3b7a38c48ca",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009005,
     "end_time": "2025-11-14T21:10:10.593970",
     "exception": false,
     "start_time": "2025-11-14T21:10:10.584965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.2 - Stacking (Logistic Regression + XGBoost-> Logistic Regression meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14672753",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T21:10:10.612877Z",
     "iopub.status.busy": "2025-11-14T21:10:10.612502Z",
     "iopub.status.idle": "2025-11-14T21:15:07.674494Z",
     "shell.execute_reply": "2025-11-14T21:15:07.673713Z"
    },
    "papermill": {
     "duration": 297.074091,
     "end_time": "2025-11-14T21:15:07.676397",
     "exception": false,
     "start_time": "2025-11-14T21:10:10.602306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stack LR+XGB+RF‚ÜíLR] Using 90 LR features, 187 XGB features, 160 RF features on 10000 training rows.\n",
      "\n",
      "[Per-fold validation summary]\n",
      "  [Fold  1] LR   acc=0.8260 | AUC=0.8933   ||  XGB  acc=0.8100 | AUC=0.8878 | best_iter=204   ||  RF   acc=0.8000  | AUC=0.8739\n",
      "  [Fold  2] LR   acc=0.8300 | AUC=0.8932   ||  XGB  acc=0.8380 | AUC=0.8946 | best_iter=288   ||  RF   acc=0.8060  | AUC=0.8832\n",
      "  [Fold  3] LR   acc=0.8280 | AUC=0.9008   ||  XGB  acc=0.8280 | AUC=0.8979 | best_iter=252   ||  RF   acc=0.8000  | AUC=0.8800\n",
      "  [Fold  4] LR   acc=0.8400 | AUC=0.9097   ||  XGB  acc=0.8480 | AUC=0.9129 | best_iter=526   ||  RF   acc=0.8320  | AUC=0.9018\n",
      "  [Fold  5] LR   acc=0.8320 | AUC=0.9013   ||  XGB  acc=0.8400 | AUC=0.9054 | best_iter=340   ||  RF   acc=0.8060  | AUC=0.8895\n",
      "  [Fold  6] LR   acc=0.8620 | AUC=0.9247   ||  XGB  acc=0.8440 | AUC=0.9205 | best_iter=437   ||  RF   acc=0.8320  | AUC=0.8974\n",
      "  [Fold  7] LR   acc=0.8420 | AUC=0.9185   ||  XGB  acc=0.8320 | AUC=0.9072 | best_iter=290   ||  RF   acc=0.8040  | AUC=0.8955\n",
      "  [Fold  8] LR   acc=0.8600 | AUC=0.9232   ||  XGB  acc=0.8440 | AUC=0.9190 | best_iter=402   ||  RF   acc=0.8260  | AUC=0.9007\n",
      "  [Fold  9] LR   acc=0.8480 | AUC=0.9255   ||  XGB  acc=0.8480 | AUC=0.9242 | best_iter=404   ||  RF   acc=0.8380  | AUC=0.9113\n",
      "  [Fold 10] LR   acc=0.8440 | AUC=0.9239   ||  XGB  acc=0.8420 | AUC=0.9202 | best_iter=372   ||  RF   acc=0.8340  | AUC=0.9131\n",
      "  [Fold 11] LR   acc=0.8440 | AUC=0.9080   ||  XGB  acc=0.8280 | AUC=0.9055 | best_iter=186   ||  RF   acc=0.8160  | AUC=0.8990\n",
      "  [Fold 12] LR   acc=0.8400 | AUC=0.8939   ||  XGB  acc=0.8220 | AUC=0.8798 | best_iter=179   ||  RF   acc=0.8060  | AUC=0.8724\n",
      "  [Fold 13] LR   acc=0.8420 | AUC=0.9173   ||  XGB  acc=0.8520 | AUC=0.9189 | best_iter=293   ||  RF   acc=0.8400  | AUC=0.9086\n",
      "  [Fold 14] LR   acc=0.8260 | AUC=0.8987   ||  XGB  acc=0.8060 | AUC=0.8957 | best_iter=348   ||  RF   acc=0.8000  | AUC=0.8744\n",
      "  [Fold 15] LR   acc=0.8320 | AUC=0.9060   ||  XGB  acc=0.8240 | AUC=0.9094 | best_iter=352   ||  RF   acc=0.8240  | AUC=0.8902\n",
      "  [Fold 16] LR   acc=0.8320 | AUC=0.9023   ||  XGB  acc=0.8340 | AUC=0.8969 | best_iter=210   ||  RF   acc=0.8160  | AUC=0.8824\n",
      "  [Fold 17] LR   acc=0.8320 | AUC=0.8915   ||  XGB  acc=0.8300 | AUC=0.8942 | best_iter=123   ||  RF   acc=0.8220  | AUC=0.8857\n",
      "  [Fold 18] LR   acc=0.8460 | AUC=0.9119   ||  XGB  acc=0.8540 | AUC=0.9167 | best_iter=195   ||  RF   acc=0.8240  | AUC=0.8988\n",
      "  [Fold 19] LR   acc=0.8420 | AUC=0.9047   ||  XGB  acc=0.8540 | AUC=0.9151 | best_iter=199   ||  RF   acc=0.8380  | AUC=0.9058\n",
      "  [Fold 20] LR   acc=0.8420 | AUC=0.9061   ||  XGB  acc=0.8380 | AUC=0.9072 | best_iter=299   ||  RF   acc=0.8140  | AUC=0.8897\n",
      "\n",
      "[OOF][Meta LR on LR+XGB+RF] Accuracy @ 0.50 = 0.8425\n",
      "[OOF][Meta LR on LR+XGB+RF] ROC-AUC         = 0.9091\n",
      "\n",
      "Ready for 3.3 threshold tuning (variables: oof_meta_scores, meta_test_scores, y)\n"
     ]
    }
   ],
   "source": [
    "# === 3.2 Stacking (LogisticRegression + XGBoost + RandomForest -> LogisticRegression meta) ===\n",
    "# - Ogni base learner usa il proprio set di feature:\n",
    "#       * LR  -> selected_cols_lr  (standardizzato, no calibrazione)\n",
    "#       * XGB -> selected_cols_xgb (early stopping + calibrazione sigmoid)\n",
    "#       * RF  -> selected_cols_rf  (calibrazione sigmoid)\n",
    "# - True OOF stacking su 3 colonne [p_LR, p_XGB, p_RF]\n",
    "# - Meta-learner = LogisticRegression su queste 3 prob\n",
    "# - Espone: oof_meta_scores, meta_test_scores, y\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import xgboost as xgb\n",
    "\n",
    "RANDOM_STATE= 42\n",
    "FOLDS = 20\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# --- Safety checks & matrici -----------------------------------------------\n",
    "assert \"train_reduced\" in globals() and \"test_reduced\" in globals(), \"Run 3.1 before 3.2.\"\n",
    "assert \"selected_cols_lr\"  in globals(), \"Missing 'selected_cols_lr' from 3.1.\"\n",
    "assert \"selected_cols_xgb\" in globals(), \"Missing 'selected_cols_xgb' from 3.1.\"\n",
    "assert \"selected_cols_rf\"  in globals(), \"Missing 'selected_cols_rf' from 3.1.\"\n",
    "\n",
    "y = train_reduced[\"player_won\"].astype(int).to_numpy()\n",
    "\n",
    "X_lr_full  = train_reduced[selected_cols_lr].to_numpy()\n",
    "X_xgb_full = train_reduced[selected_cols_xgb].to_numpy()\n",
    "X_rf_full  = train_reduced[selected_cols_rf].to_numpy()\n",
    "\n",
    "X_lr_test  = test_reduced[selected_cols_lr].to_numpy()\n",
    "X_xgb_test = test_reduced[selected_cols_xgb].to_numpy()\n",
    "X_rf_test  = test_reduced[selected_cols_rf].to_numpy()\n",
    "\n",
    "n_train = X_lr_full.shape[0]\n",
    "n_test  = X_lr_test.shape[0]\n",
    "\n",
    "print(f\"[Stack LR+XGB+RF‚ÜíLR] Using \"\n",
    "      f\"{len(selected_cols_lr)} LR features, \"\n",
    "      f\"{len(selected_cols_xgb)} XGB features, \"\n",
    "      f\"{len(selected_cols_rf)} RF features on {n_train} training rows.\")\n",
    "\n",
    "# --- Base learners config ---------------------------------------------------\n",
    "# LR\n",
    "base_lr_seed = 13\n",
    "\n",
    "# XGB\n",
    "base_xgb_params = dict(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.03,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=11,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\",\n",
    "    early_stopping_rounds=100\n",
    ")\n",
    "\n",
    "# RF\n",
    "base_rf_seed = 99\n",
    "rf_base_params = dict(\n",
    "    n_estimators=400,\n",
    "    max_depth=8,\n",
    "    min_samples_leaf=20,\n",
    "    max_features=\"sqrt\",\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=base_rf_seed\n",
    ")\n",
    "\n",
    "# --- OOF holders (3 base learners) ------------------------------------------\n",
    "n_base_for_meta = 3\n",
    "oof_base = np.zeros((n_train, n_base_for_meta), dtype=float)\n",
    "test_base_folds = np.zeros((n_test, n_base_for_meta, FOLDS), dtype=float)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"\\n[Per-fold validation summary]\")\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_lr_full, y), 1):\n",
    "    X_lr_tr,  X_lr_va  = X_lr_full[tr_idx],  X_lr_full[va_idx]\n",
    "    X_xgb_tr, X_xgb_va = X_xgb_full[tr_idx], X_xgb_full[va_idx]\n",
    "    X_rf_tr,  X_rf_va  = X_rf_full[tr_idx],  X_rf_full[va_idx]\n",
    "    y_tr,     y_va     = y[tr_idx],         y[va_idx]\n",
    "\n",
    "    # ---- Base 1: Logistic Regression (scaled, no calibration) ----\n",
    "    lr_model = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(\n",
    "            solver=\"liblinear\",\n",
    "            penalty=\"l2\",\n",
    "            C=0.5,\n",
    "            max_iter=3000,\n",
    "            random_state=base_lr_seed\n",
    "        )\n",
    "    )\n",
    "    lr_model.fit(X_lr_tr, y_tr)\n",
    "    lr_va = lr_model.predict_proba(X_lr_va)[:, 1]\n",
    "    lr_te = lr_model.predict_proba(X_lr_test)[:, 1]\n",
    "\n",
    "    # ---- Base 2: XGBoost (early stopping) + sigmoid calib on val ----\n",
    "    xgb_model = xgb.XGBClassifier(**base_xgb_params)\n",
    "    xgb_model.fit(\n",
    "        X_xgb_tr, y_tr,\n",
    "        eval_set=[(X_xgb_va, y_va)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        best_it = getattr(xgb_model, \"best_iteration\", None)\n",
    "        if best_it is not None:\n",
    "            xgb_va_raw = xgb_model.predict_proba(\n",
    "                X_xgb_va, iteration_range=(0, best_it + 1)\n",
    "            )[:, 1]\n",
    "            xgb_te_raw = xgb_model.predict_proba(\n",
    "                X_xgb_test, iteration_range=(0, best_it + 1)\n",
    "            )[:, 1]\n",
    "        else:\n",
    "            xgb_va_raw = xgb_model.predict_proba(X_xgb_va)[:, 1]\n",
    "            xgb_te_raw = xgb_model.predict_proba(X_xgb_test)[:, 1]\n",
    "        used_best = best_it\n",
    "    except Exception:\n",
    "        xgb_va_raw = xgb_model.predict_proba(X_xgb_va)[:, 1]\n",
    "        xgb_te_raw = xgb_model.predict_proba(X_xgb_test)[:, 1]\n",
    "        used_best = \"N/A\"\n",
    "\n",
    "    xgb_cal = CalibratedClassifierCV(estimator=xgb_model, method=\"sigmoid\", cv=\"prefit\")\n",
    "    xgb_cal.fit(X_xgb_va, y_va)\n",
    "    xgb_va = xgb_cal.predict_proba(X_xgb_va)[:, 1]\n",
    "    xgb_te = xgb_cal.predict_proba(X_xgb_test)[:, 1]\n",
    "\n",
    "    # ---- Base 3: RandomForest + sigmoid calib on val ----\n",
    "    rf_model = RandomForestClassifier(**rf_base_params)\n",
    "    rf_model.fit(X_rf_tr, y_tr)\n",
    "    rf_cal = CalibratedClassifierCV(estimator=rf_model, method=\"sigmoid\", cv=\"prefit\")\n",
    "    rf_cal.fit(X_rf_va, y_va)\n",
    "    rf_va = rf_cal.predict_proba(X_rf_va)[:, 1]\n",
    "    rf_te = rf_cal.predict_proba(X_rf_test)[:, 1]\n",
    "\n",
    "    # ---- Store OOF & per-fold test probs (LR, XGB, RF) ----\n",
    "    oof_base[va_idx, 0] = lr_va\n",
    "    oof_base[va_idx, 1] = xgb_va\n",
    "    oof_base[va_idx, 2] = rf_va\n",
    "\n",
    "    test_base_folds[:, 0, fold - 1] = lr_te\n",
    "    test_base_folds[:, 1, fold - 1] = xgb_te\n",
    "    test_base_folds[:, 2, fold - 1] = rf_te\n",
    "\n",
    "    # ---- Fold metrics ----\n",
    "    def _rep(p):\n",
    "        acc = accuracy_score(y_va, (p >= 0.5).astype(int))\n",
    "        try:\n",
    "            auc = roc_auc_score(y_va, p)\n",
    "        except Exception:\n",
    "            auc = np.nan\n",
    "        return acc, auc\n",
    "\n",
    "    acc_lr,  auc_lr  = _rep(lr_va)\n",
    "    acc_xgb, auc_xgb = _rep(xgb_va)\n",
    "    acc_rf,  auc_rf  = _rep(rf_va)\n",
    "\n",
    "    print(f\"  [Fold {fold:2d}] \"\n",
    "          f\"LR   acc={acc_lr:.4f} | AUC={auc_lr:.4f}   ||  \"\n",
    "          f\"XGB  acc={acc_xgb:.4f} | AUC={auc_xgb:.4f} | best_iter={used_best}   ||  \"\n",
    "          f\"RF   acc={acc_rf:.4f}  | AUC={auc_rf:.4f}\")\n",
    "\n",
    "# --- Aggregate test probs per base learner ----------------------------------\n",
    "test_base_mean = test_base_folds.mean(axis=2)   # shape: (n_test, 3)\n",
    "\n",
    "# --- Meta-learner su [p_LR, p_XGB, p_RF] -----------------------------------\n",
    "meta_clf = LogisticRegression(\n",
    "    solver=\"lbfgs\",\n",
    "    penalty=\"l2\",\n",
    "    C=0.5,\n",
    "    max_iter=5000,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "oof_meta_scores = np.zeros(n_train, dtype=float)\n",
    "meta_test_folds = np.zeros((n_test, FOLDS), dtype=float)\n",
    "\n",
    "skf_meta = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE + 1)\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf_meta.split(oof_base, y), 1):\n",
    "    X_tr_m, X_va_m = oof_base[tr_idx], oof_base[va_idx]\n",
    "    y_tr_m, y_va_m = y[tr_idx], y[va_idx]\n",
    "\n",
    "    meta_clf_fold = LogisticRegression(\n",
    "        solver=\"lbfgs\",\n",
    "        penalty=\"l2\",\n",
    "        C=1.0,\n",
    "        max_iter=5000,\n",
    "        random_state=RANDOM_STATE + fold\n",
    "    )\n",
    "    meta_clf_fold.fit(X_tr_m, y_tr_m)\n",
    "    oof_meta_scores[va_idx] = meta_clf_fold.predict_proba(X_va_m)[:, 1]\n",
    "    meta_test_folds[:, fold - 1] = meta_clf_fold.predict_proba(test_base_mean)[:, 1]\n",
    "\n",
    "# Fit finale del meta su tutto l'OOF\n",
    "meta_clf.fit(oof_base, y)\n",
    "meta_test_scores = meta_test_folds.mean(axis=1)\n",
    "\n",
    "# --- OOF report del meta predictor -----------------------------------------\n",
    "oof_acc_default = accuracy_score(y, (oof_meta_scores >= 0.50).astype(int))\n",
    "try:\n",
    "    oof_auc = roc_auc_score(y, oof_meta_scores)\n",
    "except Exception:\n",
    "    oof_auc = np.nan\n",
    "\n",
    "print(\"\\n[OOF][Meta LR on LR+XGB+RF] Accuracy @ 0.50 = {:.4f}\".format(oof_acc_default))\n",
    "print(\"[OOF][Meta LR on LR+XGB+RF] ROC-AUC         = {:.4f}\".format(oof_auc))\n",
    "print(\"\\nReady for 3.3 threshold tuning (variables: oof_meta_scores, meta_test_scores, y)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09167303",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T21:15:07.711891Z",
     "iopub.status.busy": "2025-11-14T21:15:07.711507Z",
     "iopub.status.idle": "2025-11-14T21:15:09.398538Z",
     "shell.execute_reply": "2025-11-14T21:15:09.397721Z"
    },
    "papermill": {
     "duration": 1.706212,
     "end_time": "2025-11-14T21:15:09.400489",
     "exception": false,
     "start_time": "2025-11-14T21:15:07.694277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta-search] Exploring LogisticRegression(C, random_state) on meta level...\n",
      "\n",
      "[Meta-search] Top 5 configurations:\n",
      "  rs3_C0.5 -> ACC=0.8431 | AUC=0.9095\n",
      "  rs5_C0.5 -> ACC=0.8431 | AUC=0.9095\n",
      "  rs7_C0.5 -> ACC=0.8431 | AUC=0.9095\n",
      "  rs11_C0.5 -> ACC=0.8431 | AUC=0.9095\n",
      "  rs17_C0.5 -> ACC=0.8431 | AUC=0.9095\n",
      "\n",
      "[Meta-search] Selected best meta config: rs3_C0.5 (ACC=0.8431, AUC=0.9095)\n",
      "\n",
      "[Meta-search] Updated 'oof_meta_scores' and 'meta_test_scores' with best meta config.\n",
      "You can now re-run 3.3 for threshold tuning using the improved meta predictions.\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# 3.2-meta-extra ‚Äî Meta-learner mini search (C & random_state)\n",
    "# ====================================\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "assert \"oof_base\" in globals(), \"Need 'oof_base' from 3.2.\"\n",
    "assert \"y\" in globals(), \"Need 'y' labels.\"\n",
    "assert \"test_base_mean\" in globals(), \"Need 'test_base_mean' from 3.2.\"\n",
    "\n",
    "X_meta = np.asarray(oof_base, dtype=float)        # shape (n_train, n_base)\n",
    "X_meta_test = np.asarray(test_base_mean, dtype=float)  # shape (n_test, n_base)\n",
    "y_meta = np.asarray(y, dtype=int)\n",
    "\n",
    "META_RANDOM_STATES = [3, 5, 7, 11, 17]\n",
    "META_C_VALUES      = [0.5, 1.0, 1.5, 2.0]\n",
    "\n",
    "results = []\n",
    "meta_test_candidates = {}\n",
    "meta_oof_candidates  = {}\n",
    "\n",
    "print(\"[Meta-search] Exploring LogisticRegression(C, random_state) on meta level...\")\n",
    "\n",
    "for rs in META_RANDOM_STATES:\n",
    "    for C in META_C_VALUES:\n",
    "        key = f\"rs{rs}_C{C}\"\n",
    "        clf = LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            penalty=\"l2\",\n",
    "            C=C,\n",
    "            max_iter=5000,\n",
    "            random_state=rs,\n",
    "        )\n",
    "        clf.fit(X_meta, y_meta)\n",
    "        oof_pred = clf.predict_proba(X_meta)[:, 1]\n",
    "        try:\n",
    "            auc = roc_auc_score(y_meta, oof_pred)\n",
    "        except Exception:\n",
    "            auc = np.nan\n",
    "        acc = accuracy_score(y_meta, (oof_pred >= 0.5).astype(int))\n",
    "\n",
    "        results.append((key, acc, auc))\n",
    "        meta_test_candidates[key] = clf.predict_proba(X_meta_test)[:, 1]\n",
    "        meta_oof_candidates[key]  = oof_pred\n",
    "\n",
    "# Rank by AUC, then Accuracy\n",
    "results_sorted = sorted(results, key=lambda x: (x[2], x[1]), reverse=True)\n",
    "\n",
    "print(\"\\n[Meta-search] Top 5 configurations:\")\n",
    "for r in results_sorted[:5]:\n",
    "    print(f\"  {r[0]} -> ACC={r[1]:.4f} | AUC={r[2]:.4f}\")\n",
    "\n",
    "best_key, best_acc, best_auc = results_sorted[0]\n",
    "print(f\"\\n[Meta-search] Selected best meta config: {best_key} (ACC={best_acc:.4f}, AUC={best_auc:.4f})\")\n",
    "\n",
    "# Override global meta scores with best configuration\n",
    "oof_meta_scores = meta_oof_candidates[best_key]\n",
    "meta_test_scores = meta_test_candidates[best_key]\n",
    "\n",
    "print(\"\\n[Meta-search] Updated 'oof_meta_scores' and 'meta_test_scores' with best meta config.\")\n",
    "print(\"You can now re-run 3.3 for threshold tuning using the improved meta predictions.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d2e60d",
   "metadata": {
    "_cell_guid": "ff38c3fc-7871-4c84-a702-d12a57e52704",
    "_uuid": "bdd6313f-2062-42fa-b307-393d08e9a535",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015121,
     "end_time": "2025-11-14T21:15:09.434309",
     "exception": false,
     "start_time": "2025-11-14T21:15:09.419188",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.3 - Threshold tuning for the StackingClassifier (uses OOF probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60770a1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-14T21:15:09.467743Z",
     "iopub.status.busy": "2025-11-14T21:15:09.466542Z",
     "iopub.status.idle": "2025-11-14T21:15:15.175845Z",
     "shell.execute_reply": "2025-11-14T21:15:15.174523Z"
    },
    "papermill": {
     "duration": 5.727687,
     "end_time": "2025-11-14T21:15:15.177768",
     "exception": false,
     "start_time": "2025-11-14T21:15:09.450081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.3] Threshold tuning on 10000 OOF samples.\n",
      "\n",
      "[3.3] Best by Accuracy:\n",
      "threshold    0.501000\n",
      "accuracy     0.843200\n",
      "f1           0.843043\n",
      "mcc          0.686401\n",
      "auc          0.909503\n",
      "logloss      0.387447\n",
      "Name: 201, dtype: float64\n",
      "\n",
      "[3.3] Best by F1:\n",
      "threshold    0.442000\n",
      "accuracy     0.841300\n",
      "f1           0.843476\n",
      "mcc          0.682864\n",
      "auc          0.909503\n",
      "logloss      0.387447\n",
      "Name: 142, dtype: float64\n",
      "\n",
      "[3.3] Best by MCC:\n",
      "threshold    0.503000\n",
      "accuracy     0.843200\n",
      "f1           0.842949\n",
      "mcc          0.686404\n",
      "auc          0.909503\n",
      "logloss      0.387447\n",
      "Name: 203, dtype: float64\n",
      "\n",
      "[3.3] Selected operating threshold = 0.5030\n",
      "\n",
      "[3.3] Final OOF metrics at selected threshold:\n",
      "  Accuracy = 0.8432\n",
      "  F1       = 0.8429\n",
      "  MCC      = 0.6864\n",
      "  AUC      = 0.9095\n",
      "\n",
      "[3.3] Submission preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won\n",
       "0          0           0\n",
       "1          1           1\n",
       "2          2           1\n",
       "3          3           1\n",
       "4          4           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ====================================\n",
    "# 3.3 ‚Äî Advanced Threshold Tuning\n",
    "# ====================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    "    log_loss,\n",
    ")\n",
    "\n",
    "assert \"oof_meta_scores\" in globals(), \"Run 3.2 first to get 'oof_meta_scores'.\"\n",
    "assert \"meta_test_scores\" in globals(), \"Run 3.2 first to get 'meta_test_scores'.\"\n",
    "assert \"y\" in globals(), \"Need training labels 'y'.\"\n",
    "assert \"test_df\" in globals(), \"Need 'test_df' with 'battle_id'.\"\n",
    "\n",
    "oof_probs = np.asarray(oof_meta_scores, dtype=float)\n",
    "test_probs = np.asarray(meta_test_scores, dtype=float)\n",
    "y_true = np.asarray(y, dtype=int)\n",
    "\n",
    "print(f\"[3.3] Threshold tuning on {len(y_true)} OOF samples.\")\n",
    "\n",
    "# --- Scan thresholds ---\n",
    "thr_values = np.linspace(0.30, 0.70, 401)  # step ~0.001\n",
    "rows = []\n",
    "\n",
    "for thr in thr_values:\n",
    "    pred = (oof_probs >= thr).astype(int)\n",
    "    acc = accuracy_score(y_true, pred)\n",
    "    f1  = f1_score(y_true, pred)\n",
    "    mcc = matthews_corrcoef(y_true, pred)\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, oof_probs)\n",
    "    except Exception:\n",
    "        auc = np.nan\n",
    "    ll  = log_loss(y_true, np.clip(oof_probs, 1e-6, 1-1e-6))\n",
    "    rows.append((thr, acc, f1, mcc, auc, ll))\n",
    "\n",
    "thr_df = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\"threshold\", \"accuracy\", \"f1\", \"mcc\", \"auc\", \"logloss\"]\n",
    ")\n",
    "\n",
    "# --- Pick best thresholds according to different metrics ---\n",
    "best_acc_row = thr_df.iloc[thr_df[\"accuracy\"].idxmax()]\n",
    "best_f1_row  = thr_df.iloc[thr_df[\"f1\"].idxmax()]\n",
    "best_mcc_row = thr_df.iloc[thr_df[\"mcc\"].idxmax()]\n",
    "\n",
    "print(\"\\n[3.3] Best by Accuracy:\")\n",
    "print(best_acc_row)\n",
    "\n",
    "print(\"\\n[3.3] Best by F1:\")\n",
    "print(best_f1_row)\n",
    "\n",
    "print(\"\\n[3.3] Best by MCC:\")\n",
    "print(best_mcc_row)\n",
    "\n",
    "# --- Main operating threshold: prefer Accuracy, break ties by F1 then MCC ---\n",
    "best_row = best_acc_row.copy()\n",
    "\n",
    "# If F1-optimal threshold has same accuracy within 1e-4 but better F1, take that\n",
    "if abs(best_f1_row[\"accuracy\"] - best_row[\"accuracy\"]) < 1e-4 and best_f1_row[\"f1\"] > best_row[\"f1\"]:\n",
    "    best_row = best_f1_row\n",
    "\n",
    "# Similarly check MCC if still tied\n",
    "if abs(best_mcc_row[\"accuracy\"] - best_row[\"accuracy\"]) < 1e-4 and best_mcc_row[\"mcc\"] > best_row[\"mcc\"]:\n",
    "    best_row = best_mcc_row\n",
    "\n",
    "best_threshold = float(best_row[\"threshold\"])\n",
    "print(f\"\\n[3.3] Selected operating threshold = {best_threshold:.4f}\")\n",
    "\n",
    "# --- Final OOF report at selected threshold ---\n",
    "final_pred_oof = (oof_probs >= best_threshold).astype(int)\n",
    "final_acc = accuracy_score(y_true, final_pred_oof)\n",
    "final_f1  = f1_score(y_true, final_pred_oof)\n",
    "final_mcc = matthews_corrcoef(y_true, final_pred_oof)\n",
    "try:\n",
    "    final_auc = roc_auc_score(y_true, oof_probs)\n",
    "except Exception:\n",
    "    final_auc = np.nan\n",
    "\n",
    "print(\"\\n[3.3] Final OOF metrics at selected threshold:\")\n",
    "print(f\"  Accuracy = {final_acc:.4f}\")\n",
    "print(f\"  F1       = {final_f1:.4f}\")\n",
    "print(f\"  MCC      = {final_mcc:.4f}\")\n",
    "print(f\"  AUC      = {final_auc:.4f}\")\n",
    "\n",
    "# --- Build submission using selected threshold ---\n",
    "test_pred_labels = (test_probs >= best_threshold).astype(int)\n",
    "\n",
    "# Alias for compatibility with Cell 4 (which expects 'stack_pred_labels_tuned')\n",
    "stack_pred_labels_tuned = test_pred_labels\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"battle_id\": test_df[\"battle_id\"].values,\n",
    "    \"player_won\": test_pred_labels,\n",
    "})\n",
    "\n",
    "print(\"\\n[3.3] Submission preview:\")\n",
    "display(submission.head())\n",
    "\n",
    "# Keep submission & best threshold for later\n",
    "stacking_best_threshold = best_threshold\n",
    "stacking_submission = submission.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb539966",
   "metadata": {
    "_cell_guid": "fe1e5039-65ab-41a2-b17e-d0b74be840f8",
    "_uuid": "fc400151-e3d6-481e-87dc-6e23ec10bb0b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010251,
     "end_time": "2025-11-14T21:15:15.197863",
     "exception": false,
     "start_time": "2025-11-14T21:15:15.187612",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Creating the Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b88bf655",
   "metadata": {
    "_cell_guid": "2a35849f-8198-4a64-9eb1-25bffb277291",
    "_uuid": "536ccc01-19ab-4d61-b21b-d403562a08dc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-14T21:15:15.221715Z",
     "iopub.status.busy": "2025-11-14T21:15:15.220612Z",
     "iopub.status.idle": "2025-11-14T21:15:15.258118Z",
     "shell.execute_reply": "2025-11-14T21:15:15.257264Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.050284,
     "end_time": "2025-11-14T21:15:15.259633",
     "exception": false,
     "start_time": "2025-11-14T21:15:15.209349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Using threshold = 0.5030 for final submission.\n",
      "[4] Submission file 'submission.csv' created.\n",
      "[4] Submission shape: (5000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won\n",
       "0          0           0\n",
       "1          1           1\n",
       "2          2           1\n",
       "3          3           1\n",
       "4          4           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 4. Build and save final submission ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Safety checks ---\n",
    "if \"meta_test_scores\" not in globals():\n",
    "    raise RuntimeError(\"Missing 'meta_test_scores'. Run Cells 3.2 and 3.3 first.\")\n",
    "\n",
    "if \"test_df\" not in globals() or \"battle_id\" not in test_df.columns:\n",
    "    raise RuntimeError(\"Missing 'test_df' with 'battle_id' column.\")\n",
    "\n",
    "# Prefer the name set in 3.3, otherwise fall back to best_threshold\n",
    "if \"stacking_best_threshold\" in globals():\n",
    "    thr = float(stacking_best_threshold)\n",
    "elif \"best_threshold\" in globals():\n",
    "    thr = float(best_threshold)\n",
    "else:\n",
    "    raise RuntimeError(\"Missing best threshold. Run Cell 3.3 (advanced threshold tuning) first.\")\n",
    "\n",
    "print(f\"[4] Using threshold = {thr:.4f} for final submission.\")\n",
    "\n",
    "# --- Convert test probabilities to labels ---\n",
    "test_probs = np.asarray(meta_test_scores, dtype=float)\n",
    "stack_pred_labels_tuned = (test_probs >= thr).astype(int)\n",
    "\n",
    "# --- Build submission DataFrame ---\n",
    "submission = pd.DataFrame({\n",
    "    \"battle_id\": test_df[\"battle_id\"].values,\n",
    "    \"player_won\": stack_pred_labels_tuned,\n",
    "})\n",
    "\n",
    "# Save to CSV for Kaggle\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"[4] Submission file 'submission.csv' created.\")\n",
    "print(\"[4] Submission shape:\", submission.shape)\n",
    "display(submission.head())\n",
    "\n",
    "# Keep handy in memory\n",
    "stacking_submission = submission.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94b7d6",
   "metadata": {
    "_cell_guid": "cd0077c1-c58f-4486-86d3-b2b38ecc0f55",
    "_uuid": "06a20782-709c-467d-b15a-c98f0653a2af",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.009746,
     "end_time": "2025-11-14T21:15:15.280614",
     "exception": false,
     "start_time": "2025-11-14T21:15:15.270868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5. Submitting Your Results\n",
    "\n",
    "Once you have generated your `submission.csv` file, there are two primary ways to submit it to the competition.\n",
    "\n",
    "---\n",
    "\n",
    "#### Method A: Submitting Directly from the Notebook\n",
    "\n",
    "This is the standard method for code competitions. It ensures that your submission is linked to the code that produced it, which is crucial for reproducibility.\n",
    "\n",
    "1.  **Save Your Work:** Click the **\"Save Version\"** button in the top-right corner of the notebook editor.\n",
    "2.  **Run the Notebook:** In the pop-up window, select **\"Save & Run All (Commit)\"** and then click the **\"Save\"** button. This will run your entire notebook from top to bottom and save the output, including your `submission.csv` file.\n",
    "3.  **Go to the Viewer:** Once the save process is complete, navigate to the notebook viewer page. \n",
    "4.  **Submit to Competition:** In the viewer, find the **\"Submit to Competition\"** section. This is usually located in the header of the output section or in the vertical \"...\" menu on the right side of the page. Clicking the **Submit** button this will submit your generated `submission.csv` file.\n",
    "\n",
    "After submitting, you will see your score in the **\"Submit to Competition\"** section or in the [Public Leaderboard](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?).\n",
    "\n",
    "---\n",
    "\n",
    "#### Method B: Manual Upload\n",
    "\n",
    "You can also generate your predictions and submission file using any environment you prefer (this notebook, Google Colab, or your local machine).\n",
    "\n",
    "1.  **Generate the `submission.csv` file** using your model.\n",
    "2.  **Download the file** to your computer.\n",
    "3.  **Navigate to the [Leaderboard Page](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?)** and click on the **\"Submit Predictions\"** button.\n",
    "4.  **Upload Your File:** Drag and drop or select your `submission.csv` file to upload it.\n",
    "\n",
    "This method is quick, but keep in mind that for the final evaluation, you might be required to provide the code that generated your submission.\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13033998,
     "sourceId": 107555,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 403.560935,
   "end_time": "2025-11-14T21:15:17.720469",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-14T21:08:34.159534",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00b7f9795d2d4f59a486ece2066be948": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8d4a92f0bb4443c7bfa0eb1f3dcd9d2b",
        "IPY_MODEL_6b9c684ccaae4738bd545e14a3ce6b88",
        "IPY_MODEL_471276703b6c4ce484d0ae0a93a4911c"
       ],
       "layout": "IPY_MODEL_d8f8211d03cd4879ae71356f3a168c4c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "02ea13f17b03457e9ebae1c0f6d8c152": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a0fdc098dfc408db00a869465192ebf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2424ded8ee2144dca41e24a77d95d21b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2d683815b253432d860b8f9eecf5f1b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "471276703b6c4ce484d0ae0a93a4911c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_02ea13f17b03457e9ebae1c0f6d8c152",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ee63b042d3c84cbfa692ed8eb003e42f",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá10000/10000‚Äá[00:36&lt;00:00,‚Äá297.26it/s]"
      }
     },
     "49d9be9c19a94146a08ad0c489d59bd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b283a525c38946a0b562662beb3c6b2f",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_bf1e44ea318c40599063961a382900a9",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá5000/5000‚Äá[00:18&lt;00:00,‚Äá244.24it/s]"
      }
     },
     "4aa3972ba763411d979aa1138db53473": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5a0a82d0ff884d05a158ea661cac3540": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5da1127082f8440db10e79ff716231f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ae01cf3ab9774cc88aeb7e6f8b03f146",
        "IPY_MODEL_b766c43e9bc349f186528aba1e7f0d25",
        "IPY_MODEL_49d9be9c19a94146a08ad0c489d59bd9"
       ],
       "layout": "IPY_MODEL_5a0a82d0ff884d05a158ea661cac3540",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6b9c684ccaae4738bd545e14a3ce6b88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d683815b253432d860b8f9eecf5f1b0",
       "max": 10000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4aa3972ba763411d979aa1138db53473",
       "tabbable": null,
       "tooltip": null,
       "value": 10000
      }
     },
     "6ca31914d42c4c28b9fb780381126a80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8d4a92f0bb4443c7bfa0eb1f3dcd9d2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2424ded8ee2144dca41e24a77d95d21b",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_0a0fdc098dfc408db00a869465192ebf",
       "tabbable": null,
       "tooltip": null,
       "value": "Extracting‚Äáfeatures:‚Äá100%"
      }
     },
     "ad13c9bc9f2d447bb86ee92b810eb3ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ae01cf3ab9774cc88aeb7e6f8b03f146": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bb498a4cab424bba9dc194514ceb2825",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_ad13c9bc9f2d447bb86ee92b810eb3ac",
       "tabbable": null,
       "tooltip": null,
       "value": "Extracting‚Äáfeatures:‚Äá100%"
      }
     },
     "b283a525c38946a0b562662beb3c6b2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b766c43e9bc349f186528aba1e7f0d25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e0ed2eff6735480895f82a81082acc4b",
       "max": 5000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6ca31914d42c4c28b9fb780381126a80",
       "tabbable": null,
       "tooltip": null,
       "value": 5000
      }
     },
     "bb498a4cab424bba9dc194514ceb2825": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf1e44ea318c40599063961a382900a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d8f8211d03cd4879ae71356f3a168c4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0ed2eff6735480895f82a81082acc4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee63b042d3c84cbfa692ed8eb003e42f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
