{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78c269b5",
   "metadata": {
    "_cell_guid": "9cf7fcc7-f8d3-4f9a-9128-f94e5a717ff3",
    "_uuid": "00713b04-49ef-4f25-9036-4177259b53e4",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.00847,
     "end_time": "2025-11-12T23:28:47.096127",
     "exception": false,
     "start_time": "2025-11-12T23:28:47.087657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# FDS Challenge\n",
    "\n",
    "This notebook will guide you through the first steps of the competition. Our goal here is to show you how to:\n",
    "\n",
    "1.  Load the `train.jsonl` and `test.jsonl` files from the competition data.\n",
    "2.  Create a very simple set of features from the data.\n",
    "3.  Train a basic model.\n",
    "4.  Generate a `submission.csv` file in the correct format.\n",
    "5.  Submit your results.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3a3ba9",
   "metadata": {
    "_cell_guid": "b7c3e856-84d8-4080-97ee-7570902defbc",
    "_uuid": "30695d23-3c14-4ded-ac54-0da74eab1161",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.006409,
     "end_time": "2025-11-12T23:28:47.109357",
     "exception": false,
     "start_time": "2025-11-12T23:28:47.102948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Loading and Inspecting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a46b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Define the path to our data ---\n",
    "COMPETITION_NAME = 'fds-pokemon-battles-prediction-2025'\n",
    "DATA_PATH = os.path.join('../input', COMPETITION_NAME)\n",
    "train_file_path = \"/kaggle/input/fds-pokemon-battles-prediction-2025/train.jsonl\"\n",
    "test_file_path = \"/kaggle/input/fds-pokemon-battles-prediction-2025/train.jsonl\"\n",
    "\n",
    "train_data = []\n",
    "test_data  = []\n",
    "\n",
    "# --- Load TRAIN data ---\n",
    "print(f\"üì¶ Loading data from '{train_file_path}'...\")\n",
    "try:\n",
    "    with open(train_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            train_data.append(json.loads(line))\n",
    "    print(f\"‚úÖ Successfully loaded {len(train_data)} battles from train.\")\n",
    "    \n",
    "    # Show structure of first train battle\n",
    "    if train_data:\n",
    "        print(\"\\n--- Structure of the first train battle: ---\")\n",
    "        first_battle = train_data[0]\n",
    "        battle_for_display = first_battle.copy()\n",
    "        battle_for_display['battle_timeline'] = first_battle.get('battle_timeline', [])[:2]\n",
    "        print(json.dumps(battle_for_display, indent=4))\n",
    "        if len(first_battle.get('battle_timeline', [])) > 3:\n",
    "            print(\"    ...\")\n",
    "            print(\"    (battle_timeline has been truncated for display)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: Could not find the training file at '{train_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")\n",
    "\n",
    "\n",
    "# --- Load TEST data ---\n",
    "print(f\"\\nüì¶ Loading data from '{test_file_path}'...\")\n",
    "try:\n",
    "    with open(test_file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            test_data.append(json.loads(line))\n",
    "    print(f\"‚úÖ Successfully loaded {len(test_data)} battles from test.\")\n",
    "    \n",
    "    if test_data:\n",
    "        print(\"\\n--- Structure of the first test battle: ---\")\n",
    "        first_test_battle = test_data[0]\n",
    "        test_display = first_test_battle.copy()\n",
    "        test_display['battle_timeline'] = test_display.get('battle_timeline', [])[:2]\n",
    "        print(json.dumps(test_display, indent=4))\n",
    "        if len(first_test_battle.get('battle_timeline', [])) > 3:\n",
    "            print(\"    ...\")\n",
    "            print(\"    (battle_timeline has been truncated for display)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå ERROR: Could not find the test file at '{test_file_path}'.\")\n",
    "    print(\"Please make sure you have added the competition data to this notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7488f5",
   "metadata": {
    "_cell_guid": "0e496703-c5aa-4a03-8262-f8f9c1d2f386",
    "_uuid": "3a8ee9c9-3a1f-441a-9c71-6bd1445de82f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.007253,
     "end_time": "2025-11-12T23:28:56.263987",
     "exception": false,
     "start_time": "2025-11-12T23:28:56.256734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ab667e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T23:28:56.285407Z",
     "iopub.status.busy": "2025-11-12T23:28:56.284979Z",
     "iopub.status.idle": "2025-11-12T23:29:46.525440Z",
     "shell.execute_reply": "2025-11-12T23:29:46.524499Z"
    },
    "papermill": {
     "duration": 50.256159,
     "end_time": "2025-11-12T23:29:46.526981",
     "exception": false,
     "start_time": "2025-11-12T23:28:56.270822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ebe75b34b24dafa2e3a5550fb51824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48642f33b7b54ff0a4c01435b9b8a68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training features preview:\n",
      "[Sanity] Near-constant features (not dropping yet): 117\n",
      "[FeatureEng] Added 10 engineered features. Bad values -> train: 0, test: 0\n",
      "\n",
      "Preview (raw):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/1206161880.py:1303: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[name] = _ensure_float32(train_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1304: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[name]  = _ensure_float32(test_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1303: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[name] = _ensure_float32(train_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1304: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[name]  = _ensure_float32(test_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1303: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[name] = _ensure_float32(train_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1304: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[name]  = _ensure_float32(test_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1303: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[name] = _ensure_float32(train_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1304: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[name]  = _ensure_float32(test_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1303: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[name] = _ensure_float32(train_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1304: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[name]  = _ensure_float32(test_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1303: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[name] = _ensure_float32(train_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1304: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[name]  = _ensure_float32(test_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1303: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[name] = _ensure_float32(train_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1304: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[name]  = _ensure_float32(test_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1303: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[name] = _ensure_float32(train_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1304: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[name]  = _ensure_float32(test_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1303: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[name] = _ensure_float32(train_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1304: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[name]  = _ensure_float32(test_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1303: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[name] = _ensure_float32(train_series)\n",
      "/tmp/ipykernel_13/1206161880.py:1304: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[name]  = _ensure_float32(test_series)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_team_size</th>\n",
       "      <th>p2_team_size</th>\n",
       "      <th>p1_unique_types</th>\n",
       "      <th>p2_unique_types</th>\n",
       "      <th>p1_team_stat_sum</th>\n",
       "      <th>p2_team_stat_sum</th>\n",
       "      <th>p1_team_stat_avg</th>\n",
       "      <th>p2_team_stat_avg</th>\n",
       "      <th>diff_team_size</th>\n",
       "      <th>diff_unique_types</th>\n",
       "      <th>...</th>\n",
       "      <th>damage_prediction</th>\n",
       "      <th>ix_p1avg_x_p1pow</th>\n",
       "      <th>ix_speed_x_prio5</th>\n",
       "      <th>ix_hpmean_x_fracadv</th>\n",
       "      <th>ix_early3_x_prio5</th>\n",
       "      <th>ix_stabdiff_x_firstko</th>\n",
       "      <th>ix_ter_x_stab_full</th>\n",
       "      <th>ix_ter5_x_early3</th>\n",
       "      <th>ix_leadmatch5_x_early3</th>\n",
       "      <th>ix_hazards_x_prio5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3190.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>88.611111</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5103.343621</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012237</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768176</td>\n",
       "      <td>-0.234097</td>\n",
       "      <td>-18.532655</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>83.888889</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7353.043478</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.030833</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737240</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-24.000089</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3155.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>87.638889</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3086.836420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.422497</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>19.671460</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>91.250000</td>\n",
       "      <td>86.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6169.293478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.025778</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.391304</td>\n",
       "      <td>0.391304</td>\n",
       "      <td>-0.806667</td>\n",
       "      <td>-111.872196</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>89.444444</td>\n",
       "      <td>89.166667</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3127.115385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013289</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248521</td>\n",
       "      <td>-0.186000</td>\n",
       "      <td>-0.092190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1_team_size  p2_team_size  p1_unique_types  p2_unique_types  \\\n",
       "0             6             1                5                2   \n",
       "1             6             1                6                2   \n",
       "2             6             1                8                2   \n",
       "3             6             1                8                2   \n",
       "4             6             1                6                2   \n",
       "\n",
       "   p1_team_stat_sum  p2_team_stat_sum  p1_team_stat_avg  p2_team_stat_avg  \\\n",
       "0            3190.0             535.0         88.611111         89.166667   \n",
       "1            3020.0             540.0         83.888889         90.000000   \n",
       "2            3155.0             520.0         87.638889         86.666667   \n",
       "3            3285.0             520.0         91.250000         86.666667   \n",
       "4            3220.0             535.0         89.444444         89.166667   \n",
       "\n",
       "   diff_team_size  diff_unique_types  ...  damage_prediction  \\\n",
       "0               5                  3  ...                1.0   \n",
       "1               5                  4  ...                1.0   \n",
       "2               5                  6  ...                1.0   \n",
       "3               5                  6  ...                1.0   \n",
       "4               5                  4  ...                1.0   \n",
       "\n",
       "   ix_p1avg_x_p1pow  ix_speed_x_prio5  ix_hpmean_x_fracadv  ix_early3_x_prio5  \\\n",
       "0       5103.343621               0.0            -0.012237               -0.0   \n",
       "1       7353.043478              -0.0            -0.030833               -0.0   \n",
       "2       3086.836420               0.0             0.021089                0.0   \n",
       "3       6169.293478               0.0            -0.025778               -0.0   \n",
       "4       3127.115385               0.0             0.013289               -0.0   \n",
       "\n",
       "   ix_stabdiff_x_firstko  ix_ter_x_stab_full  ix_ter5_x_early3  \\\n",
       "0               0.000000            0.768176         -0.234097   \n",
       "1               0.000000            0.737240         -0.200000   \n",
       "2               0.000000            0.422497          0.170000   \n",
       "3              -0.391304            0.391304         -0.806667   \n",
       "4               0.000000            0.248521         -0.186000   \n",
       "\n",
       "   ix_leadmatch5_x_early3  ix_hazards_x_prio5  \n",
       "0              -18.532655                 0.0  \n",
       "1              -24.000089                 0.0  \n",
       "2               19.671460                 0.0  \n",
       "3             -111.872196                 0.0  \n",
       "4               -0.092190                 0.0  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prepared (unscaled, clean types):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1_team_size</th>\n",
       "      <th>p2_team_size</th>\n",
       "      <th>p1_unique_types</th>\n",
       "      <th>p2_unique_types</th>\n",
       "      <th>p1_team_stat_sum</th>\n",
       "      <th>p2_team_stat_sum</th>\n",
       "      <th>p1_team_stat_avg</th>\n",
       "      <th>p2_team_stat_avg</th>\n",
       "      <th>diff_team_size</th>\n",
       "      <th>diff_unique_types</th>\n",
       "      <th>...</th>\n",
       "      <th>atk_def_ratio</th>\n",
       "      <th>spd_gap</th>\n",
       "      <th>hp_ratio</th>\n",
       "      <th>survival_score</th>\n",
       "      <th>momentum_index</th>\n",
       "      <th>power_acc_gap</th>\n",
       "      <th>offensive_balance</th>\n",
       "      <th>defensive_efficiency</th>\n",
       "      <th>status_influence</th>\n",
       "      <th>speed_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3190.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>88.611115</td>\n",
       "      <td>89.166664</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.564148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>83.888885</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.866543</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3155.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>87.638885</td>\n",
       "      <td>86.666664</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.966488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3285.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>91.250000</td>\n",
       "      <td>86.666664</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19.889786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>535.0</td>\n",
       "      <td>89.444443</td>\n",
       "      <td>89.166664</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.130913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1_team_size  p2_team_size  p1_unique_types  p2_unique_types  \\\n",
       "0           6.0           1.0              5.0              2.0   \n",
       "1           6.0           1.0              6.0              2.0   \n",
       "2           6.0           1.0              8.0              2.0   \n",
       "3           6.0           1.0              8.0              2.0   \n",
       "4           6.0           1.0              6.0              2.0   \n",
       "\n",
       "   p1_team_stat_sum  p2_team_stat_sum  p1_team_stat_avg  p2_team_stat_avg  \\\n",
       "0            3190.0             535.0         88.611115         89.166664   \n",
       "1            3020.0             540.0         83.888885         90.000000   \n",
       "2            3155.0             520.0         87.638885         86.666664   \n",
       "3            3285.0             520.0         91.250000         86.666664   \n",
       "4            3220.0             535.0         89.444443         89.166664   \n",
       "\n",
       "   diff_team_size  diff_unique_types  ...  atk_def_ratio  spd_gap  hp_ratio  \\\n",
       "0             5.0                3.0  ...            0.0      0.0       0.0   \n",
       "1             5.0                4.0  ...            0.0      0.0       0.0   \n",
       "2             5.0                6.0  ...            0.0      0.0       0.0   \n",
       "3             5.0                6.0  ...            0.0      0.0       0.0   \n",
       "4             5.0                4.0  ...            0.0      0.0       0.0   \n",
       "\n",
       "   survival_score  momentum_index  power_acc_gap  offensive_balance  \\\n",
       "0             0.0             0.0     -14.564148                0.0   \n",
       "1             0.0             0.0      22.866543                0.0   \n",
       "2             0.0             0.0     -17.966488                0.0   \n",
       "3             0.0             0.0     -19.889786                0.0   \n",
       "4             0.0             0.0     -11.130913                0.0   \n",
       "\n",
       "   defensive_efficiency  status_influence  speed_ratio  \n",
       "0                   0.0               0.0          0.0  \n",
       "1                   0.0               0.0          0.0  \n",
       "2                   0.0               0.0          0.0  \n",
       "3                   0.0               0.0          0.0  \n",
       "4                   0.0               0.0          0.0  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================\n",
    "# CELLA 2 ‚Äî Feature Engineering \n",
    "# =========================\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Base stat keys used throughout the feature extraction\n",
    "# ---------------------------------------------\n",
    "BASE_STAT_KEYS = [\"base_hp\",\"base_atk\",\"base_def\",\"base_spa\",\"base_spd\",\"base_spe\"]\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Static team composition and stats\n",
    "# ---------------------------------------------\n",
    "def unique_types(team: List[Dict[str, Any]]) -> int:\n",
    "    collected=[]\n",
    "    for p in team or []:\n",
    "        ts=p.get(\"types\") or []\n",
    "        if isinstance(ts,str): ts=[ts]\n",
    "        collected.extend([t for t in ts if t])\n",
    "    return len(set(collected))\n",
    "\n",
    "def sum_stats_of_team(team: List[Dict[str, Any]]) -> float:\n",
    "    total=0.0\n",
    "    for p in team or []:\n",
    "        for k in BASE_STAT_KEYS:\n",
    "            v=p.get(k)\n",
    "            if isinstance(v,(int,float)):\n",
    "                total+=float(v)\n",
    "    return total\n",
    "\n",
    "def avg_stats_of_team(team: List[Dict[str, Any]]) -> float:\n",
    "    if not team:\n",
    "        return 0.0\n",
    "    per=[]\n",
    "    for p in team:\n",
    "        vals=[p.get(k) for k in BASE_STAT_KEYS if isinstance(p.get(k),(int,float))]\n",
    "        if vals:\n",
    "            per.append(sum(vals)/len(vals))\n",
    "    return float(sum(per)/len(per)) if per else 0.0\n",
    "\n",
    "def sum_and_avg_of_single(poke: dict) -> Tuple[float, float]:\n",
    "    vals = [poke.get(k) for k in BASE_STAT_KEYS if isinstance(poke.get(k), (int, float))]\n",
    "    if not vals:\n",
    "        return 0.0, 0.0\n",
    "    total = float(sum(vals))\n",
    "    return total, total / len(vals)\n",
    "\n",
    "def team_stat_variance(team: List[Dict[str,Any]]) -> float:\n",
    "    if not team:\n",
    "        return 0.0\n",
    "    per=[]\n",
    "    for p in team:\n",
    "        vals=[p.get(k) for k in BASE_STAT_KEYS if isinstance(p.get(k),(int,float))]\n",
    "        if vals:\n",
    "            per.append(sum(vals)/len(vals))\n",
    "    if len(per)<2:\n",
    "        return 0.0\n",
    "    return float(pd.Series(per).var())\n",
    "\n",
    "def _team_speed_stats(team):\n",
    "    \"\"\"Return mean and max base speed over a team.\"\"\"\n",
    "    sp = [p.get(\"base_spe\", 0.0) for p in team or [] if isinstance(p.get(\"base_spe\", None), (int, float))]\n",
    "    if not sp:\n",
    "        return 0.0, 0.0\n",
    "    return float(np.mean(sp)), float(np.max(sp))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# General numeric helpers\n",
    "# ---------------------------------------------\n",
    "def _safe_mean(arr): \n",
    "    return float(np.mean(arr)) if arr else 0.0\n",
    "\n",
    "def _safe_ratio(a,b,cap=10.0):\n",
    "    r=a/(b+1e-6)\n",
    "    if r < 0: r = 0.0\n",
    "    if r > cap: r = cap\n",
    "    if not np.isfinite(r): r = 0.0\n",
    "    return float(r)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Timeline-based HP feature extraction\n",
    "# ---------------------------------------------\n",
    "def get_timeline(r: Dict[str,Any], max_turns: int = 30):\n",
    "    tl = r.get(\"battle_timeline\",[]) or []\n",
    "    return tl[:max_turns] if isinstance(tl,list) else []\n",
    "\n",
    "def _extract_hp_series(tl):\n",
    "    p1=[]; p2=[]\n",
    "    for t in tl:\n",
    "        if not isinstance(t,dict): \n",
    "            continue\n",
    "        s1=t.get(\"p1_pokemon_state\") or {}\n",
    "        s2=t.get(\"p2_pokemon_state\") or {}\n",
    "        v1=s1.get(\"hp_pct\"); v2=s2.get(\"hp_pct\")\n",
    "        if isinstance(v1,(int,float)) and isinstance(v2,(int,float)):\n",
    "            p1.append(float(v1)); p2.append(float(v2))\n",
    "    return p1,p2\n",
    "\n",
    "def _mean_last_std_min(arr):\n",
    "    if not arr:\n",
    "        return 0.0,0.0,0.0,0.0\n",
    "    x=np.array(arr,dtype=float)\n",
    "    return float(x.mean()), float(x[-1]), float(x.std(ddof=0)), float(x.min())\n",
    "\n",
    "def _window(arr,n): return arr[:n] if arr else []\n",
    "def _frac_positive(arr): return float((np.array(arr)>0).mean()) if arr else 0.0\n",
    "def _slope(arr):\n",
    "    if len(arr)<2: return 0.0\n",
    "    x=np.arange(len(arr))\n",
    "    m,_=np.polyfit(x,np.array(arr),1)\n",
    "    return float(m)\n",
    "def _auc_pct(arr): return float(np.sum(arr)/(100.0*len(arr))) if arr else 0.0\n",
    "def _status_count(tl,who):\n",
    "    cnt=0\n",
    "    k=f\"{who}_pokemon_state\"\n",
    "    for t in tl:\n",
    "        if not isinstance(t,dict): continue\n",
    "        st=(t.get(k) or {}).get(\"status\",None)\n",
    "        if st not in (None,\"\",\"none\",\"NONE\"):\n",
    "            cnt+=1\n",
    "    return float(cnt)\n",
    "def _ko_count(arr): return float(sum(1 for v in arr if v==0))\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Move-related statistics from timeline\n",
    "# ---------------------------------------------\n",
    "def _move_stats_for_side(tl, who, window=None):\n",
    "    key=f\"{who}_move_details\"\n",
    "    seq = tl if window is None else tl[:window]\n",
    "    pw, ac, pr = [], [], []\n",
    "    for t in seq:\n",
    "        md=t.get(key) or {}\n",
    "        bp=md.get(\"base_power\"); acc=md.get(\"accuracy\"); pri=md.get(\"priority\")\n",
    "        if isinstance(bp,(int,float)): pw.append(float(bp))\n",
    "        if isinstance(acc,(int,float)): ac.append(float(acc))\n",
    "        if isinstance(pri,(int,float)): pr.append(float(pri))\n",
    "    suf=\"\" if window is None else f\"_{window}\"\n",
    "    return {\n",
    "        f\"mv_{who}_power_mean{suf}\": _safe_mean(pw),\n",
    "        f\"mv_{who}_acc_mean{suf}\":   _safe_mean(ac),\n",
    "        f\"mv_{who}_priority_mean{suf}\": _safe_mean(pr),\n",
    "    }\n",
    "# ---------------------------------------------\n",
    "# Type effectiveness helpers (uppercase canonical)\n",
    "# ---------------------------------------------\n",
    "_TYPE_CHART = {\n",
    "    \"NORMAL\":   {\"ROCK\":0.5, \"GHOST\":0.0, \"STEEL\":0.5},\n",
    "    \"FIRE\":     {\"FIRE\":0.5, \"WATER\":0.5, \"GRASS\":2.0, \"ICE\":2.0, \"BUG\":2.0, \"ROCK\":0.5, \"DRAGON\":0.5, \"STEEL\":2.0},\n",
    "    \"WATER\":    {\"FIRE\":2.0, \"WATER\":0.5, \"GRASS\":0.5, \"GROUND\":2.0, \"ROCK\":2.0, \"DRAGON\":0.5},\n",
    "    \"ELECTRIC\": {\"WATER\":2.0, \"ELECTRIC\":0.5, \"GRASS\":0.5, \"GROUND\":0.0, \"FLYING\":2.0, \"DRAGON\":0.5},\n",
    "    \"GRASS\":    {\"FIRE\":0.5, \"WATER\":2.0, \"GRASS\":0.5, \"POISON\":0.5, \"GROUND\":2.0, \"FLYING\":0.5, \"BUG\":0.5, \"ROCK\":2.0, \"DRAGON\":0.5, \"STEEL\":0.5},\n",
    "    \"ICE\":      {\"FIRE\":0.5, \"WATER\":0.5, \"GRASS\":2.0, \"GROUND\":2.0, \"FLYING\":2.0, \"DRAGON\":2.0, \"STEEL\":0.5},\n",
    "    \"FIGHTING\": {\"NORMAL\":2.0, \"ICE\":2.0, \"POISON\":0.5, \"FLYING\":0.5, \"PSYCHIC\":0.5, \"BUG\":0.5, \"ROCK\":2.0, \"GHOST\":0.0, \"DARK\":2.0, \"STEEL\":2.0, \"FAIRY\":0.5},\n",
    "    \"POISON\":   {\"GRASS\":2.0, \"POISON\":0.5, \"GROUND\":0.5, \"ROCK\":0.5, \"GHOST\":0.5, \"STEEL\":0.0, \"FAIRY\":2.0},\n",
    "    \"GROUND\":   {\"FIRE\":2.0, \"ELECTRIC\":2.0, \"GRASS\":0.5, \"POISON\":2.0, \"FLYING\":0.0, \"BUG\":0.5, \"ROCK\":2.0, \"STEEL\":2.0},\n",
    "    \"FLYING\":   {\"ELECTRIC\":0.5, \"GRASS\":2.0, \"FIGHTING\":2.0, \"BUG\":2.0, \"ROCK\":0.5, \"STEEL\":0.5},\n",
    "    \"PSYCHIC\":  {\"FIGHTING\":2.0, \"POISON\":2.0, \"PSYCHIC\":0.5, \"DARK\":0.0, \"STEEL\":0.5},\n",
    "    \"BUG\":      {\"FIRE\":0.5, \"GRASS\":2.0, \"FIGHTING\":0.5, \"POISON\":0.5, \"FLYING\":0.5, \"PSYCHIC\":2.0, \"GHOST\":0.5, \"DARK\":2.0, \"STEEL\":0.5, \"FAIRY\":0.5},\n",
    "    \"ROCK\":     {\"FIRE\":2.0, \"ICE\":2.0, \"FIGHTING\":0.5, \"GROUND\":0.5, \"FLYING\":2.0, \"BUG\":2.0, \"STEEL\":0.5},\n",
    "    \"GHOST\":    {\"NORMAL\":0.0, \"PSYCHIC\":2.0, \"GHOST\":2.0, \"DARK\":0.5},\n",
    "    \"DRAGON\":   {\"DRAGON\":2.0, \"STEEL\":0.5, \"FAIRY\":0.0},\n",
    "    \"DARK\":     {\"FIGHTING\":0.5, \"PSYCHIC\":2.0, \"GHOST\":2.0, \"DARK\":0.5, \"FAIRY\":0.5},\n",
    "    \"STEEL\":    {\"FIRE\":0.5, \"WATER\":0.5, \"ELECTRIC\":0.5, \"ICE\":2.0, \"ROCK\":2.0, \"FAIRY\":2.0, \"STEEL\":0.5},\n",
    "    \"FAIRY\":    {\"FIRE\":0.5, \"FIGHTING\":2.0, \"POISON\":0.5, \"DRAGON\":2.0, \"DARK\":2.0, \"STEEL\":0.5},\n",
    "}\n",
    "\n",
    "def _type_multiplier(move_type: str, target_types: List[str] | set) -> float:\n",
    "    \"\"\"Effectiveness multiplier for move_type against mono/dual target types.\"\"\"\n",
    "    if not move_type:\n",
    "        return 1.0\n",
    "    mt = move_type.strip().upper()\n",
    "    mult = 1.0\n",
    "    for tt in target_types or []:\n",
    "        tt_up = str(tt).strip().upper()\n",
    "        mult *= _TYPE_CHART.get(mt, {}).get(tt_up, 1.0)\n",
    "    return float(mult) if np.isfinite(mult) else 1.0\n",
    "\n",
    "def _avg_type_eff_p1_vs_p2lead(tl: list[dict], p2_lead_types: List[str] | set, window: int | None = None) -> float:\n",
    "    \"\"\"Mean effectiveness of P1 used moves vs P2 lead types over full/early window.\"\"\"\n",
    "    seq = tl if window is None else tl[:window]\n",
    "    vals = []\n",
    "    for t in seq:\n",
    "        md = t.get(\"p1_move_details\") or {}\n",
    "        mv_t = md.get(\"type\")\n",
    "        if isinstance(mv_t, str) and p2_lead_types:\n",
    "            vals.append(_type_multiplier(mv_t, p2_lead_types))\n",
    "    return float(np.mean(vals)) if vals else 1.0  # neutral if unknown\n",
    "\n",
    "# ---------------------------------------------\n",
    "# STAB features (Same-Type Attack Bonus)\n",
    "# ---------------------------------------------\n",
    "def _name_to_types_map_p1(record: Dict[str, Any]) -> Dict[str, set]:\n",
    "    mp = {}\n",
    "    for p in record.get(\"p1_team_details\", []) or []:\n",
    "        nm = (p.get(\"name\") or \"\").strip().lower()\n",
    "        ts = p.get(\"types\") or []\n",
    "        if isinstance(ts, str):\n",
    "            ts = [ts]\n",
    "        ts_norm = {str(t).strip().upper() for t in ts if t and str(t).strip().upper() != \"NOTYPE\"}\n",
    "        if nm:\n",
    "            mp[nm] = ts_norm\n",
    "    return mp\n",
    "\n",
    "def _active_name_and_move_type(turn: Dict[str, Any], who: str) -> tuple[str, str]:\n",
    "    state = turn.get(f\"{who}_pokemon_state\") or {}\n",
    "    md    = turn.get(f\"{who}_move_details\") or {}\n",
    "    nm = (state.get(\"name\") or \"\").strip().lower()\n",
    "    mv_t = (md.get(\"type\") or \"\").strip().upper()\n",
    "    return nm, mv_t\n",
    "\n",
    "def _stab_features(record: Dict[str, Any], max_turns: int = 30) -> Dict[str, float]:\n",
    "    tl = get_timeline(record, max_turns=max_turns)\n",
    "\n",
    "    # type maps of P1 (name -> set(types))\n",
    "    p1_types_map = _name_to_types_map_p1(record)\n",
    "\n",
    "    # ratio & diff - helpers\n",
    "    def _accumulate(seq):\n",
    "        p1_total = p1_stab = 0\n",
    "        p2_total = p2_stab = 0  \n",
    "\n",
    "        for t in seq:\n",
    "            # P1\n",
    "            nm1, mv1_type = _active_name_and_move_type(t, \"p1\")\n",
    "            if mv1_type:\n",
    "                p1_total += 1\n",
    "                types1 = p1_types_map.get(nm1, set())\n",
    "                is_stab = (mv1_type in types1) if types1 else False\n",
    "                if is_stab:\n",
    "                    p1_stab += 1\n",
    "\n",
    "        p1_ratio = (p1_stab / p1_total) if p1_total > 0 else 0.0\n",
    "        p2_ratio = 0.0\n",
    "\n",
    "        return {\n",
    "            \"stab_stab_ratio_diff\": float(p1_ratio - p2_ratio),\n",
    "            \"stab_stab_ratio_ratio\": _safe_ratio(p1_ratio, p2_ratio if p2_ratio > 0 else 1e-6, cap=10.0),\n",
    "        }\n",
    "\n",
    "    full = _accumulate(tl)\n",
    "    w5   = _accumulate(tl[:5])\n",
    "\n",
    "    return {\n",
    "        \"stab_stab_ratio_diff_full\":  float(full[\"stab_stab_ratio_diff\"]),\n",
    "        \"stab_stab_ratio_ratio_full\": float(full[\"stab_stab_ratio_ratio\"]),\n",
    "        \"stab_stab_ratio_diff_w5\":    float(w5[\"stab_stab_ratio_diff\"]),\n",
    "        \"stab_stab_ratio_ratio_w5\":   float(w5[\"stab_stab_ratio_ratio\"]),\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Early momentum (first 3 turns)\n",
    "# ---------------------------------------------\n",
    "def _first_ko_flag(hp_series: list[float]) -> int:\n",
    "    for v in hp_series:\n",
    "        if isinstance(v, (int, float)) and float(v) == 0.0:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def _first_status_advantage(tl: list[dict], first_n: int = 3) -> float:\n",
    "    p1 = p2 = 0\n",
    "    for t in tl[:first_n]:\n",
    "        s1 = (t.get(\"p1_pokemon_state\") or {}).get(\"status\", None)\n",
    "        s2 = (t.get(\"p2_pokemon_state\") or {}).get(\"status\", None)\n",
    "        if s1 not in (None, \"\", \"none\", \"NONE\"): p1 += 1\n",
    "        if s2 not in (None, \"\", \"none\", \"NONE\"): p2 += 1\n",
    "    return float(p1 - p2)\n",
    "\n",
    "def _early_momentum_features(record: Dict[str, Any], first_n: int = 3) -> Dict[str, float]:\n",
    "    tl = get_timeline(record, max_turns=30)\n",
    "    p1, p2 = _extract_hp_series(tl)\n",
    "    p1w, p2w = _window(p1, first_n), _window(p2, first_n)\n",
    "\n",
    "    diffw = [a - b for a, b in zip(p1w, p2w)] if p1w and p2w and len(p1w) == len(p2w) else []\n",
    "    mean_diff_first = float(np.mean(diffw)) if diffw else 0.0\n",
    "\n",
    "    p1_first_ko = _first_ko_flag(p2w)\n",
    "    p2_first_ko = _first_ko_flag(p1w)\n",
    "    first_ko_score = float(p1_first_ko - p2_first_ko)\n",
    "\n",
    "    status_adv = _first_status_advantage(tl, first_n=first_n)\n",
    "\n",
    "    return {\n",
    "        f\"early_hp_diff_mean_{first_n}\": mean_diff_first,\n",
    "        f\"early_first_ko_score_{first_n}\": first_ko_score,\n",
    "        f\"early_status_advantage_{first_n}\": status_adv,\n",
    "    }\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Priority counts and advantage (full / 5 / 10)\n",
    "# ---------------------------------------------\n",
    "def _priority_counts(record: Dict[str, Any], max_turns: int = 30, window: int | None = None) -> Dict[str, float]:\n",
    "    tl = get_timeline(record, max_turns=max_turns)\n",
    "    turns = tl if window is None else tl[:window]\n",
    "\n",
    "    p1_count = 0.0\n",
    "    p2_count = 0.0\n",
    "    for t in turns:\n",
    "        md1 = t.get(\"p1_move_details\") or {}\n",
    "        md2 = t.get(\"p2_move_details\") or {}\n",
    "        pri1 = md1.get(\"priority\")\n",
    "        pri2 = md2.get(\"priority\")\n",
    "        if isinstance(pri1, (int, float)) and float(pri1) > 0: p1_count += 1.0\n",
    "        if isinstance(pri2, (int, float)) and float(pri2) > 0: p2_count += 1.0\n",
    "\n",
    "    suf = \"\" if window is None else f\"_{window}\"\n",
    "    return {\n",
    "        f\"mv_p1_priority_count{suf}\": p1_count,\n",
    "        f\"mv_p2_priority_count{suf}\": p2_count,\n",
    "        f\"mv_priority_count_diff{suf}\": p1_count - p2_count,\n",
    "    }\n",
    "\n",
    "def _priority_feature_block(record: Dict[str, Any]) -> Dict[str, float]:\n",
    "    f = {}\n",
    "    f.update(_priority_counts(record, max_turns=30, window=None))\n",
    "    f.update(_priority_counts(record, max_turns=30, window=5))\n",
    "    return f\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# LEAD MATCHUP / DAMAGE-INDEX HELPERS\n",
    "# ====================================\n",
    "def _simple_damage_index(base_power: float, stab: bool, eff: float, atk_proxy: float, def_proxy: float) -> float:\n",
    "    if not isinstance(base_power, (int, float)) or base_power <= 0:\n",
    "        return 0.0\n",
    "    s = 1.5 if stab else 1.0\n",
    "    ratio = (float(atk_proxy) + 1e-3) / (float(def_proxy) + 1e-3)\n",
    "    val = float(base_power) * s * float(eff) * ratio\n",
    "    return float(val) if np.isfinite(val) else 0.0\n",
    "\n",
    "def _p1_vs_p2lead_matchup_index(record: dict, tl: list[dict]) -> dict:\n",
    "    p1_team = record.get(\"p1_team_details\", []) or []\n",
    "    p1_mean_atk = float(np.mean([p.get(\"base_atk\", 0) for p in p1_team])) if p1_team else 0.0\n",
    "    p1_mean_spa = float(np.mean([p.get(\"base_spa\", 0) for p in p1_team])) if p1_team else 0.0\n",
    "\n",
    "    lead = record.get(\"p2_lead_details\") or {}\n",
    "    p2_types = lead.get(\"types\") or []\n",
    "    if isinstance(p2_types, str): p2_types = [p2_types]\n",
    "    p2_types = [t for t in p2_types if t]\n",
    "    p2_def = float(lead.get(\"base_def\", 0.0) or 0.0)\n",
    "    p2_spd = float(lead.get(\"base_spd\", 0.0) or 0.0)\n",
    "\n",
    "    p1map = {}\n",
    "    for p in p1_team:\n",
    "        nm = (p.get(\"name\") or \"\").strip().lower()\n",
    "        ts = p.get(\"types\") or []\n",
    "        if isinstance(ts, str): ts = [ts]\n",
    "        p1map[nm] = {str(x).strip().upper() for x in ts if x}\n",
    "\n",
    "    def _acc(window=None):\n",
    "        seq = tl if window is None else tl[:window]\n",
    "        vals = []\n",
    "        for t in seq:\n",
    "            md = t.get(\"p1_move_details\") or {}\n",
    "            bp = md.get(\"base_power\"); cat = md.get(\"category\"); mtype = md.get(\"type\")\n",
    "            if not isinstance(bp, (int, float)) or bp <= 0: \n",
    "                continue\n",
    "            nm = (t.get(\"p1_pokemon_state\") or {}).get(\"name\", \"\")\n",
    "            nm = (nm or \"\").strip().lower()\n",
    "            is_stab = str(mtype or \"\").strip().upper() in p1map.get(nm, set())\n",
    "            eff = _type_multiplier(mtype, p2_types)\n",
    "            if (cat or \"\").upper() == \"PHYSICAL\":\n",
    "                idx = _simple_damage_index(bp, is_stab, eff, p1_mean_atk, p2_def)\n",
    "            elif (cat or \"\").upper() == \"SPECIAL\":\n",
    "                idx = _simple_damage_index(bp, is_stab, eff, p1_mean_spa, p2_spd)\n",
    "            else:\n",
    "                idx = 0.0\n",
    "            vals.append(idx)\n",
    "        return float(np.mean(vals)) if vals else 0.0\n",
    "\n",
    "    return {\n",
    "        \"lead_matchup_p1_index_full\": _acc(None),\n",
    "        \"lead_matchup_p1_index_5\":    _acc(5),\n",
    "    }\n",
    "\n",
    "# ==========================\n",
    "# SWITCH / HAZARD / MOMENTUM\n",
    "# ==========================\n",
    "def _switch_count(tl: list[dict], who: str) -> float:\n",
    "    last = None\n",
    "    cnt = 0\n",
    "    key = f\"{who}_pokemon_state\"\n",
    "    for t in tl:\n",
    "        nm = (t.get(key) or {}).get(\"name\")\n",
    "        if nm is None:\n",
    "            continue\n",
    "        if last is not None and nm != last:\n",
    "            cnt += 1\n",
    "        last = nm\n",
    "    return float(cnt)\n",
    "\n",
    "HAZARD_MOVES = {\"stealthrock\", \"spikes\", \"toxicspikes\", \"stickyweb\"}\n",
    "\n",
    "def _hazard_flags(tl: list[dict]) -> dict:\n",
    "    p1 = p2 = 0.0\n",
    "    for t in tl:\n",
    "        m1 = (t.get(\"p1_move_details\") or {}).get(\"name\")\n",
    "        m2 = (t.get(\"p2_move_details\") or {}).get(\"name\")\n",
    "        if m1 and str(m1).strip().lower() in HAZARD_MOVES: p1 = 1.0\n",
    "        if m2 and str(m2).strip().lower() in HAZARD_MOVES: p2 = 1.0\n",
    "    return {\"hazard_p1_flag\": p1, \"hazard_p2_flag\": p2, \"hazard_flag_diff\": p1 - p2}\n",
    "\n",
    "def _momentum_shift(tl: list[dict], t1: int = 3, t2: int = 10) -> dict:\n",
    "    def _hp_diff_mean(win):\n",
    "        p1, p2 = _extract_hp_series(win)\n",
    "        if not p1 or not p2 or len(p1) != len(p2): return 0.0\n",
    "        d = [a-b for a,b in zip(p1,p2)]\n",
    "        return float(np.mean(d)) if d else 0.0\n",
    "    d1 = _hp_diff_mean(tl[:t1]); d2 = _hp_diff_mean(tl[:t2])\n",
    "    return {\"momentum_shift_3_10\": float(d1 - d2), \"momentum_shift_abs_3_10\": float(abs(d1 - d2))}\n",
    "\n",
    "HEAL_MOVES = {\"recover\",\"roost\",\"softboiled\",\"rest\",\"wish\",\"synthesis\",\"morningsun\",\"moonlight\",\"drainpunch\",\"leechseed\"}\n",
    "\n",
    "def _recovery_pressure(tl: list[dict]) -> dict:\n",
    "    p1 = p2 = 0.0\n",
    "    for t in tl:\n",
    "        m1 = (t.get(\"p1_move_details\") or {}).get(\"name\")\n",
    "        m2 = (t.get(\"p2_move_details\") or {}).get(\"name\")\n",
    "        if m1 and str(m1).strip().lower() in HEAL_MOVES: p1 += 1.0\n",
    "        if m2 and str(m2).strip().lower() in HEAL_MOVES: p2 += 1.0\n",
    "    return {\"recover_p1_count\": p1, \"recover_p2_count\": p2, \"recover_count_diff\": p1 - p2}\n",
    "\n",
    "# ---------------------------------------------\n",
    "# NEW FEATURES \n",
    "# ---------------------------------------------\n",
    "def new_features(r):\n",
    "    tl = get_timeline(r, max_turns=30)\n",
    "    p1, p2 = _extract_hp_series(tl)\n",
    "    t1 = r.get(\"p1_team_details\", []) or []\n",
    "    lead = r.get(\"p2_lead_details\", {}) or {}\n",
    "\n",
    "    f = {}\n",
    "    if len(p1) >= 3 and len(p2) >= 3:\n",
    "        f['early_hp_winner'] = 1.0 if np.mean(p1[:3]) > np.mean(p2[:3]) else 0.0\n",
    "        f['early_hp_difference'] = np.mean(p1[:3]) - np.mean(p2[:3])\n",
    "\n",
    "    if p1 and p2:\n",
    "        f['final_hp_winner'] = 1.0 if p1[-1] > p2[-1] else 0.0\n",
    "        f['final_hp_difference'] = p1[-1] - p2[-1]\n",
    "\n",
    "    p1_total_stats = sum(p.get(k, 0) for p in t1 for k in BASE_STAT_KEYS)\n",
    "    p2_total_stats = sum(lead.get(k, 0) for k in BASE_STAT_KEYS)\n",
    "    f['stronger_team'] = 1.0 if p1_total_stats > p2_total_stats else 0.0\n",
    "    f['team_strength_gap'] = p1_total_stats - p2_total_stats\n",
    "\n",
    "    p1_speeds = [p.get('base_spe', 0) for p in t1]\n",
    "    p2_speed = lead.get('base_spe', 0)\n",
    "    f['faster_team'] = 1.0 if max(p1_speeds, default=0) > p2_speed else 0.0\n",
    "    f['speed_advantage'] = max(p1_speeds, default=0) - p2_speed\n",
    "    f['num_faster_pokemon'] = sum(1 for s in p1_speeds if s > p2_speed)\n",
    "\n",
    "    f['p1_danger_count'] = sum(1 for hp in p1 if 0 < hp < 25)\n",
    "    f['p2_danger_count'] = sum(1 for hp in p2 if 0 < hp < 25)\n",
    "    f['survived_more_danger'] = 1.0 if f['p1_danger_count'] < f['p2_danger_count'] else 0.0\n",
    "    return f\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Mirko & Deb\n",
    "# ---------------------------------------------\n",
    "def get_defensive_profile(types):\n",
    "    \"\"\"\n",
    "    Combined defensive multipliers for a defender with 'types' against every attack type.\n",
    "    Fixed: use attacking type first, then multiply by defender types.\n",
    "    \"\"\"\n",
    "    types = types or []\n",
    "    if isinstance(types, str): types = [types]\n",
    "    types_up = [str(t).strip().upper() for t in types if t]\n",
    "\n",
    "    combined = {}\n",
    "    for atk_type in _TYPE_CHART.keys():\n",
    "        mult = 1.0\n",
    "        for tdef in types_up:\n",
    "            mult *= _TYPE_CHART.get(atk_type, {}).get(tdef, 1.0)\n",
    "        combined[atk_type] = float(mult)\n",
    "    return combined\n",
    "\n",
    "def new_features_mirko(battle):\n",
    "    features = {}\n",
    "    # Player 1 Team aggregate\n",
    "    p1_team = battle.get('p1_team_details', []) or []\n",
    "    if p1_team:\n",
    "        ratios = []\n",
    "        v_hp=[]; v_spe=[]; v_atk=[]; v_def=[]\n",
    "        all_types=[]\n",
    "        weaknesses=[]; resistances=[]; immunities=[]\n",
    "        for p in p1_team:\n",
    "            if not isinstance(p, dict): \n",
    "                continue\n",
    "            off = (p.get(\"base_atk\",0) + p.get(\"base_spa\",0))\n",
    "            deff = (p.get(\"base_def\",0) + p.get(\"base_spd\",0))\n",
    "            ratios.append(off / deff if deff > 0 else 0.0)\n",
    "\n",
    "            v_hp.append(p.get('base_hp',0)); v_spe.append(p.get('base_spe',0))\n",
    "            v_atk.append(p.get('base_atk',0)); v_def.append(p.get('base_def',0))\n",
    "\n",
    "            ts = p.get(\"types\") or []\n",
    "            if isinstance(ts,str): ts=[ts]\n",
    "            all_types.extend([t for t in ts if str(t).lower()!='notype'])\n",
    "\n",
    "            prof = get_defensive_profile(ts)\n",
    "            w = sum(1 for m in prof.values() if m > 1)\n",
    "            r = sum(1 for m in prof.values() if 0 < m < 1)\n",
    "            i = sum(1 for m in prof.values() if m == 0)\n",
    "            weaknesses.append(w); resistances.append(r); immunities.append(i)\n",
    "\n",
    "        features[\"avg_type_role_ratio\"] = float(np.mean(ratios)) if ratios else 0.0\n",
    "        features['p1_var_hp']  = float(np.std(v_hp)) if v_hp else 0.0\n",
    "        features['p1_var_spe'] = float(np.std(v_spe)) if v_spe else 0.0\n",
    "        features['p1_var_atk'] = float(np.std(v_atk)) if v_atk else 0.0\n",
    "        features['p1_var_def'] = float(np.std(v_def)) if v_def else 0.0\n",
    "\n",
    "        unique_types = len(set(all_types))\n",
    "        features['diversity_ratio'] = unique_types / 6.0\n",
    "\n",
    "        features[\"avg_weaknesses\"] = float(np.mean(weaknesses))  if weaknesses  else 0.0\n",
    "        features[\"avg_resistances\"] = float(np.mean(resistances)) if resistances else 0.0\n",
    "        features[\"avg_immunities\"] = float(np.mean(immunities))  if immunities  else 0.0\n",
    "\n",
    "    # P2 lead raw stats\n",
    "    p2_lead = battle.get('p2_lead_details') or {}\n",
    "    if isinstance(p2_lead, dict) and p2_lead:\n",
    "        features['p2_lead_hp']  = p2_lead.get('base_hp', 0)\n",
    "        features['p2_lead_spe'] = p2_lead.get('base_spe', 0)\n",
    "        features['p2_lead_atk'] = p2_lead.get('base_atk', 0)\n",
    "        features['p2_lead_def'] = p2_lead.get('base_def', 0)\n",
    "\n",
    "    # Voluntary leave counters (None move_details ~ skipped)\n",
    "    tl = battle.get('battle_timeline', []) or []\n",
    "    idx_none_p2 = [i+1 for i,e in enumerate(tl) if e.get('p2_move_details') is None]\n",
    "    idx_none_p1 = [i+1 for i,e in enumerate(tl) if e.get('p1_move_details') is None]\n",
    "    def _bucket_count(idxs,a,b): return len([x for x in idxs if a<=x<=b])\n",
    "    features['vol_leave_diff_1'] = _bucket_count(idx_none_p1,1,10)  - _bucket_count(idx_none_p2,1,10)\n",
    "    features['vol_leave_diff_2'] = _bucket_count(idx_none_p1,11,20) - _bucket_count(idx_none_p2,11,20)\n",
    "    features['vol_leave_diff_3'] = _bucket_count(idx_none_p1,21,10**9) - _bucket_count(idx_none_p2,21,10**9)\n",
    "\n",
    "    # Forced leave heuristics (name change + action executed)\n",
    "    def _forced_counts(side_key, move_key):\n",
    "        lst=[]\n",
    "        for t in tl:\n",
    "            lst.append([ (t.get(side_key) or {}).get(\"name\"), (t.get(move_key) is None) ])\n",
    "        c1=c2=c3=0\n",
    "        for i in range(len(lst)-1):\n",
    "            changed = (lst[i+1][0] != lst[i][0])\n",
    "            acted   = (lst[i+1][1] == False)\n",
    "            turn_idx = i+1\n",
    "            if changed and acted:\n",
    "                if 1<=turn_idx<=10: c1+=1\n",
    "                elif 11<=turn_idx<=20: c2+=1\n",
    "                else: c3+=1\n",
    "        return c1,c2,c3\n",
    "    p1c1,p1c2,p1c3 = _forced_counts(\"p1_pokemon_state\",\"p1_move_details\")\n",
    "    p2c1,p2c2,p2c3 = _forced_counts(\"p2_pokemon_state\",\"p2_move_details\")\n",
    "    features['forced_leave_diff_1'] = float(p1c1 - p2c1)\n",
    "    features['forced_leave_diff_2'] = float(p1c2 - p2c2)\n",
    "    features['forced_leave_diff_3'] = float(p1c3 - p2c3)\n",
    "\n",
    "    # IDs / target\n",
    "    features['battle_id'] = battle.get('battle_id')\n",
    "    if 'player_won' in battle: features['player_won'] = int(battle['player_won'])\n",
    "    return features\n",
    "\n",
    "# ======= helpers for team & HP & damage stats =======\n",
    "def _pnames_from_p1_team(record):\n",
    "    team = record.get(\"p1_team_details\", []) or []\n",
    "    names = []\n",
    "    for p in team:\n",
    "        if isinstance(p, dict):\n",
    "            nm = (p.get(\"name\") or \"\").strip().lower()\n",
    "            if nm: names.append(nm)\n",
    "    return names\n",
    "\n",
    "def _pname_from_p2_lead(record):\n",
    "    lead = record.get(\"p2_lead_details\") or {}\n",
    "    if isinstance(lead, dict):\n",
    "        nm = (lead.get(\"name\") or \"\").strip().lower()\n",
    "        return nm if nm else None\n",
    "    return None\n",
    "\n",
    "def build_pokemon_win_stats(train_data, alpha=1.0):\n",
    "    games = defaultdict(int); wins = defaultdict(int)\n",
    "    for r in train_data:\n",
    "        p1_names = _pnames_from_p1_team(r)\n",
    "        p2_lead  = _pname_from_p2_lead(r)\n",
    "        p1_won   = bool(r.get(\"player_won\", False))\n",
    "        for nm in p1_names: games[nm]+=1\n",
    "        if p2_lead: games[p2_lead]+=1\n",
    "        if p1_won:\n",
    "            for nm in p1_names: wins[nm]+=1\n",
    "        else:\n",
    "            if p2_lead: wins[p2_lead]+=1\n",
    "    winrate={}\n",
    "    for nm in games:\n",
    "        g=games[nm]; w=wins[nm]\n",
    "        wr=(w+alpha)/(g+2*alpha)\n",
    "        winrate[nm]={\"games\":g,\"wins\":w,\"winrate\":wr}\n",
    "    return winrate\n",
    "\n",
    "def team_score_from_stats(team_names, stats, default_wr=0.5):\n",
    "    vals=[stats.get((nm or \"\").strip().lower(),{}).get(\"winrate\",default_wr) for nm in team_names if nm]\n",
    "    return float(np.mean(vals)) if vals else default_wr\n",
    "\n",
    "def predict_from_stats(test_record, stats, threshold=0.5):\n",
    "    p1_names = _pnames_from_p1_team(test_record)\n",
    "    score = team_score_from_stats(p1_names, stats, default_wr=0.5)\n",
    "    return (score > threshold), score\n",
    "\n",
    "def build_pokemon_hp_stats(train_data):\n",
    "    hp_sum=defaultdict(float); hp_count=defaultdict(int)\n",
    "    for r in train_data:\n",
    "        timeline = r.get(\"battle_timeline\", []) or []\n",
    "        if not timeline: continue\n",
    "        last_turn = timeline[-1]\n",
    "        for player_key in [\"p1_pokemon_state\", \"p2_pokemon_state\"]:\n",
    "            name = (last_turn.get(player_key, {}).get(\"name\") or \"\").strip().lower()\n",
    "            hp   = last_turn.get(player_key, {}).get(\"hp_pct\", None)\n",
    "            if name and isinstance(hp,(int,float)):\n",
    "                hp_sum[name]+=float(hp); hp_count[name]+=1\n",
    "    stats = {name: {\"count\": hp_count[name], \"hp_mean\": hp_sum[name]/hp_count[name]} for name in hp_sum}\n",
    "    return stats\n",
    "\n",
    "def team_hp_score(team_names, hp_stats, default_hp=50.0):\n",
    "    vals=[]\n",
    "    for name in team_names:\n",
    "        n=(name or \"\").strip().lower()\n",
    "        vals.append(hp_stats.get(n,{}).get(\"hp_mean\", default_hp))\n",
    "    return float(np.mean(vals)) if vals else default_hp\n",
    "\n",
    "def build_pokemon_avg_damage(train_data):\n",
    "    total_damage=defaultdict(float); battles_count=defaultdict(int)\n",
    "    for battle in train_data:\n",
    "        timeline = battle.get(\"battle_timeline\", []) or []\n",
    "        p1_names = [(p.get(\"name\") or \"\").lower() for p in (battle.get(\"p1_team_details\", []) or []) if isinstance(p,dict)]\n",
    "        p2_lead  = battle.get(\"p2_lead_details\", {})\n",
    "        p2_name  = (p2_lead.get(\"name\") or \"\").lower() if isinstance(p2_lead,dict) else None\n",
    "\n",
    "        for name in p1_names: battles_count[name]+=1\n",
    "        if p2_name: battles_count[p2_name]+=1\n",
    "\n",
    "        for i in range(1,len(timeline)):\n",
    "            prev, curr = timeline[i-1], timeline[i]\n",
    "            hp2b = (prev.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\", None)\n",
    "            hp2a = (curr.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\", None)\n",
    "            if isinstance(hp2b,(int,float)) and isinstance(hp2a,(int,float)):\n",
    "                dmg=max(0,hp2b-hp2a)\n",
    "                if p1_names and dmg>0:\n",
    "                    for name in p1_names: total_damage[name]+=dmg\n",
    "            hp1b = (prev.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\", None)\n",
    "            hp1a = (curr.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\", None)\n",
    "            if isinstance(hp1b,(int,float)) and isinstance(hp1a,(int,float)):\n",
    "                dmg=max(0,hp1b-hp1a)\n",
    "                if p2_name and dmg>0:\n",
    "                    total_damage[p2_name]+=dmg\n",
    "    avg_damage = {name: total_damage[name]/battles_count[name] for name in battles_count if battles_count[name]>0}\n",
    "    return avg_damage\n",
    "\n",
    "def damage_feature_for_battle(record, avg_damage):\n",
    "    p1_names = [(p.get(\"name\") or \"\").lower() for p in (record.get(\"p1_team_details\",[]) or []) if isinstance(p,dict)]\n",
    "    p1_damage_score = sum(avg_damage.get(name, 0.0) for name in p1_names)\n",
    "    p2_lead = record.get(\"p2_lead_details\", {}) or {}\n",
    "    p2_name = (p2_lead.get(\"name\") or \"\").lower() if isinstance(p2_lead,dict) else None\n",
    "    p2_damage_score = avg_damage.get(p2_name,0.0) if p2_name else 0.0\n",
    "    diff = p1_damage_score - p2_damage_score\n",
    "    return {\"avg_damage_p1\": p1_damage_score, \"avg_damage_p2\": p2_damage_score, \"avg_damage_diff\": diff, \"damage_prediction\": 1.0 if diff>0 else 0.0}\n",
    "\n",
    "# ======= Deb's feature block (kept) =======\n",
    "def new_features_deb(r):\n",
    "    tl = get_timeline(r, max_turns=30)\n",
    "    p1, p2 = _extract_hp_series(tl)\n",
    "    t1 = r.get(\"p1_team_details\", []) or []\n",
    "    lead = r.get(\"p2_lead_details\", {}) or {}\n",
    "    f = {}\n",
    "\n",
    "    if len(p1) >= 3 and len(p2) >= 3:\n",
    "        media_p1 = float(np.mean(p1[:3])); media_p2 = float(np.mean(p2[:3]))\n",
    "        f['is_p1_higher_avg_hp_after_3_turns'] = 1.0 if media_p1 > media_p2 else 0.0\n",
    "        f['avg_hp_difference_after_3_turns'] = media_p1 - media_p2\n",
    "\n",
    "    if p1 and p2:\n",
    "        f['is_player1_final_hp_winner'] = 1.0 if p1[-1] > p2[-1] else 0.0\n",
    "        f['final_hp_difference'] = p1[-1] - p2[-1]\n",
    "\n",
    "    if len(p1) >= 6 and len(p2) >= 6:\n",
    "        f['comeback_happened'] = float((np.mean(p1[:3]) > np.mean(p2[:3])) != (np.mean(p1[-3:]) > np.mean(p2[-3:])))\n",
    "\n",
    "    p1_total_stats = sum(p.get('base_hp',0)+p.get('base_atk',0)+p.get('base_def',0)+p.get('base_spa',0)+p.get('base_spd',0)+p.get('base_spe',0) for p in t1 if isinstance(p,dict))\n",
    "    p2_total_stats = (lead.get('base_hp',0)+lead.get('base_atk',0)+lead.get('base_def',0)+lead.get('base_spa',0)+lead.get('base_spd',0)+lead.get('base_spe',0))\n",
    "    f['stronger_team'] = 1.0 if p1_total_stats > p2_total_stats else 0.0\n",
    "    f['team_strength_gap'] = p1_total_stats - p2_total_stats\n",
    "\n",
    "    p1_speeds = [p.get('base_spe', 0) for p in t1 if isinstance(p,dict)]\n",
    "    p2_speed = lead.get('base_spe', 0) if isinstance(lead,dict) else 0\n",
    "    if p1_speeds:\n",
    "        f['faster_team'] = 1.0 if max(p1_speeds) > p2_speed else 0.0\n",
    "        f['speed_advantage'] = max(p1_speeds) - p2_speed\n",
    "        f['num_faster_pokemon'] = sum(1 for s in p1_speeds if s > p2_speed)\n",
    "    else:\n",
    "        f['faster_team'] = 0.0; f['speed_advantage'] = 0.0; f['num_faster_pokemon'] = 0.0\n",
    "\n",
    "    p1_powers=[]; p2_powers=[]\n",
    "    for t in tl:\n",
    "        if not isinstance(t,dict): continue\n",
    "        md1=t.get('p1_move_details'); md2=t.get('p2_move_details')\n",
    "        bp1 = md1.get('base_power') if isinstance(md1,dict) else None\n",
    "        bp2 = md2.get('base_power') if isinstance(md2,dict) else None\n",
    "        if isinstance(bp1,(int,float)) and bp1>0: p1_powers.append(float(bp1))\n",
    "        if isinstance(bp2,(int,float)) and bp2>0: p2_powers.append(float(bp2))\n",
    "    if p1_powers and p2_powers:\n",
    "        f['most_avg_powerful_move'] = 1.0 if np.mean(p1_powers) > np.mean(p2_powers) else 0.0\n",
    "        f['avg_move_power_difference'] = float(np.mean(p1_powers) - np.mean(p2_powers))\n",
    "    else:\n",
    "        f['most_avg_powerful_move'] = 0.0; f['avg_move_power_difference'] = 0.0\n",
    "\n",
    "    f['p1_low_hp_count'] = sum(1 for hp in p1 if 0 < hp < 25)\n",
    "    f['p2_low_hp_count'] = sum(1 for hp in p2 if 0 < hp < 25)\n",
    "    f['is_player1_less_time_in_danger'] = 1.0 if f['p1_low_hp_count'] < f['p2_low_hp_count'] else 0.0\n",
    "    f['battle_length'] = len(tl)\n",
    "    f['long_battle'] = 1.0 if len(tl) > 15 else 0.0\n",
    "\n",
    "    if len(p1) > 1 and len(p2) > 1:\n",
    "        p1_changes=[abs(p1[i]-p1[i-1]) for i in range(1,len(p1))]\n",
    "        p2_changes=[abs(p2[i]-p2[i-1]) for i in range(1,len(p2))]\n",
    "        f['p1_hp_stability'] = -float(np.mean(p1_changes)) if p1_changes else 0.0\n",
    "        f['p2_hp_stability'] = -float(np.mean(p2_changes)) if p2_changes else 0.0\n",
    "        f['more_stable_hp'] = 1.0 if (p1_changes and p2_changes and np.mean(p1_changes) < np.mean(p2_changes)) else 0.0\n",
    "    else:\n",
    "        f['p1_hp_stability']=0.0; f['p2_hp_stability']=0.0; f['more_stable_hp']=0.0\n",
    "\n",
    "    p1_first_ko=0.0; p2_first_ko=0.0\n",
    "    for hp1,hp2 in zip(p1,p2):\n",
    "        if hp2==0 and p2_first_ko==0.0: p2_first_ko=1.0; break\n",
    "        if hp1==0 and p1_first_ko==0.0: p1_first_ko=1.0; break\n",
    "    f['player1_got_first_ko']=p2_first_ko\n",
    "    f['player1_suffered_first_ko']=p1_first_ko\n",
    "\n",
    "    p1_types=set()\n",
    "    for p in t1:\n",
    "        if not isinstance(p,dict): continue\n",
    "        types=p.get('types',[])\n",
    "        if isinstance(types,str): types=[types]\n",
    "        p1_types.update(t for t in types if t)\n",
    "    f['number_different_types']=len(p1_types)\n",
    "    f['team_has_type_variety']=1.0 if len(p1_types)>=4 else 0.0\n",
    "\n",
    "    if p1 and p2:\n",
    "        p1_healthy_ratio = sum(1 for hp in p1 if hp>50)/len(p1)\n",
    "        p2_healthy_ratio = sum(1 for hp in p2 if hp>50)/len(p2)\n",
    "        f['p1_hp_over_50_ratio']=p1_healthy_ratio\n",
    "        f['p2_hp_over_50_ratio']=p2_healthy_ratio\n",
    "        f['is_player1_healthier']=1.0 if p1_healthy_ratio>p2_healthy_ratio else 0.0\n",
    "    else:\n",
    "        f['p1_hp_over_50_ratio']=0.0; f['p2_hp_over_50_ratio']=0.0; f['is_player1_healthier']=0.0\n",
    "\n",
    "    if len(p1)==len(p2) and p1:\n",
    "        turns_ahead=sum(1 for a,b in zip(p1,p2) if a>b)\n",
    "        f['turns_in_lead']=float(turns_ahead)\n",
    "        f['lead_ratio']=turns_ahead/len(p1)\n",
    "        f['dominated_battle']=1.0 if turns_ahead>len(p1)*0.7 else 0.0\n",
    "    else:\n",
    "        f['turns_in_lead']=0.0; f['lead_ratio']=0.0; f['dominated_battle']=0.0\n",
    "\n",
    "    p_leave = r.get('battle_timeline', []) or []\n",
    "    if p_leave:\n",
    "        lst=[]; c1=c2=0\n",
    "        for turn in p_leave:\n",
    "            lst.append([\n",
    "                (turn.get(\"p1_pokemon_state\") or {}).get(\"name\"),\n",
    "                (turn.get('p1_move_details') is None),\n",
    "                (turn.get(\"p2_pokemon_state\") or {}).get(\"name\"),\n",
    "                (turn.get('p2_move_details') is None)\n",
    "            ])\n",
    "        for i in range(len(lst)-1):\n",
    "            if lst[i+1][0]!=lst[i][0] and lst[i+1][1]==False: c1+=1\n",
    "            elif lst[i+1][2]!=lst[i][2] and lst[i+1][3]==False: c2+=1\n",
    "        f['forced_pokemon_switch_diff']=float(c1-c2)\n",
    "    else:\n",
    "        f['forced_pokemon_switch_diff']=0.0\n",
    "\n",
    "    if p_leave:\n",
    "        p1_names=set([ (t.get(\"p1_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p1_pokemon_state\") or {}).get(\"name\") ])\n",
    "        p2_names=set([ (t.get(\"p2_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p2_pokemon_state\") or {}).get(\"name\") ])\n",
    "        f['used_pokemon_diff']=float(len(p1_names)-len(p2_names))\n",
    "    else:\n",
    "        f['used_pokemon_diff']=0.0\n",
    "\n",
    "    if p_leave:\n",
    "        recent=p_leave[-5:] if len(p_leave)>=5 else p_leave\n",
    "        p1r=[(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0) for t in recent]\n",
    "        p2r=[(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0) for t in recent]\n",
    "        f['avg_hp_recent_diff']=float(np.mean(p1r)-np.mean(p2r)) if p1r and p2r else 0.0\n",
    "    else:\n",
    "        f['avg_hp_recent_diff']=0.0\n",
    "\n",
    "    if p_leave:\n",
    "        p1_status=sum(1 for t in p_leave if (t.get(\"p1_pokemon_state\") or {}).get(\"status\",\"nostatus\")!=\"nostatus\")\n",
    "        p2_status=sum(1 for t in p_leave if (t.get(\"p2_pokemon_state\") or {}).get(\"status\",\"nostatus\")!=\"nostatus\")\n",
    "        f['num_bad_status_diff']=float(p2_status-p1_status)\n",
    "    else:\n",
    "        f['num_bad_status_diff']=0.0\n",
    "\n",
    "    if p_leave:\n",
    "        last=p_leave[-1]\n",
    "        p1f=(last.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "        p2f=(last.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "        f['final_hp_diff']=float(p1f-p2f)\n",
    "        p1_alive = 1 if p1f>0 else 0\n",
    "        p2_alive = 1 if p2f>0 else 0\n",
    "        p1_used=len(set([(t.get(\"p1_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p1_pokemon_state\") or {}).get(\"name\")]))\n",
    "        p2_used=len(set([(t.get(\"p2_pokemon_state\") or {}).get(\"name\") for t in p_leave if (t.get(\"p2_pokemon_state\") or {}).get(\"name\")]))\n",
    "        team_size=6\n",
    "        p1_remaining = team_size - p1_used + p1_alive\n",
    "        p2_remaining = team_size - p2_used + p2_alive\n",
    "        f['pokemon_remaining_diff']=float(p1_remaining - p2_remaining)\n",
    "    else:\n",
    "        f['final_hp_diff']=0.0; f['pokemon_remaining_diff']=0.0\n",
    "\n",
    "    if p_leave and len(p_leave)>=2:\n",
    "        total_dmg_dealt=0.0; total_dmg_taken=0.0\n",
    "        for i in range(1,len(p_leave)):\n",
    "            prev, curr = p_leave[i-1], p_leave[i]\n",
    "            p2b=(prev.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            p2a=(curr.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            total_dmg_dealt += max(0,p2b-p2a)\n",
    "            p1b=(prev.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            p1a=(curr.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            total_dmg_taken += max(0,p1b-p1a)\n",
    "        f['damage_ratio'] = float(total_dmg_dealt/total_dmg_taken) if total_dmg_taken>0 else (total_dmg_dealt*10 if total_dmg_dealt>0 else 1.0)\n",
    "        f['tot_damage_diff']=float(total_dmg_dealt-total_dmg_taken)\n",
    "    else:\n",
    "        f['damage_ratio']=1.0; f['tot_damage_diff']=0.0\n",
    "\n",
    "    if p_leave and len(p_leave)>=6:\n",
    "        mid=len(p_leave)//2\n",
    "        first=p_leave[:mid]; second=p_leave[mid:]\n",
    "        p1e=[(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0) for t in first]\n",
    "        p2e=[(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0) for t in first]\n",
    "        p1l=[(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0) for t in second]\n",
    "        p2l=[(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0) for t in second]\n",
    "        early_adv = float(np.mean(p1e)-np.mean(p2e)) if p1e and p2e else 0.0\n",
    "        late_adv  = float(np.mean(p1l)-np.mean(p2l)) if p1l and p2l else 0.0\n",
    "        f['late_game_improvement']=late_adv - early_adv\n",
    "        f['late_game_hp_adv']=late_adv\n",
    "        f['early_game_hp_adv']=early_adv\n",
    "    else:\n",
    "        f['late_game_improvement']=0.0; f['late_game_hp_adv']=0.0; f['early_game_hp_adv']=0.0\n",
    "\n",
    "    if len(p1)>=10 and len(p2)>=10:\n",
    "        f['avg_hp_diff_gap'] = float( (np.mean(p1[5:10]) - np.mean(p2[5:10])) - (np.mean(p1[:5]) - np.mean(p2[:5])) )\n",
    "\n",
    "    if len(p1)>3 and len(p2)>3:\n",
    "        f['p1_hp_std']=float(np.std(np.diff(p1)))\n",
    "        f['p2_hp_std']=float(np.std(np.diff(p2)))\n",
    "\n",
    "    if p1 and p2:\n",
    "        f['max_hp_deficit_player1'] = float(max(0, max(p2) - min(p1)))\n",
    "\n",
    "    total_dealt=total_taken=0.0\n",
    "    for i in range(1,len(tl)):\n",
    "        prev, curr = tl[i-1], tl[i]\n",
    "        if not (isinstance(prev,dict) and isinstance(curr,dict)): continue\n",
    "        weight = 1.0 + (i/len(tl))*0.5\n",
    "        p2_prev=(prev.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",100)\n",
    "        p2_curr=(curr.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",100)\n",
    "        total_dealt += max(0,p2_prev-p2_curr)*weight\n",
    "        p1_prev=(prev.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",100)\n",
    "        p1_curr=(curr.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",100)\n",
    "        total_taken += max(0,p1_prev-p1_curr)*weight\n",
    "    f['damage_trade_ratio_weighted'] = float(total_dealt/max(1,total_taken))\n",
    "\n",
    "    if tl:\n",
    "        last=tl[-1]\n",
    "        p1f=(last.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "        p2f=(last.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "        f['final_hp_advantage']=float(p1f-p2f)\n",
    "        f['final_hp_ratio']=float(p1f/max(1,p2f))\n",
    "        p1_last_pow=(last.get(\"p1_move_details\") or {}).get(\"base_power\",0)\n",
    "        p2_last_pow=(last.get(\"p2_move_details\") or {}).get(\"base_power\",0)\n",
    "        f['final_power_advantage']=float(p1_last_pow - p2_last_pow)\n",
    "        p1_status=(last.get(\"p1_pokemon_state\") or {}).get(\"status\",\"\")\n",
    "        p2_status=(last.get(\"p2_pokemon_state\") or {}).get(\"status\",\"\")\n",
    "        f['final_status_advantage']=0.0\n",
    "        if p2_status and str(p2_status).lower() not in [\"\",\"none\",\"nostatus\"]: f['final_status_advantage'] += 1.0\n",
    "        if p1_status and str(p1_status).lower() not in [\"\",\"none\",\"nostatus\"]: f['final_status_advantage'] -= 1.0\n",
    "\n",
    "        final_score = 0.0\n",
    "        final_score += (p1f - p2f) * 0.5\n",
    "        if p1f>0 and p2f==0: final_score += 30.0\n",
    "        elif p2f>0 and p1f==0: final_score -= 30.0\n",
    "        final_score += (p1_last_pow - p2_last_pow) * 0.15\n",
    "        final_score += f['final_status_advantage'] * 5.0\n",
    "        f['final_battle_score']=final_score\n",
    "        f['final_winning_prob']=1.0/(1.0+np.exp(-final_score/10.0))\n",
    "\n",
    "        recent=tl[-5:] if len(tl)>=5 else tl\n",
    "        diffs=[]\n",
    "        for t in recent:\n",
    "            p1h=(t.get(\"p1_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            p2h=(t.get(\"p2_pokemon_state\") or {}).get(\"hp_pct\",0)\n",
    "            diffs.append(p1h-p2h)\n",
    "        if diffs:\n",
    "            f['recent_avg_hp_advantage']=float(np.mean(diffs))\n",
    "            f['recent_hp_improving']=1.0 if len(diffs)>1 and diffs[-1]>diffs[0] else 0.0\n",
    "\n",
    "    if 'final_hp_advantage' in f and len(tl)>=5:\n",
    "        hp_gap=f['final_hp_advantage']\n",
    "        turns=len(tl)\n",
    "        comeback=0.35\n",
    "        if abs(hp_gap)>50: comeback=0.95\n",
    "        elif abs(hp_gap)>30: comeback=0.75\n",
    "        elif abs(hp_gap)>15: comeback=0.55\n",
    "        if turns<10: comeback*=0.8\n",
    "        elif turns>20: comeback*=1.2\n",
    "        comeback=min(1.0, comeback)\n",
    "        win_prob = 0.5 + (comeback*0.5) if hp_gap>0 else 0.5 - (comeback*0.5)\n",
    "        f['comeback_difficulty']=float(comeback)\n",
    "        f['predicted_win_prob']=float(win_prob)\n",
    "\n",
    "    if p1 and p2 and len(tl)>=3:\n",
    "        p1_current_hp=p1[-1]; p2_current_hp=p2[-1]\n",
    "        pattern_score=0.0\n",
    "        p1_kos=sum(1 for hp in p2 if hp==0); p2_kos=sum(1 for hp in p1 if hp==0)\n",
    "        ko_adv = p1_kos - p2_kos\n",
    "        if ko_adv>=2: pattern_score+=0.3\n",
    "        elif ko_adv==1: pattern_score+=0.15\n",
    "        elif ko_adv==-1: pattern_score-=0.15\n",
    "        elif ko_adv<=-2: pattern_score-=0.3\n",
    "        if len(p1)>=5 and len(p2)>=5:\n",
    "            p1_trend = np.mean(p1[-3:]) - np.mean(p1[-5:-2])\n",
    "            p2_trend = np.mean(p2[-3:]) - np.mean(p2[-5:-2])\n",
    "            if p1_trend>5 and p2_trend<-5: pattern_score+=0.2\n",
    "            elif p1_trend<-5 and p2_trend>5: pattern_score-=0.2\n",
    "\n",
    "        p1_used=set(); p2_used=set()\n",
    "        for t in tl:\n",
    "            if isinstance(t,dict):\n",
    "                p1n=(t.get(\"p1_pokemon_state\") or {}).get(\"name\",\"\")\n",
    "                p2n=(t.get(\"p2_pokemon_state\") or {}).get(\"name\",\"\")\n",
    "                if p1n: p1_used.add(p1n)\n",
    "                if p2n: p2_used.add(p2n)\n",
    "        team_size=6\n",
    "        p1_rem=team_size - len(p1_used) + (1 if p1_current_hp>0 else 0)\n",
    "        p2_rem=team_size - len(p2_used) + (1 if p2_current_hp>0 else 0)\n",
    "        pokemon_adv = p1_rem - p2_rem\n",
    "        if pokemon_adv>=2: pattern_score+=0.35\n",
    "        elif pokemon_adv==1: pattern_score+=0.20\n",
    "        elif pokemon_adv==-1: pattern_score-=0.20\n",
    "        elif pokemon_adv<=-2: pattern_score-=0.35\n",
    "\n",
    "        f['ko_advantage']=float(ko_adv)\n",
    "        f['estimated_pokemon_remaining_p1']=float(p1_rem)\n",
    "        f['estimated_pokemon_remaining_p2']=float(p2_rem)\n",
    "        f['pokemon_advantage']=float(pokemon_adv)\n",
    "        base_prob=0.5\n",
    "        if 'final_hp_advantage' in f: base_prob += (f['final_hp_advantage']/100.0)*0.3\n",
    "        base_prob += pattern_score*0.4\n",
    "        if 'predicted_win_prob' in f: base_prob = base_prob*0.7 + f['predicted_win_prob']*0.3\n",
    "        f['final_win_probability']=max(0.0,min(1.0,base_prob))\n",
    "\n",
    "    if 'final_win_probability' in f:\n",
    "        prob=f['final_win_probability']\n",
    "        confidence = abs(prob-0.5)*2\n",
    "        if f.get('p1_alive_final',0)==1 and f.get('p2_alive_final',0)==0: confidence=0.95\n",
    "        elif f.get('p1_alive_final',0)==0 and f.get('p2_alive_final',0)==1: confidence=0.95\n",
    "        f['prediction_confidence']=float(confidence)\n",
    "        if prob>0.75 and confidence>0.6: f['outcome_prediction']=2.0\n",
    "        elif prob>0.6: f['outcome_prediction']=1.0\n",
    "        elif prob<0.25 and confidence>0.6: f['outcome_prediction']=-2.0\n",
    "        elif prob<0.4: f['outcome_prediction']=-1.0\n",
    "        else: f['outcome_prediction']=0.0\n",
    "    return f\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Global stats built on train_data \n",
    "# ---------------------------------------------\n",
    "POKEMON_STATS    = build_pokemon_win_stats(train_data, alpha=1.0)\n",
    "POKEMON_HP_STATS = build_pokemon_hp_stats(train_data)\n",
    "pokemon_avg_damage = build_pokemon_avg_damage(train_data)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Full feature set (static + timeline + moves + Mirko & Deb)\n",
    "# ---------------------------------------------\n",
    "def _one_record_features(r):\n",
    "    # Static team features\n",
    "    t1 = r.get(\"p1_team_details\", []) or []\n",
    "    lead = r.get(\"p2_lead_details\", {}) or {}\n",
    "    t2 = [lead] if isinstance(lead, dict) and lead else []\n",
    "\n",
    "    p1sz = len(t1); p2sz = len(t2)\n",
    "    p1u  = unique_types(t1); p2u = unique_types(t2)\n",
    "    p1s  = sum_stats_of_team(t1); p2s = sum_stats_of_team(t2)\n",
    "    p1a  = avg_stats_of_team(t1); p2a = avg_stats_of_team(t2)\n",
    "    p2_ls, p2_la = sum_and_avg_of_single(lead) if lead else (0.0, 0.0)\n",
    "    p1v  = team_stat_variance(t1)\n",
    "\n",
    "    f = {\n",
    "        \"p1_team_size\": p1sz, \"p2_team_size\": p2sz,\n",
    "        \"p1_unique_types\": p1u, \"p2_unique_types\": p2u,\n",
    "        \"p1_team_stat_sum\": p1s, \"p2_team_stat_sum\": p2s,\n",
    "        \"p1_team_stat_avg\": p1a, \"p2_team_stat_avg\": p2a,\n",
    "        \"diff_team_size\": p1sz - p2sz,\n",
    "        \"diff_unique_types\": p1u - p2u,\n",
    "        \"diff_team_stat_sum\": p1s - p2s,\n",
    "        \"diff_team_stat_avg\": p1a - p2a,\n",
    "        \"p2_lead_stat_sum\": p2_ls, \"p2_lead_stat_avg\": p2_la,\n",
    "        \"p1_sum_minus_p2_lead_sum\": p1s - p2_ls,\n",
    "        \"p1_avg_minus_p2_lead_avg\": p1a - p2_la,\n",
    "        \"p1_team_stat_var\": p1v,\n",
    "        \"ratio_p1_avg_over_p2_lead_avg\": _safe_ratio(p1a, p2_la),\n",
    "    }\n",
    "\n",
    "    # Speed advantage vs p2 lead\n",
    "    p1_mean_spe, p1_max_spe = _team_speed_stats(t1)\n",
    "    p2_lead_spe = float(lead.get(\"base_spe\", 0.0)) if lead else 0.0\n",
    "    faster_cnt = sum(1 for p in t1 if isinstance(p.get(\"base_spe\"),(int,float)) and float(p[\"base_spe\"])>p2_lead_spe)\n",
    "    frac_faster = float(faster_cnt)/max(1,len(t1))\n",
    "    f.update({\n",
    "        \"p1_mean_spe\": p1_mean_spe, \"p1_max_spe\": p1_max_spe, \"p2_lead_spe\": p2_lead_spe,\n",
    "        \"spe_mean_adv\": p1_mean_spe - p2_lead_spe, \"spe_max_adv\": p1_max_spe - p2_lead_spe,\n",
    "        \"p1_frac_faster_than_p2lead\": frac_faster,\n",
    "    })\n",
    "\n",
    "    # Timeline HP features\n",
    "    tl = get_timeline(r, max_turns=30)\n",
    "    p1, p2 = _extract_hp_series(tl)\n",
    "    diff = [a-b for a,b in zip(p1,p2)] if p1 and p2 and len(p1)==len(p2) else []\n",
    "\n",
    "    p1m,p1l,p1s_,p1mn = _mean_last_std_min(p1)\n",
    "    p2m,p2l,p2s_,p2mn = _mean_last_std_min(p2)\n",
    "    dm,dl,ds,dmn = _mean_last_std_min(diff)\n",
    "\n",
    "    f.update({\n",
    "        \"tl_turns_used\": float(len(tl)),\n",
    "        \"tl_p1_hp_mean\": p1m, \"tl_p1_hp_last\": p1l, \"tl_p1_hp_std\": p1s_, \"tl_p1_hp_min\": p1mn,\n",
    "        \"tl_p2_hp_mean\": p2m, \"tl_p2_hp_last\": p2l, \"tl_p2_hp_std\": p2s_, \"tl_p2_hp_min\": p2mn,\n",
    "        \"tl_hp_diff_mean\": dm, \"tl_hp_diff_last\": dl, \"tl_hp_diff_std\": ds, \"tl_hp_diff_min\": dmn,\n",
    "        \"tl_p1_hp_slope\": _slope(p1), \"tl_p2_hp_slope\": _slope(p2), \"tl_hp_diff_slope\": _slope(diff),\n",
    "        \"tl_p1_hp_auc\": _auc_pct(p1), \"tl_p2_hp_auc\": _auc_pct(p2),\n",
    "        \"tl_frac_turns_advantage\": _frac_positive(diff),\n",
    "        \"tl_p1_status_count\": _status_count(tl,\"p1\"),\n",
    "        \"tl_p2_status_count\": _status_count(tl,\"p2\"),\n",
    "    })\n",
    "    f[\"tl_status_count\"] = f[\"tl_p1_status_count\"] + f[\"tl_p2_status_count\"]\n",
    "    f[\"tl_p1_ko_count\"]  = _ko_count(p1)\n",
    "    f[\"tl_p2_ko_count\"]  = _ko_count(p2)\n",
    "    f[\"tl_ko_count\"]     = f[\"tl_p1_ko_count\"] + f[\"tl_p2_ko_count\"]\n",
    "\n",
    "    # Type effectiveness P1 ‚Üí P2 lead\n",
    "    p2_types = lead.get(\"types\") or []\n",
    "    if isinstance(p2_types,str): p2_types=[p2_types]\n",
    "    p2_types=[t for t in p2_types if t]\n",
    "    f.update({\n",
    "        \"ter_p1_vs_p2lead_full\": _avg_type_eff_p1_vs_p2lead(tl, p2_types, window=None),\n",
    "        \"ter_p1_vs_p2lead_5\":    _avg_type_eff_p1_vs_p2lead(tl, p2_types, window=5),\n",
    "        \"ter_p1_vs_p2lead_10\":   _avg_type_eff_p1_vs_p2lead(tl, p2_types, window=10),\n",
    "    })\n",
    "\n",
    "    # --- New safe, bounded features (add near the end of _one_record_features) ---\n",
    "\n",
    "    # 1) Team offensive tilt: physical vs special (bounded, finite)\n",
    "    p1_sum_atk = float(sum(p.get(\"base_atk\", 0) for p in t1 if isinstance(p, dict)))\n",
    "    p1_sum_spa = float(sum(p.get(\"base_spa\", 0) for p in t1 if isinstance(p, dict)))\n",
    "    f[\"p1_offense_bias_ratio\"] = (p1_sum_atk + 1e-3) / (p1_sum_spa + 1e-3)  # >1 => more physical tilt\n",
    "    f[\"p1_offense_balance_gap\"] = p1_sum_atk - p1_sum_spa\n",
    "    \n",
    "    # 2) Defensive overlap: shared-weakness burden (small integers / means)\n",
    "    def _count_weaknesses_of_types(types):\n",
    "        prof = get_defensive_profile(types or [])\n",
    "        return float(sum(1 for m in prof.values() if m > 1.0))\n",
    "    \n",
    "    p1_weak_counts = []\n",
    "    for p in t1:\n",
    "        if isinstance(p, dict):\n",
    "            p1_weak_counts.append(_count_weaknesses_of_types(p.get(\"types\", [])))\n",
    "    \n",
    "    f[\"p1_weakness_mean\"] = float(np.mean(p1_weak_counts)) if p1_weak_counts else 0.0\n",
    "    f[\"p1_weakness_max\"]  = float(np.max(p1_weak_counts))  if p1_weak_counts else 0.0\n",
    "    \n",
    "    # 3) Breadth of resistances (unique resistances union)\n",
    "    def _unique_resistances(types):\n",
    "        prof = get_defensive_profile(types or [])\n",
    "        return {atk for atk, mult in prof.items() if 0.0 < mult < 1.0}\n",
    "    \n",
    "    res_sets = []\n",
    "    for p in t1:\n",
    "        if isinstance(p, dict):\n",
    "            res_sets.append(_unique_resistances(p.get(\"types\", [])))\n",
    "    union_res = set().union(*res_sets) if res_sets else set()\n",
    "    f[\"p1_unique_resistances\"] = float(len(union_res))\n",
    "    \n",
    "    # 4) Early HP volatility (first 5 turns), bounded by [0,100] deltas\n",
    "    def _safe_clip_hp(seq):\n",
    "        return [max(0.0, min(100.0, float(x))) for x in seq]\n",
    "    \n",
    "    def _mean_abs_step(arr):\n",
    "        return float(np.mean([abs(arr[i] - arr[i-1]) for i in range(1, len(arr))])) if len(arr) > 1 else 0.0\n",
    "    \n",
    "    p1_hp5 = _safe_clip_hp(_window(p1, 5))\n",
    "    p2_hp5 = _safe_clip_hp(_window(p2, 5))\n",
    "    f[\"p1_hp_abs_step_5\"] = _mean_abs_step(p1_hp5)\n",
    "    f[\"p2_hp_abs_step_5\"] = _mean_abs_step(p2_hp5)\n",
    "    f[\"hp_abs_step_gap_5\"] = f[\"p1_hp_abs_step_5\"] - f[\"p2_hp_abs_step_5\"]\n",
    "    \n",
    "    # 5) Hazards effectiveness given switches (difference version; robust via f.get)\n",
    "    haz_p1 = float(f.get(\"hazard_p1_flag\", 0.0))\n",
    "    haz_p2 = float(f.get(\"hazard_p2_flag\", 0.0))\n",
    "    sw_p1  = float(f.get(\"switch_p1_count\", 0.0))\n",
    "    sw_p2  = float(f.get(\"switch_p2_count\", 0.0))\n",
    "    haz_sw_p1 = haz_p1 * sw_p2\n",
    "    haz_sw_p2 = haz_p2 * sw_p1\n",
    "    f[\"hazard_switch_pressure_diff\"] = haz_sw_p1 - haz_sw_p2\n",
    "    \n",
    "    # 6) Late-game move accuracy advantage (last 5 turns), safe mean\n",
    "    def _avg_acc_lastN(timeline, who, n=5):\n",
    "        seq = timeline[-n:] if len(timeline) >= n else timeline\n",
    "        accs = []\n",
    "        for t in seq:\n",
    "            md = (t.get(f\"{who}_move_details\") or {})\n",
    "            a = md.get(\"accuracy\", None)\n",
    "            if isinstance(a, (int, float)):\n",
    "                accs.append(float(a))\n",
    "        return float(np.mean(accs)) if accs else 0.0\n",
    "    \n",
    "    f[\"late_acc_adv_5\"] = _avg_acc_lastN(tl, \"p1\", 5) - _avg_acc_lastN(tl, \"p2\", 5)\n",
    "\n",
    "    # --- Move-based features (full & 5 turns) ---\n",
    "    mv1_full = _move_stats_for_side(tl, \"p1\", None)\n",
    "    mv2_full = _move_stats_for_side(tl, \"p2\", None)\n",
    "    f.update(mv1_full); f.update(mv2_full)\n",
    "    f[\"mv_power_mean_ratio\"]  = _safe_ratio(mv1_full[\"mv_p1_power_mean\"], mv2_full[\"mv_p2_power_mean\"])\n",
    "    mv1_5 = _move_stats_for_side(tl, \"p1\", 5)\n",
    "    mv2_5 = _move_stats_for_side(tl, \"p2\", 5)\n",
    "    f.update(mv1_5); f.update(mv2_5)\n",
    "    \n",
    "    f[\"mv_power_mean_ratio_5\"] = _safe_ratio(mv1_5[\"mv_p1_power_mean_5\"], mv2_5[\"mv_p2_power_mean_5\"])\n",
    "    \n",
    "    # Matchup / switches / hazards / momentum / recovery / STAB / early / priority\n",
    "    f.update(_p1_vs_p2lead_matchup_index(r, tl))\n",
    "    f[\"switch_p1_count\"]=_switch_count(tl,\"p1\"); f[\"switch_p2_count\"]=_switch_count(tl,\"p2\")\n",
    "    f[\"switch_count_diff\"]=f[\"switch_p1_count\"]-f[\"switch_p2_count\"]\n",
    "    f.update(_hazard_flags(tl))\n",
    "    f.update(_recovery_pressure(tl))\n",
    "    f.update(_stab_features(r, max_turns=30))\n",
    "    f.update(_early_momentum_features(r, first_n=3))\n",
    "    f.update(_priority_feature_block(r))\n",
    "    f.update(new_features(r))\n",
    "    f.update(new_features_deb(r))\n",
    "    f.update(new_features_mirko(r))\n",
    "\n",
    "    # Team Winrate / HP resilience / Avg damage\n",
    "    try:\n",
    "        p1_team_names=_pnames_from_p1_team(r)\n",
    "        f[\"p1_team_winrate_score\"]=team_score_from_stats(p1_team_names, POKEMON_STATS, default_wr=0.5)\n",
    "    except Exception:\n",
    "        f[\"p1_team_winrate_score\"]=0.5\n",
    "    p1_names=_pnames_from_p1_team(r)\n",
    "    p2_name=_pname_from_p2_lead(r)\n",
    "    f[\"p1_team_avg_hp_score\"]=team_hp_score(p1_names, POKEMON_HP_STATS)\n",
    "    f[\"p2_lead_avg_hp\"]=POKEMON_HP_STATS.get(p2_name,{}).get(\"hp_mean\",50.0)\n",
    "    f[\"hp_resilience_diff\"]=f[\"p1_team_avg_hp_score\"] - f[\"p2_lead_avg_hp\"]\n",
    "    f[\"predicted_win_by_hp\"]=1.0 if f[\"hp_resilience_diff\"]>0 else 0.0\n",
    "\n",
    "    f.update(damage_feature_for_battle(r, pokemon_avg_damage))\n",
    "\n",
    "    # IDs / target\n",
    "    f[\"battle_id\"]=r.get(\"battle_id\")\n",
    "    if \"player_won\" in r:\n",
    "        f[\"player_won\"]= int(r[\"player_won\"]) if isinstance(r[\"player_won\"], bool) else r[\"player_won\"]\n",
    "    return f\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Public API (same name & return type as starter)\n",
    "# ---------------------------------------------\n",
    "def create_simple_features(data: list[dict]) -> pd.DataFrame:\n",
    "    rows=[]\n",
    "    for battle in tqdm(data, desc=\"Extracting features\"):\n",
    "        rows.append(_one_record_features(battle))\n",
    "    return pd.DataFrame(rows).fillna(0)\n",
    "\n",
    "# ---------------------------------------------\n",
    "# Run feature extraction\n",
    "# ---------------------------------------------\n",
    "print(\"Processing training data...\")\n",
    "train_df = create_simple_features(train_data)\n",
    "\n",
    "print(\"\\nProcessing test data...\")\n",
    "test_data = []\n",
    "with open(test_file_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        test_data.append(json.loads(line))\n",
    "test_df = create_simple_features(test_data)\n",
    "\n",
    "print(\"\\nTraining features preview:\")\n",
    "\n",
    "# --- Manual interactions (robust to missing columns) ---\n",
    "def _maybe_add_interactions(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def safe_mul(a, b, name):\n",
    "        if a in df.columns and b in df.columns:\n",
    "            df[name] = df[a] * df[b]\n",
    "\n",
    "    # Team strength √ó move power (full)\n",
    "    safe_mul(\"p1_team_stat_avg\", \"mv_p1_power_mean\", \"ix_p1avg_x_p1pow\")\n",
    "    # Speed √ó priority advantage (first 5 turns if available)\n",
    "    if \"spe_max_adv\" in df.columns and \"mv_priority_count_diff_5\" in df.columns:\n",
    "        df[\"ix_speed_x_prio5\"] = df[\"spe_max_adv\"] * df[\"mv_priority_count_diff_5\"]\n",
    "    # HP momentum √ó fraction of advantaged turns\n",
    "    safe_mul(\"tl_hp_diff_mean\", \"tl_frac_turns_advantage\", \"ix_hpmean_x_fracadv\")\n",
    "    # Early momentum √ó priority diff (first 5)\n",
    "    if \"early_hp_diff_mean_3\" in df.columns and \"mv_priority_count_diff_5\" in df.columns:\n",
    "        df[\"ix_early3_x_prio5\"] = df[\"early_hp_diff_mean_3\"] * df[\"mv_priority_count_diff_5\"]\n",
    "    # STAB advantage √ó early KO score\n",
    "    if \"stab_stab_ratio_diff_full\" in df.columns and \"early_first_ko_score_3\" in df.columns:\n",
    "        df[\"ix_stabdiff_x_firstko\"] = df[\"stab_stab_ratio_diff_full\"] * df[\"early_first_ko_score_3\"]\n",
    "    # Type effectiveness √ó STAB (full)\n",
    "    if \"ter_p1_vs_p2lead_full\" in df.columns and \"stab_stab_ratio_diff_full\" in df.columns:\n",
    "        df[\"ix_ter_x_stab_full\"] = df[\"ter_p1_vs_p2lead_full\"] * df[\"stab_stab_ratio_diff_full\"]\n",
    "    # Type effectiveness √ó early momentum (first 3)\n",
    "    if \"ter_p1_vs_p2lead_5\" in df.columns and \"early_hp_diff_mean_3\" in df.columns:\n",
    "        df[\"ix_ter5_x_early3\"] = df[\"ter_p1_vs_p2lead_5\"] * df[\"early_hp_diff_mean_3\"]\n",
    "    # Lead matchup √ó early momentum\n",
    "    if \"lead_matchup_p1_index_5\" in df.columns and \"early_hp_diff_mean_3\" in df.columns:\n",
    "        df[\"ix_leadmatch5_x_early3\"] = df[\"lead_matchup_p1_index_5\"] * df[\"early_hp_diff_mean_3\"]\n",
    "    # Hazards advantage √ó priority pressure\n",
    "    if \"hazard_flag_diff\" in df.columns and \"mv_priority_count_diff_5\" in df.columns:\n",
    "        df[\"ix_hazards_x_prio5\"] = df[\"hazard_flag_diff\"] * df[\"mv_priority_count_diff_5\"]\n",
    "    return df\n",
    "\n",
    "train_df = _maybe_add_interactions(train_df)\n",
    "test_df  = _maybe_add_interactions(test_df)\n",
    "\n",
    "# Keep raw copies\n",
    "train_df_raw = train_df.copy()\n",
    "test_df_raw  = test_df.copy()\n",
    "\n",
    "# ---- No scaling here (we'll scale inside the Pipeline in Cell 3.2) ----\n",
    "# 1) Make sure features are numeric, to avoid casting issues downstream\n",
    "num_cols = [c for c in train_df.columns if c not in (\"battle_id\", \"player_won\")]\n",
    "train_df[num_cols] = train_df[num_cols].apply(pd.to_numeric, errors=\"coerce\").astype(\"float32\")\n",
    "test_df[num_cols]  = test_df[num_cols].apply(pd.to_numeric, errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "# 2) Replace inf/-inf with NaN (safer for imputers)\n",
    "tr_vals = train_df[num_cols].to_numpy()\n",
    "te_vals = test_df[num_cols].to_numpy()\n",
    "tr_vals[~np.isfinite(tr_vals)] = np.nan\n",
    "te_vals[~np.isfinite(te_vals)] = np.nan\n",
    "train_df[num_cols] = tr_vals\n",
    "test_df[num_cols]  = te_vals\n",
    "\n",
    "# 3) Clip percent-like fields to sensible bounds (do it raw, not scaled)\n",
    "num_only = train_df.drop(columns=[\"battle_id\",\"player_won\"], errors=\"ignore\").select_dtypes(include=[np.number])\n",
    "percent_like = [x for x in num_only.columns if (\"hp\" in x.lower()) or (\"auc\" in x.lower())]\n",
    "for c in percent_like:\n",
    "    if c in train_df.columns:\n",
    "        train_df[c] = train_df[c].clip(lower=0, upper=100)\n",
    "        test_df[c]  = test_df[c].clip(lower=0, upper=100)\n",
    "\n",
    "# 4) Flag near-constants (‚â•99% same value) ‚Äî info only\n",
    "near_const = [c for c in num_only.columns if (num_only[c].nunique(dropna=True) / max(1, len(num_only)) < 0.01)]\n",
    "print(f\"[Sanity] Near-constant features (not dropping yet): {len(near_const)}\")\n",
    "\n",
    "# === 2.x Custom predictive features (safe: no NaN, no div-by-zero) ===\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "EPS = 1e-6\n",
    "REPLACE_EXISTING = True  # set to False to skip creation if a feature name already exists\n",
    "\n",
    "def _pick_first(df: pd.DataFrame, candidates, default_value=0.0):\n",
    "    \"\"\"Return the first existing column from candidates; else a float32 Series filled with default_value.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return df[c].astype(\"float32\")\n",
    "    return pd.Series(default_value, index=df.index, dtype=\"float32\")\n",
    "\n",
    "def _safe_div(a: pd.Series, b: pd.Series):\n",
    "    \"\"\"Elementwise safe division a/(b+EPS) with finite output.\"\"\"\n",
    "    out = a.astype(\"float32\") / (b.astype(\"float32\") + EPS)\n",
    "    out = out.replace([np.inf, -np.inf], 0.0).fillna(0.0).astype(\"float32\")\n",
    "    return out\n",
    "\n",
    "def _ensure_float32(s: pd.Series):\n",
    "    return s.astype(\"float32\").replace([np.inf, -np.inf], 0.0).fillna(0.0)\n",
    "\n",
    "def _normalize_acc(s: pd.Series):\n",
    "    \"\"\"If accuracy looks like [0..100], scale to [0..1].\"\"\"\n",
    "    s = _ensure_float32(s)\n",
    "    if len(s):\n",
    "        maxv = float(np.nanmax(s.values))\n",
    "    else:\n",
    "        maxv = 0.0\n",
    "    if maxv > 1.5:  # heuristically assume it's a percentage\n",
    "        s = s / 100.0\n",
    "    return s.clip(0.0, 1.0)\n",
    "\n",
    "def _add_feature_pair(train_df, test_df, name, train_series, test_series):\n",
    "    \"\"\"Attach float32 features to both train and test with final sanitation.\"\"\"\n",
    "    if (not REPLACE_EXISTING) and (name in train_df.columns or name in test_df.columns):\n",
    "        return\n",
    "    train_df[name] = _ensure_float32(train_series)\n",
    "    test_df[name]  = _ensure_float32(test_series)\n",
    "\n",
    "# --- Robust base columns (try multiple candidates, fall back to zeros) ---\n",
    "\n",
    "# Attack / Defense (means)\n",
    "atk_p1 = _pick_first(train_df, [\"atk_p1_mean\",\"atk_p1\",\"atk_p1_full\"], 0.0)\n",
    "atk_p2 = _pick_first(train_df, [\"atk_p2_mean\",\"atk_p2\",\"atk_p2_full\"], 0.0)\n",
    "def_p1 = _pick_first(train_df, [\"def_p1_mean\",\"def_p1\",\"def_p1_full\"], 0.0)\n",
    "def_p2 = _pick_first(train_df, [\"def_p2_mean\",\"def_p2\",\"def_p2_full\"], 0.0)\n",
    "\n",
    "atk_p1_te = _pick_first(test_df, [\"atk_p1_mean\",\"atk_p1\",\"atk_p1_full\"], 0.0)\n",
    "atk_p2_te = _pick_first(test_df, [\"atk_p2_mean\",\"atk_p2\",\"atk_p2_full\"], 0.0)\n",
    "def_p1_te = _pick_first(test_df, [\"def_p1_mean\",\"def_p1\",\"def_p1_full\"], 0.0)\n",
    "def_p2_te = _pick_first(test_df, [\"def_p2_mean\",\"def_p2\",\"def_p2_full\"], 0.0)\n",
    "\n",
    "# Special Attack / Defense (means)\n",
    "sp_atk_p1 = _pick_first(train_df, [\"sp_atk_p1_mean\",\"spatk_p1_mean\",\"spa_p1_mean\",\"sp_atk_p1\"], 0.0)\n",
    "sp_atk_p2 = _pick_first(train_df, [\"sp_atk_p2_mean\",\"spatk_p2_mean\",\"spa_p2_mean\",\"sp_atk_p2\"], 0.0)\n",
    "sp_def_p1 = _pick_first(train_df, [\"sp_def_p1_mean\",\"spdef_p1_mean\",\"spd_p1_mean_def\",\"sp_def_p1\"], 0.0)\n",
    "sp_def_p2 = _pick_first(train_df, [\"sp_def_p2_mean\",\"spdef_p2_mean\",\"spd_p2_mean_def\",\"sp_def_p2\"], 0.0)\n",
    "\n",
    "sp_atk_p1_te = _pick_first(test_df, [\"sp_atk_p1_mean\",\"spatk_p1_mean\",\"spa_p1_mean\",\"sp_atk_p1\"], 0.0)\n",
    "sp_atk_p2_te = _pick_first(test_df, [\"sp_atk_p2_mean\",\"spatk_p2_mean\",\"spa_p2_mean\",\"sp_atk_p2\"], 0.0)\n",
    "sp_def_p1_te = _pick_first(test_df, [\"sp_def_p1_mean\",\"spdef_p1_mean\",\"spd_p1_mean_def\",\"sp_def_p1\"], 0.0)\n",
    "sp_def_p2_te = _pick_first(test_df, [\"sp_def_p2_mean\",\"spdef_p2_mean\",\"spd_p2_mean_def\",\"sp_def_p2\"], 0.0)\n",
    "\n",
    "# Speed (means)\n",
    "spd_p1 = _pick_first(train_df, [\"spd_p1_mean\",\"speed_p1_mean\",\"spd_p1\"], 0.0)\n",
    "spd_p2 = _pick_first(train_df, [\"spd_p2_mean\",\"speed_p2_mean\",\"spd_p2\"], 0.0)\n",
    "spd_p1_te = _pick_first(test_df,  [\"spd_p1_mean\",\"speed_p1_mean\",\"spd_p1\"], 0.0)\n",
    "spd_p2_te = _pick_first(test_df,  [\"spd_p2_mean\",\"speed_p2_mean\",\"spd_p2\"], 0.0)\n",
    "\n",
    "# HP current / max\n",
    "hp1_cur = _pick_first(train_df, [\"hp_p1_remain\",\"hp_p1_curr\",\"hp_p1\"], 0.0)\n",
    "hp2_cur = _pick_first(train_df, [\"hp_p2_remain\",\"hp_p2_curr\",\"hp_p2\"], 0.0)\n",
    "hp1_max = _pick_first(train_df, [\"hp_p1_max\",\"hp_p1_base\",\"hp_p1_total\"], 1.0)\n",
    "hp2_max = _pick_first(train_df, [\"hp_p2_max\",\"hp_p2_base\",\"hp_p2_total\"], 1.0)\n",
    "\n",
    "hp1_cur_te = _pick_first(test_df, [\"hp_p1_remain\",\"hp_p1_curr\",\"hp_p1\"], 0.0)\n",
    "hp2_cur_te = _pick_first(test_df, [\"hp_p2_remain\",\"hp_p2_curr\",\"hp_p2\"], 0.0)\n",
    "hp1_max_te = _pick_first(test_df, [\"hp_p1_max\",\"hp_p1_base\",\"hp_p1_total\"], 1.0)\n",
    "hp2_max_te = _pick_first(test_df, [\"hp_p2_max\",\"hp_p2_base\",\"hp_p2_total\"], 1.0)\n",
    "\n",
    "# Move power / accuracy\n",
    "pwr_p1 = _pick_first(train_df, [\"mv_p1_power_mean_full\",\"mv_p1_power_mean\",\"mv_power_p1_mean\"], 0.0)\n",
    "pwr_p2 = _pick_first(train_df, [\"mv_p2_power_mean_full\",\"mv_p2_power_mean\",\"mv_power_p2_mean\"], 0.0)\n",
    "acc_p1 = _normalize_acc(_pick_first(train_df, [\"mv_p1_acc_mean_full\",\"mv_p1_acc_mean\",\"mv_acc_p1_mean\"], 0.0))\n",
    "acc_p2 = _normalize_acc(_pick_first(train_df, [\"mv_p2_acc_mean_full\",\"mv_p2_acc_mean\",\"mv_acc_p2_mean\"], 0.0))\n",
    "\n",
    "pwr_p1_te = _pick_first(test_df, [\"mv_p1_power_mean_full\",\"mv_p1_power_mean\",\"mv_power_p1_mean\"], 0.0)\n",
    "pwr_p2_te = _pick_first(test_df, [\"mv_p2_power_mean_full\",\"mv_p2_power_mean\",\"mv_power_p2_mean\"], 0.0)\n",
    "acc_p1_te = _normalize_acc(_pick_first(test_df, [\"mv_p1_acc_mean_full\",\"mv_p1_acc_mean\",\"mv_acc_p1_mean\"], 0.0))\n",
    "acc_p2_te = _normalize_acc(_pick_first(test_df, [\"mv_p2_acc_mean_full\",\"mv_p2_acc_mean\",\"mv_acc_p2_mean\"], 0.0))\n",
    "\n",
    "# Move type counts (STATUS / PHYSICAL / SPECIAL) ‚Äî safe fallbacks\n",
    "st_p1 = _pick_first(train_df, [\"mv_p1_count_STATUS_full\",\"mv_p1_count_STATUS\",\"status_moves_p1\"], 0.0)\n",
    "ph_p1 = _pick_first(train_df, [\"mv_p1_count_PHYSICAL_full\",\"mv_p1_count_PHYSICAL\",\"physical_moves_p1\"], 0.0)\n",
    "sp_p1 = _pick_first(train_df, [\"mv_p1_count_SPECIAL_full\",\"mv_p1_count_SPECIAL\",\"special_moves_p1\"], 0.0)\n",
    "st_p2 = _pick_first(train_df, [\"mv_p2_count_STATUS_full\",\"mv_p2_count_STATUS\",\"status_moves_p2\"], 0.0)\n",
    "ph_p2 = _pick_first(train_df, [\"mv_p2_count_PHYSICAL_full\",\"mv_p2_count_PHYSICAL\",\"physical_moves_p2\"], 0.0)\n",
    "sp_p2 = _pick_first(train_df, [\"mv_p2_count_SPECIAL_full\",\"mv_p2_count_SPECIAL\",\"special_moves_p2\"], 0.0)\n",
    "\n",
    "st_p1_te = _pick_first(test_df, [\"mv_p1_count_STATUS_full\",\"mv_p1_count_STATUS\",\"status_moves_p1\"], 0.0)\n",
    "ph_p1_te = _pick_first(test_df, [\"mv_p1_count_PHYSICAL_full\",\"mv_p1_count_PHYSICAL\",\"physical_moves_p1\"], 0.0)\n",
    "sp_p1_te = _pick_first(test_df, [\"mv_p1_count_SPECIAL_full\",\"mv_p1_count_SPECIAL\",\"special_moves_p1\"], 0.0)\n",
    "st_p2_te = _pick_first(test_df, [\"mv_p2_count_STATUS_full\",\"mv_p2_count_STATUS\",\"status_moves_p2\"], 0.0)\n",
    "ph_p2_te = _pick_first(test_df, [\"mv_p2_count_PHYSICAL_full\",\"mv_p2_count_PHYSICAL\",\"physical_moves_p2\"], 0.0)\n",
    "sp_p2_te = _pick_first(test_df, [\"mv_p2_count_SPECIAL_full\",\"mv_p2_count_SPECIAL\",\"special_moves_p2\"], 0.0)\n",
    "\n",
    "# ===============================\n",
    "# 10 SAFE, HIGH-SIGNAL FEATURES\n",
    "# ===============================\n",
    "\n",
    "# 1) atk_def_ratio: P1 attack vs P2 defense\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"atk_def_ratio\",\n",
    "    _safe_div(atk_p1, def_p2),\n",
    "    _safe_div(atk_p1_te, def_p2_te)\n",
    ")\n",
    "\n",
    "# 2) spd_gap: P1 speed minus P2 speed\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"spd_gap\",\n",
    "    (spd_p1 - spd_p2),\n",
    "    (spd_p1_te - spd_p2_te)\n",
    ")\n",
    "\n",
    "# 3) hp_ratio: P1 current HP vs P2 current HP\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"hp_ratio\",\n",
    "    _safe_div(hp1_cur, hp2_cur),\n",
    "    _safe_div(hp1_cur_te, hp2_cur_te)\n",
    ")\n",
    "\n",
    "# 4) survival_score: (P1 HP%) - (P2 HP%)\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"survival_score\",\n",
    "    _safe_div(hp1_cur, hp1_max) - _safe_div(hp2_cur, hp2_max),\n",
    "    _safe_div(hp1_cur_te, hp1_max_te) - _safe_div(hp2_cur_te, hp2_max_te)\n",
    ")\n",
    "\n",
    "# 5) momentum_index: (atk*spd)_P1 / (atk*spd)_P2\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"momentum_index\",\n",
    "    _safe_div(atk_p1 * spd_p1, atk_p2 * spd_p2),\n",
    "    _safe_div(atk_p1_te * spd_p1_te, atk_p2_te * spd_p2_te)\n",
    ")\n",
    "\n",
    "# 6) power_acc_gap: (avg power weighted by acc) P1 - P2\n",
    "pwa_p1 = _ensure_float32(pwr_p1 * acc_p1)\n",
    "pwa_p2 = _ensure_float32(pwr_p2 * acc_p2)\n",
    "pwa_p1_te = _ensure_float32(pwr_p1_te * acc_p1_te)\n",
    "pwa_p2_te = _ensure_float32(pwr_p2_te * acc_p2_te)\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"power_acc_gap\",\n",
    "    (pwa_p1 - pwa_p2),\n",
    "    (pwa_p1_te - pwa_p2_te)\n",
    ")\n",
    "\n",
    "# 7) offensive_balance: (atk + sp_atk) P1 / P2\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"offensive_balance\",\n",
    "    _safe_div(atk_p1 + sp_atk_p1, atk_p2 + sp_atk_p2),\n",
    "    _safe_div(atk_p1_te + sp_atk_p1_te, atk_p2_te + sp_atk_p2_te)\n",
    ")\n",
    "\n",
    "# 8) defensive_efficiency: (def + sp_def) P1 / P2\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"defensive_efficiency\",\n",
    "    _safe_div(def_p1 + sp_def_p1, def_p2 + sp_def_p2),\n",
    "    _safe_div(def_p1_te + sp_def_p1_te, def_p2_te + sp_def_p2_te)\n",
    ")\n",
    "\n",
    "# 9) status_influence: share STATUS moves P1 - P2\n",
    "tot_p1 = _ensure_float32(st_p1 + ph_p1 + sp_p1).replace(0.0, 1.0)\n",
    "tot_p2 = _ensure_float32(st_p2 + ph_p2 + sp_p2).replace(0.0, 1.0)\n",
    "tot_p1_te = _ensure_float32(st_p1_te + ph_p1_te + sp_p1_te).replace(0.0, 1.0)\n",
    "tot_p2_te = _ensure_float32(st_p2_te + ph_p2_te + sp_p2_te).replace(0.0, 1.0)\n",
    "\n",
    "status_share_p1 = _safe_div(st_p1, tot_p1)\n",
    "status_share_p2 = _safe_div(st_p2, tot_p2)\n",
    "status_share_p1_te = _safe_div(st_p1_te, tot_p1_te)\n",
    "status_share_p2_te = _safe_div(st_p2_te, tot_p2_te)\n",
    "\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"status_influence\",\n",
    "    (status_share_p1 - status_share_p2),\n",
    "    (status_share_p1_te - status_share_p2_te)\n",
    ")\n",
    "\n",
    "# 10) speed_ratio: P1 speed / P2 speed\n",
    "_add_feature_pair(\n",
    "    train_df, test_df, \"speed_ratio\",\n",
    "    _safe_div(spd_p1, spd_p2),\n",
    "    _safe_div(spd_p1_te, spd_p2_te)\n",
    ")\n",
    "\n",
    "# --- Quick validation: no NaN/Inf and report how many were added ---\n",
    "new_cols = [\n",
    "    \"atk_def_ratio\",\"spd_gap\",\"hp_ratio\",\"survival_score\",\"momentum_index\",\n",
    "    \"power_acc_gap\",\"offensive_balance\",\"defensive_efficiency\",\"status_influence\",\"speed_ratio\"\n",
    "]\n",
    "bad_train = train_df[new_cols].isna().sum().sum() + np.isinf(train_df[new_cols].to_numpy()).sum()\n",
    "bad_test  = test_df[new_cols].isna().sum().sum()  + np.isinf(test_df[new_cols].to_numpy()).sum()\n",
    "print(f\"[FeatureEng] Added {len(new_cols)} engineered features. Bad values -> train: {bad_train}, test: {bad_test}\")\n",
    "\n",
    "print(\"\\nPreview (raw):\")\n",
    "display(train_df_raw.head())\n",
    "\n",
    "print(\"\\nPrepared (unscaled, clean types):\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67e3869",
   "metadata": {
    "_cell_guid": "180522a2-d6d8-433d-9327-d29107854e97",
    "_uuid": "cd2138cc-e20c-4963-91a9-2949b205cb22",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.007468,
     "end_time": "2025-11-12T23:29:46.542967",
     "exception": false,
     "start_time": "2025-11-12T23:29:46.535499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.A Overfitting check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524e2113",
   "metadata": {
    "_cell_guid": "98c72025-2a1c-4017-99a6-671973d4a009",
    "_kg_hide-input": true,
    "_uuid": "4bb2e0fc-f0ff-4bf2-a613-c51fe38e3103",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-12T23:29:46.561145Z",
     "iopub.status.busy": "2025-11-12T23:29:46.560757Z",
     "iopub.status.idle": "2025-11-12T23:29:55.168238Z",
     "shell.execute_reply": "2025-11-12T23:29:55.167291Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 8.619131,
     "end_time": "2025-11-12T23:29:55.169803",
     "exception": false,
     "start_time": "2025-11-12T23:29:46.550672",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_size</th>\n",
       "      <th>train_acc_mean</th>\n",
       "      <th>train_acc_std</th>\n",
       "      <th>val_acc_mean</th>\n",
       "      <th>val_acc_std</th>\n",
       "      <th>gap_train_minus_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>0.009747</td>\n",
       "      <td>0.8021</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.080400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2240</td>\n",
       "      <td>0.851607</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.022307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3679</td>\n",
       "      <td>0.847567</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.8347</td>\n",
       "      <td>0.006853</td>\n",
       "      <td>0.012867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5120</td>\n",
       "      <td>0.847734</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.8361</td>\n",
       "      <td>0.008639</td>\n",
       "      <td>0.011634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6560</td>\n",
       "      <td>0.845610</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.8359</td>\n",
       "      <td>0.005463</td>\n",
       "      <td>0.009710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8000</td>\n",
       "      <td>0.843825</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.8388</td>\n",
       "      <td>0.005662</td>\n",
       "      <td>0.005025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_size  train_acc_mean  train_acc_std  val_acc_mean  val_acc_std  \\\n",
       "0         800        0.882500       0.009747        0.8021     0.007378   \n",
       "1        2240        0.851607       0.004903        0.8293     0.003234   \n",
       "2        3679        0.847567       0.003624        0.8347     0.006853   \n",
       "3        5120        0.847734       0.002346        0.8361     0.008639   \n",
       "4        6560        0.845610       0.003039        0.8359     0.005463   \n",
       "5        8000        0.843825       0.002026        0.8388     0.005662   \n",
       "\n",
       "   gap_train_minus_val  \n",
       "0             0.080400  \n",
       "1             0.022307  \n",
       "2             0.012867  \n",
       "3             0.011634  \n",
       "4             0.009710  \n",
       "5             0.005025  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Largest train size = 8000\n",
      "  ‚Ä¢ Train acc (mean): 0.8438\n",
      "  ‚Ä¢ Val   acc (mean): 0.8388\n",
      "  ‚Ä¢ Gap (train - val): 0.0050\n",
      "\n",
      "Potential overfitting: NO\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Cell A: overfitting diagnostics (learning curve) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, learning_curve, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def diagnose_overfitting(\n",
    "    X, y,\n",
    "    cv_splits: int = 5,\n",
    "    train_sizes = np.linspace(0.1, 1.0, 6),\n",
    "    random_state: int = 42,\n",
    "    max_iter: int = 1000,\n",
    "    plot: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes a learning curve for a Logistic Regression pipeline (Scaler + Logistic).\n",
    "    Returns a dict with summary stats and optionally plots train vs validation accuracy.\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=max_iter, random_state=random_state))\n",
    "    ])\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # learning_curve supports shuffle/random_state in recent sklearn versions\n",
    "    ts_abs, train_scores, val_scores = learning_curve(\n",
    "        estimator=pipe,\n",
    "        X=X, y=y,\n",
    "        train_sizes=train_sizes,\n",
    "        cv=cv,\n",
    "        scoring=\"accuracy\",\n",
    "        shuffle=True,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    train_mean = train_scores.mean(axis=1)\n",
    "    train_std  = train_scores.std(axis=1)\n",
    "    val_mean   = val_scores.mean(axis=1)\n",
    "    val_std    = val_scores.std(axis=1)\n",
    "\n",
    "    # Table view\n",
    "    df_lc = pd.DataFrame({\n",
    "        \"train_size\": ts_abs,\n",
    "        \"train_acc_mean\": train_mean,\n",
    "        \"train_acc_std\": train_std,\n",
    "        \"val_acc_mean\": val_mean,\n",
    "        \"val_acc_std\": val_std,\n",
    "        \"gap_train_minus_val\": train_mean - val_mean\n",
    "    })\n",
    "    display(df_lc)\n",
    "\n",
    "    # Simple decision rule for potential overfitting (gap at largest size)\n",
    "    gap_last = float(df_lc[\"gap_train_minus_val\"].iloc[-1])\n",
    "    val_last = float(df_lc[\"val_acc_mean\"].iloc[-1])\n",
    "    flag_overfit = (gap_last >= 0.05) and (val_last < 0.80 or gap_last > 0.07)\n",
    "\n",
    "    print(f\"\\nLargest train size = {int(ts_abs[-1])}\")\n",
    "    print(f\"  ‚Ä¢ Train acc (mean): {train_mean[-1]:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Val   acc (mean): {val_mean[-1]:.4f}\")\n",
    "    print(f\"  ‚Ä¢ Gap (train - val): {gap_last:.4f}\")\n",
    "    print(f\"\\nPotential overfitting: {'YES' if flag_overfit else 'NO'}\")\n",
    "\n",
    "    if plot:\n",
    "        plt.figure()\n",
    "        plt.plot(ts_abs, train_mean, marker=\"o\", label=\"Train acc\")\n",
    "        plt.fill_between(ts_abs, train_mean-train_std, train_mean+train_std, alpha=0.15)\n",
    "        plt.plot(ts_abs, val_mean, marker=\"o\", label=\"Validation acc\")\n",
    "        plt.fill_between(ts_abs, val_mean-val_std, val_mean+val_std, alpha=0.15)\n",
    "        plt.xlabel(\"Number of training samples\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(\"Learning curve ‚Äî Logistic (scaled)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    return {\n",
    "        \"train_sizes\": ts_abs,\n",
    "        \"train_acc_mean\": train_mean,\n",
    "        \"val_acc_mean\": val_mean,\n",
    "        \"gap_last\": gap_last,\n",
    "        \"val_last\": val_last,\n",
    "        \"overfitting_flag\": flag_overfit\n",
    "    }\n",
    "\n",
    "# --- How to call (run after Cell 2) ---\n",
    "features = [c for c in train_df.columns if c not in (\"battle_id\", \"player_won\")]\n",
    "X = train_df[features].values\n",
    "y = train_df[\"player_won\"].values\n",
    "_ = diagnose_overfitting(X, y, cv_splits=5, max_iter=1000, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73f0902",
   "metadata": {
    "_cell_guid": "08ffc5f5-2dcb-437a-9e3a-62dafe9e3e9e",
    "_uuid": "bf65b3bb-827a-47f0-8dd3-f95e03651f9b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.008823,
     "end_time": "2025-11-12T23:29:55.190036",
     "exception": false,
     "start_time": "2025-11-12T23:29:55.181213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254bdb9f",
   "metadata": {
    "papermill": {
     "duration": 0.008765,
     "end_time": "2025-11-12T23:29:55.207932",
     "exception": false,
     "start_time": "2025-11-12T23:29:55.199167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.1 - Best Features Selection, V.3 (Elastic Net + SelectFromModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c41172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T23:29:55.228131Z",
     "iopub.status.busy": "2025-11-12T23:29:55.227477Z",
     "iopub.status.idle": "2025-11-12T23:34:06.283643Z",
     "shell.execute_reply": "2025-11-12T23:34:06.282599Z"
    },
    "papermill": {
     "duration": 251.077957,
     "end_time": "2025-11-12T23:34:06.294996",
     "exception": false,
     "start_time": "2025-11-12T23:29:55.217039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Original feature count (numeric, pre-pruning): 215\n",
      "[Pruning][A] Constant features removed: 43\n",
      "  -> Constant list (first 50): ['p1_team_size', 'p2_team_size', 'p2_unique_types', 'diff_team_size', 'tl_turns_used', 'tl_hp_diff_min', 'tl_p1_status_count', 'tl_p2_status_count', 'tl_status_count', 'hazard_switch_pressure_diff', 'hazard_p1_flag', 'hazard_p2_flag', 'hazard_flag_diff', 'early_status_advantage_3', 'mv_p1_priority_count', 'mv_p2_priority_count', 'mv_priority_count_diff', 'mv_p1_priority_count_5', 'mv_p2_priority_count_5', 'mv_priority_count_diff_5', 'stronger_team', 'battle_length', 'long_battle', 'p1_hp_stability', 'p2_hp_stability', 'team_has_type_variety', 'p1_hp_over_50_ratio', 'p2_hp_over_50_ratio', 'is_player1_healthier', 'comeback_difficulty', 'damage_prediction', 'ix_speed_x_prio5', 'ix_early3_x_prio5', 'ix_hazards_x_prio5', 'atk_def_ratio', 'spd_gap', 'hp_ratio', 'survival_score', 'momentum_index', 'offensive_balance', 'defensive_efficiency', 'status_influence', 'speed_ratio']\n",
      "[Pruning][A] After constant pruning: 172 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in greater\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pruning][B] Dropped for high correlation (>|œÅ| 0.99): 37\n",
      "[Pruning][B] After correlation pruning: 135 features\n",
      "[Pruning][C] Starting VIF pruning (thr=25.0, max steps=50) ...\n",
      "  [VIF] Step 1: dropping 'p1_team_stat_sum' (VIF=inf)\n",
      "  [VIF] Step 2: dropping 'p2_team_stat_sum' (VIF=inf)\n",
      "  [VIF] Step 3: dropping 'p1_mean_spe' (VIF=inf)\n",
      "  [VIF] Step 4: dropping 'p1_max_spe' (VIF=inf)\n",
      "  [VIF] Step 5: dropping 'tl_p1_hp_last' (VIF=inf)\n",
      "  [VIF] Step 6: dropping 'tl_p1_ko_count' (VIF=inf)\n",
      "  [VIF] Step 7: dropping 'tl_p2_ko_count' (VIF=inf)\n",
      "  [VIF] Step 8: dropping 'switch_p1_count' (VIF=inf)\n",
      "  [VIF] Step 9: dropping 'recover_p1_count' (VIF=inf)\n",
      "  [VIF] Step 10: dropping 'pokemon_remaining_diff' (VIF=inf)\n",
      "  [VIF] Step 11: dropping 'avg_damage_p1' (VIF=inf)\n",
      "  [VIF] Step 12: dropping 'used_pokemon_diff' (VIF=156734.55)\n",
      "  [VIF] Step 13: dropping 'power_acc_gap' (VIF=532.65)\n",
      "  [VIF] Step 14: dropping 'p2_lead_spe' (VIF=151.06)\n",
      "  [VIF] Step 15: dropping 'tl_hp_diff_mean' (VIF=61.21)\n",
      "  [VIF] Step 16: dropping 'spe_mean_adv' (VIF=48.92)\n",
      "  [VIF] Step 17: dropping 'final_win_probability' (VIF=42.35)\n",
      "  [VIF] Step 18: dropping 'p2_lead_hp' (VIF=37.41)\n",
      "  [VIF] Step 19: dropping 'ix_ter_x_stab_full' (VIF=27.95)\n",
      "  [VIF] Step 20: dropping 'tot_damage_diff' (VIF=27.48)\n",
      "  [VIF] All VIF <= 25.0 (max=21.51). Stopping.\n",
      "[Pruning][C] VIF dropped: 20\n",
      "[Pruning] After A+B(+C): 115 features\n",
      "[ElasticNet+TopN] Non-zero weights: 113 | Selected top-60: 60\n",
      "[Output] train_reduced shape: (10000, 62) | test_reduced shape: (5000, 61)\n",
      "[Features] Final selected (60): first 25 -> ['p1_unique_types', 'spe_max_adv', 'p1_frac_faster_than_p2lead', 'tl_p1_hp_mean', 'tl_p1_hp_std', 'tl_p2_hp_last', 'tl_p2_hp_std', 'tl_hp_diff_last', 'tl_hp_diff_std', 'tl_frac_turns_advantage', 'tl_ko_count', 'p1_offense_bias_ratio', 'p1_weakness_mean', 'p1_unique_resistances', 'p2_hp_abs_step_5', 'hp_abs_step_gap_5', 'mv_p1_power_mean', 'mv_p1_priority_mean', 'mv_p2_power_mean', 'mv_p2_acc_mean', 'mv_p2_power_mean_5', 'mv_p2_acc_mean_5', 'switch_p2_count', 'switch_count_diff', 'recover_p2_count']\n"
     ]
    }
   ],
   "source": [
    "# === 3.1 BEST FEATURES SELECTION (Elastic Net + SelectFromModel) ==================\n",
    "# - Prints original feature count\n",
    "# - Train-only pruning:\n",
    "#     (A) correlation pruning (|œÅ| > 0.95)\n",
    "#     (C) optional robust VIF pruning (iterative, safe)\n",
    "# - Selector: Elastic Net (LogisticRegressionCV, saga) + SelectFromModel with a small threshold sweep\n",
    "# - Outputs: train_reduced, test_reduced with the exact selected feature subset\n",
    "# ================================================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# -----------------------\n",
    "# Config\n",
    "# -----------------------\n",
    "RANDOM_STATE = 42\n",
    "ID_COLS      = [\"battle_id\"]\n",
    "TARGET_COL   = \"player_won\"\n",
    "DROP_VIF     = True           # set to False to skip VIF pruning\n",
    "VIF_THRESHOLD= 25.0           # robust, not too aggressive\n",
    "MAX_VIF_STEPS= 50             # safety cap\n",
    "CORR_THR     = 0.99           # correlation pruning threshold (abs Pearson)\n",
    "NEAR_CONST_P = 0.002        # near-constant if <1% distinct values\n",
    "CV_SPLITS    = 5\n",
    "\n",
    "assert TARGET_COL in train_df.columns, f\"Target '{TARGET_COL}' not found in train_df.\"\n",
    "\n",
    "# -----------------------\n",
    "# 0) Build numeric matrices\n",
    "# -----------------------\n",
    "num_cols_all = [c for c in train_df.columns if c not in (TARGET_COL, *ID_COLS)]\n",
    "X = train_df[num_cols_all].copy()\n",
    "y = train_df[TARGET_COL].astype(int).copy()\n",
    "X_test_full = test_df[num_cols_all].copy()\n",
    "\n",
    "# ensure numeric dtype (and keep NaN)\n",
    "X = X.apply(pd.to_numeric, errors=\"coerce\").astype(\"float32\")\n",
    "X_test_full = X_test_full.apply(pd.to_numeric, errors=\"coerce\").astype(\"float32\")\n",
    "\n",
    "orig_feat_count = X.shape[1]\n",
    "print(f\"[Info] Original feature count (numeric, pre-pruning): {orig_feat_count}\")\n",
    "\n",
    "# -----------------------\n",
    "# Helper: simple impute/scale (fit on TRAIN only)\n",
    "# -----------------------\n",
    "def fit_imputer_scaler(df: pd.DataFrame):\n",
    "    imp = SimpleImputer(strategy=\"median\")\n",
    "    sca = RobustScaler()\n",
    "    Z   = imp.fit_transform(df)\n",
    "    Z   = sca.fit_transform(Z)\n",
    "    return imp, sca, Z\n",
    "\n",
    "# -----------------------\n",
    "# (A) Constants \n",
    "# -----------------------\n",
    "# constants: zero variance on observed values (ignoring NaN)\n",
    "const_cols = [c for c in X.columns if X[c].nunique(dropna=True) <= 1]\n",
    "\n",
    "print(f\"[Pruning][A] Constant features removed: {len(const_cols)}\")\n",
    "if const_cols:\n",
    "    print(\"  -> Constant list (first 50):\", const_cols[:50])\n",
    "\n",
    "drop_A = const_cols\n",
    "if drop_A:\n",
    "    X.drop(columns=drop_A, inplace=True, errors=\"ignore\")\n",
    "    X_test_full.drop(columns=drop_A, inplace=True, errors=\"ignore\")\n",
    "\n",
    "print(f\"[Pruning][A] After constant pruning: {X.shape[1]} features\")\n",
    "\n",
    "# -----------------------\n",
    "# (B) Correlation pruning (|œÅ| > CORR_THR)\n",
    "# -----------------------\n",
    "# compute correlation on imputed values to avoid NaNs\n",
    "imp_tmp = SimpleImputer(strategy=\"median\").fit(X)\n",
    "X_imp = pd.DataFrame(imp_tmp.transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "corr = X_imp.corr(method=\"pearson\").abs()\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "to_drop_corr = [col for col in upper.columns if any(upper[col] > CORR_THR)]\n",
    "\n",
    "if to_drop_corr:\n",
    "    print(f\"[Pruning][B] Dropped for high correlation (>|œÅ| {CORR_THR}): {len(to_drop_corr)}\")\n",
    "    X.drop(columns=to_drop_corr, inplace=True, errors=\"ignore\")\n",
    "    X_test_full.drop(columns=to_drop_corr, inplace=True, errors=\"ignore\")\n",
    "else:\n",
    "    print(\"[Pruning][B] No features dropped by correlation threshold.\")\n",
    "\n",
    "print(f\"[Pruning][B] After correlation pruning: {X.shape[1]} features\")\n",
    "\n",
    "# -----------------------\n",
    "# (C) Optional robust VIF pruning (iterative)\n",
    "# -----------------------\n",
    "def compute_vif_frame(df_std: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute VIF using a standard OLS-based formula on standardized, imputed data.\n",
    "    Returns a DataFrame with columns ['feature','vif'].\n",
    "    \"\"\"\n",
    "    # classic VIF formula via linear regressions:\n",
    "    # to avoid heavy statsmodels dependency & to keep it robust/fast, we use sklearn OLS fallback\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    cols = list(df_std.columns)\n",
    "    vifs = []\n",
    "    for i, col in enumerate(cols):\n",
    "        yv = df_std[col].values\n",
    "        Xv = df_std.drop(columns=[col]).values\n",
    "        # handle degenerate case: one or zero columns left\n",
    "        if Xv.shape[1] == 0:\n",
    "            vifs.append(np.inf)\n",
    "            continue\n",
    "        # fit OLS\n",
    "        lr = LinearRegression(n_jobs=None)  # OLS via least squares\n",
    "        lr.fit(Xv, yv)\n",
    "        yhat = lr.predict(Xv)\n",
    "        # R^2\n",
    "        ss_res = np.sum((yv - yhat)**2)\n",
    "        ss_tot = np.sum((yv - np.mean(yv))**2) + 1e-12\n",
    "        r2 = 1.0 - ss_res / ss_tot\n",
    "        # VIF\n",
    "        if r2 >= 0.999999:\n",
    "            vif_val = np.inf\n",
    "        else:\n",
    "            vif_val = 1.0 / max(1e-12, (1.0 - r2))\n",
    "        vifs.append(vif_val)\n",
    "    return pd.DataFrame({\"feature\": cols, \"vif\": vifs})\n",
    "\n",
    "vif_dropped = []\n",
    "if DROP_VIF and X.shape[1] > 2:\n",
    "    print(f\"[Pruning][C] Starting VIF pruning (thr={VIF_THRESHOLD}, max steps={MAX_VIF_STEPS}) ...\")\n",
    "    step = 0\n",
    "    while step < MAX_VIF_STEPS and X.shape[1] > 2:\n",
    "        # refit imputer & scaler on current columns each iteration (avoids feature-name mismatch)\n",
    "        imp_vif, sca_vif, X_std = fit_imputer_scaler(X)\n",
    "        X_std = pd.DataFrame(X_std, columns=X.columns, index=X.index)\n",
    "\n",
    "        vif_frame = compute_vif_frame(X_std)\n",
    "        max_row = vif_frame.loc[vif_frame[\"vif\"].idxmax()]\n",
    "        max_feat, max_vif = str(max_row[\"feature\"]), float(max_row[\"vif\"])\n",
    "\n",
    "        if not np.isfinite(max_vif):\n",
    "            # drop the one producing inf VIF\n",
    "            print(f\"  [VIF] Step {step+1}: dropping '{max_feat}' (VIF=inf)\")\n",
    "            vif_dropped.append(max_feat)\n",
    "            X.drop(columns=[max_feat], inplace=True, errors=\"ignore\")\n",
    "            X_test_full.drop(columns=[max_feat], inplace=True, errors=\"ignore\")\n",
    "            step += 1\n",
    "            continue\n",
    "\n",
    "        if max_vif <= VIF_THRESHOLD:\n",
    "            print(f\"  [VIF] All VIF <= {VIF_THRESHOLD:.1f} (max={max_vif:.2f}). Stopping.\")\n",
    "            break\n",
    "\n",
    "        print(f\"  [VIF] Step {step+1}: dropping '{max_feat}' (VIF={max_vif:.2f})\")\n",
    "        vif_dropped.append(max_feat)\n",
    "        X.drop(columns=[max_feat], inplace=True, errors=\"ignore\")\n",
    "        X_test_full.drop(columns=[max_feat], inplace=True, errors=\"ignore\")\n",
    "        step += 1\n",
    "\n",
    "    print(f\"[Pruning][C] VIF dropped: {len(vif_dropped)}\")\n",
    "else:\n",
    "    print(\"[Pruning][C] VIF pruning skipped.\")\n",
    "\n",
    "print(f\"[Pruning] After A+B(+C): {X.shape[1]} features\")\n",
    "\n",
    "feat_cols_after_pruning = list(X.columns)\n",
    "\n",
    "# -----------------------\n",
    "# Elastic Net selector (LogisticRegressionCV, saga)\n",
    "# -----------------------\n",
    "cv = StratifiedKFold(n_splits=CV_SPLITS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# Fit imputer & scaler on TRAIN (post-pruning)\n",
    "imp_sel, sca_sel, X_std_sel = fit_imputer_scaler(X)\n",
    "\n",
    "# ENet with CV on Cs and l1 ratios\n",
    "enet = LogisticRegressionCV(\n",
    "    penalty=\"elasticnet\",\n",
    "    solver=\"saga\",\n",
    "    Cs=[0.05, 0.1, 0.2, 0.5, 1.0],\n",
    "    l1_ratios=[0.1, 0.3, 0.5, 0.7],\n",
    "    scoring=\"accuracy\",\n",
    "    cv=cv,\n",
    "    max_iter=5000,\n",
    "    tol=1e-3,\n",
    "    n_jobs=-1,\n",
    "    refit=True,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "enet.fit(X_std_sel, y)\n",
    "\n",
    "# --- Top-N selection by absolute EN coefficients (replaces SelectFromModel sweep) ---\n",
    "TARGET_N_FEATURES = 60  # <- set your desired count\n",
    "\n",
    "# 1) Get absolute coefficients from the fitted CV ElasticNet (binary -> shape (1, n_features))\n",
    "abs_w = np.abs(enet.coef_.ravel())\n",
    "\n",
    "# 2) If too few non-zeros, gently relax by re-fitting once with larger C or lower l1_ratio\n",
    "nonzero_idx = np.where(abs_w > 0)[0]\n",
    "if nonzero_idx.size < TARGET_N_FEATURES:\n",
    "    # pick relaxed hyperparams from the best CV solution\n",
    "    relaxed_C = float(enet.C_[0] * 2.0)\n",
    "    relaxed_l1 = max(0.2, float(enet.l1_ratio_[0]) - 0.1)\n",
    "\n",
    "    enet_relaxed = LogisticRegressionCV(\n",
    "        penalty=\"elasticnet\",\n",
    "        solver=\"saga\",\n",
    "        Cs=[relaxed_C],\n",
    "        l1_ratios=[relaxed_l1],\n",
    "        scoring=\"accuracy\",\n",
    "        cv=cv,\n",
    "        max_iter=6000,\n",
    "        tol=1e-3,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    enet_relaxed.fit(X_std_sel, y)\n",
    "    enet = enet_relaxed\n",
    "    abs_w = np.abs(enet.coef_.ravel())\n",
    "    nonzero_idx = np.where(abs_w > 0)[0]\n",
    "\n",
    "# 3) Pick TOP-N by absolute weight (guarantees desired count when possible)\n",
    "n_take = min(TARGET_N_FEATURES, abs_w.size)\n",
    "thresh_val = np.partition(abs_w, -n_take)[-n_take]\n",
    "top_mask = abs_w >= thresh_val\n",
    "\n",
    "selected_cols = list(np.array(feat_cols_after_pruning)[top_mask])\n",
    "print(f\"[ElasticNet+TopN] Non-zero weights: {nonzero_idx.size} | Selected top-{n_take}: {len(selected_cols)}\")\n",
    "\n",
    "# 4) Build reduced DataFrames (RAW view for downstream cells)\n",
    "train_reduced = pd.concat(\n",
    "    [train_df[ID_COLS], train_df[[TARGET_COL]], train_df[selected_cols]],\n",
    "    axis=1\n",
    ")\n",
    "test_reduced = pd.concat(\n",
    "    [test_df[ID_COLS], test_df[selected_cols]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"[Output] train_reduced shape: {train_reduced.shape} | test_reduced shape: {test_reduced.shape}\")\n",
    "print(f\"[Features] Final selected ({len(selected_cols)}): first 25 -> {selected_cols[:25]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb930b18",
   "metadata": {
    "_cell_guid": "c9df0ffe-ef6c-43d3-925a-f0ccce90af01",
    "_uuid": "a5923783-e209-48a4-b3a5-b3b7a38c48ca",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.010101,
     "end_time": "2025-11-12T23:34:06.315137",
     "exception": false,
     "start_time": "2025-11-12T23:34:06.305036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.2 - Stacking (Logistic Regression + XGBoost + Random Forest -> Logistic Regression meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd86c33",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-11-12T23:34:06.336977Z",
     "iopub.status.busy": "2025-11-12T23:34:06.336583Z",
     "iopub.status.idle": "2025-11-12T23:34:06.344960Z",
     "shell.execute_reply": "2025-11-12T23:34:06.344117Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.021226,
     "end_time": "2025-11-12T23:34:06.346363",
     "exception": false,
     "start_time": "2025-11-12T23:34:06.325137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === 3.2 Stacking (LogisticRegression + XGBoost + RandomForest -> LogisticRegression meta) ===\n",
    "# # - Uses true OOF stacking: base learners trained per fold, produce OOF probs\n",
    "# # - XGBoost with early stopping (per-fold)\n",
    "# # - RF and XGB calibrated with sigmoid on the validation fold (no leakage)\n",
    "# # - Meta-learner = LogisticRegression (stable, well-calibrated on probs)\n",
    "# # - Exposes: oof_meta_scores, meta_test_scores, y\n",
    "\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "# RANDOM_STATE = 99\n",
    "# FOLDS = 10\n",
    "# np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# # --- Safety checks & matrices ---\n",
    "# assert \"selected_cols\" in globals(), \"Run Cell 3.1 to define 'selected_cols'.\"\n",
    "# assert \"train_reduced\" in globals() and \"test_reduced\" in globals(), \"Missing reduced frames from 3.1.\"\n",
    "\n",
    "# X_sel = train_reduced[selected_cols].to_numpy()\n",
    "# X_test_sel = test_reduced[selected_cols].to_numpy()\n",
    "# y = train_reduced[\"player_won\"].astype(int).to_numpy()\n",
    "\n",
    "# n_train = X_sel.shape[0]\n",
    "# n_test  = X_test_sel.shape[0]\n",
    "\n",
    "# print(f\"[Stack LR+XGB+RF‚ÜíLR] Using {X_sel.shape[1]} selected features on {n_train} training rows.\")\n",
    "\n",
    "# # --- Base learners -------------------------------------------------------------------------\n",
    "# # (1) Logistic Regression (scaled). No calibration needed.\n",
    "# base_lr = make_pipeline(\n",
    "#     StandardScaler(),\n",
    "#     LogisticRegression(\n",
    "#         solver=\"liblinear\",\n",
    "#         penalty=\"l2\",\n",
    "#         C=0.5,\n",
    "#         max_iter=3000,\n",
    "#         random_state=RANDOM_STATE\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # (2) XGBoost (with early stopping). We'll calibrate per-fold on the val fold.\n",
    "# base_xgb_params = dict(\n",
    "#     n_estimators=2000,           # high cap, early stopping will cut it\n",
    "#     learning_rate=0.03,\n",
    "#     max_depth=6,\n",
    "#     subsample=0.8,\n",
    "#     colsample_bytree=0.8,\n",
    "#     reg_lambda=1.0,\n",
    "#     reg_alpha=0.0,\n",
    "#     objective=\"binary:logistic\",\n",
    "#     eval_metric=\"logloss\",\n",
    "#     random_state=RANDOM_STATE,\n",
    "#     n_jobs=-1,\n",
    "#     tree_method=\"hist\"\n",
    "# )\n",
    "\n",
    "# # (3) Random Forest (regularized) + per-fold calibration\n",
    "# base_rf = RandomForestClassifier(\n",
    "#     n_estimators=400,\n",
    "#     max_depth=10,\n",
    "#     min_samples_leaf=10,\n",
    "#     max_features=\"sqrt\",\n",
    "#     bootstrap=True,\n",
    "#     n_jobs=-1,\n",
    "#     random_state=RANDOM_STATE\n",
    "# )\n",
    "\n",
    "# base_names  = [\"lr\", \"xgb\", \"rf\"]\n",
    "# n_base      = len(base_names)\n",
    "\n",
    "# # --- OOF holders for base learners (level-1 features) --------------------------------------\n",
    "# oof_base = np.zeros((n_train, n_base), dtype=float)\n",
    "# test_base_folds = np.zeros((n_test, n_base, FOLDS), dtype=float)\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "# print(\"\\n[Per-fold validation summary]\")\n",
    "# for fold, (tr_idx, va_idx) in enumerate(skf.split(X_sel, y), 1):\n",
    "#     X_tr, X_va = X_sel[tr_idx], X_sel[va_idx]\n",
    "#     y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "\n",
    "#     # ---- Base 1: Logistic Regression (no calibration) ----\n",
    "#     lr_model = make_pipeline(\n",
    "#         StandardScaler(),\n",
    "#         LogisticRegression(\n",
    "#             solver=\"liblinear\",\n",
    "#             penalty=\"l2\",\n",
    "#             C=0.5,\n",
    "#             max_iter=3000,\n",
    "#             random_state=RANDOM_STATE\n",
    "#         )\n",
    "#     )\n",
    "#     lr_model.fit(X_tr, y_tr)\n",
    "#     lr_va = lr_model.predict_proba(X_va)[:, 1]\n",
    "#     lr_te = lr_model.predict_proba(X_test_sel)[:, 1]\n",
    "\n",
    "#     # ---- Base 2: XGBoost (early stopping) + sigmoid calibration on val ----\n",
    "#     xgb_model = xgb.XGBClassifier(**base_xgb_params)\n",
    "#     xgb_model.fit(\n",
    "#         X_tr, y_tr,\n",
    "#         eval_set=[(X_va, y_va)],\n",
    "#         verbose=False\n",
    "#     )\n",
    "\n",
    "#     # predictions at best iteration (handle API differences safely)\n",
    "#     try:\n",
    "#         best_it = getattr(xgb_model, \"best_iteration\", None)\n",
    "#         if best_it is not None:\n",
    "#             xgb_va_raw = xgb_model.predict_proba(X_va, iteration_range=(0, best_it + 1))[:, 1]\n",
    "#             xgb_te_raw = xgb_model.predict_proba(X_test_sel, iteration_range=(0, best_it + 1))[:, 1]\n",
    "#         else:\n",
    "#             xgb_va_raw = xgb_model.predict_proba(X_va)[:, 1]\n",
    "#             xgb_te_raw = xgb_model.predict_proba(X_test_sel)[:, 1]\n",
    "#         used_best = best_it\n",
    "#     except Exception:\n",
    "#         xgb_va_raw = xgb_model.predict_proba(X_va)[:, 1]\n",
    "#         xgb_te_raw = xgb_model.predict_proba(X_test_sel)[:, 1]\n",
    "#         used_best = \"N/A\"\n",
    "\n",
    "#     # calibrate on the validation fold (no leakage)\n",
    "#     xgb_cal = CalibratedClassifierCV(estimator=xgb_model, method=\"sigmoid\", cv=\"prefit\")\n",
    "#     xgb_cal.fit(X_va, y_va)\n",
    "#     xgb_va = xgb_cal.predict_proba(X_va)[:, 1]\n",
    "#     xgb_te = xgb_cal.predict_proba(X_test_sel)[:, 1]\n",
    "\n",
    "#     # ---- Base 3: Random Forest + sigmoid calibration on val ----\n",
    "#     rf_model = RandomForestClassifier(\n",
    "#         n_estimators=400,\n",
    "#         max_depth=10,\n",
    "#         min_samples_leaf=10,\n",
    "#         max_features=\"sqrt\",\n",
    "#         bootstrap=True,\n",
    "#         n_jobs=-1,\n",
    "#         random_state=RANDOM_STATE + fold  # slight variation per fold\n",
    "#     )\n",
    "#     rf_model.fit(X_tr, y_tr)\n",
    "#     rf_cal = CalibratedClassifierCV(estimator=rf_model, method=\"sigmoid\", cv=\"prefit\")\n",
    "#     rf_cal.fit(X_va, y_va)\n",
    "#     rf_va = rf_cal.predict_proba(X_va)[:, 1]\n",
    "#     rf_te = rf_cal.predict_proba(X_test_sel)[:, 1]\n",
    "\n",
    "#     # ---- Store OOF & per-fold test probs (level-1 design) ----\n",
    "#     oof_base[va_idx, 0] = lr_va\n",
    "#     oof_base[va_idx, 1] = xgb_va\n",
    "#     oof_base[va_idx, 2] = rf_va\n",
    "\n",
    "#     test_base_folds[:, 0, fold - 1] = lr_te\n",
    "#     test_base_folds[:, 1, fold - 1] = xgb_te\n",
    "#     test_base_folds[:, 2, fold - 1] = rf_te\n",
    "\n",
    "#     # ---- Fold metrics (on validation) ----\n",
    "#     # Report each base quickly (accuracy/AUC at 0.50)\n",
    "#     def _rep(name, p):\n",
    "#         acc = accuracy_score(y_va, (p >= 0.5).astype(int))\n",
    "#         try:\n",
    "#             auc = roc_auc_score(y_va, p)\n",
    "#         except Exception:\n",
    "#             auc = np.nan\n",
    "#         return acc, auc\n",
    "\n",
    "#     acc_lr, auc_lr   = _rep(\"lr\",  lr_va)\n",
    "#     acc_xgb, auc_xgb = _rep(\"xgb\", xgb_va)\n",
    "#     acc_rf, auc_rf   = _rep(\"rf\",  rf_va)\n",
    "\n",
    "#     print(f\"  [Fold {fold}] \"\n",
    "#           f\"LR  acc={acc_lr:.4f} | AUC={auc_lr:.4f}  ||  \"\n",
    "#           f\"XGB acc={acc_xgb:.4f} | AUC={auc_xgb:.4f} | best_iter={used_best}  ||  \"\n",
    "#           f\"RF  acc={acc_rf:.4f} | AUC={auc_rf:.4f}\")\n",
    "\n",
    "# # --- Aggregate test probs across folds for each base learner ---\n",
    "# test_base_mean = test_base_folds.mean(axis=2)   # shape: (n_test, 3)\n",
    "\n",
    "# # --- Meta-learner on OOF base features (with second-level OOF for honest estimate) ----------\n",
    "# meta_clf = LogisticRegression(\n",
    "#     solver=\"lbfgs\",\n",
    "#     penalty=\"l2\",\n",
    "#     C=1.0,\n",
    "#     max_iter=5000,\n",
    "#     random_state=RANDOM_STATE\n",
    "# )\n",
    "\n",
    "# # Build true OOF for meta as well\n",
    "# oof_meta_scores = np.zeros(n_train, dtype=float)\n",
    "# meta_test_folds = np.zeros((n_test, FOLDS), dtype=float)\n",
    "\n",
    "# skf_meta = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE + 1)\n",
    "# for fold, (tr_idx, va_idx) in enumerate(skf_meta.split(oof_base, y), 1):\n",
    "#     X_tr_m, X_va_m = oof_base[tr_idx], oof_base[va_idx]\n",
    "#     y_tr_m, y_va_m = y[tr_idx], y[va_idx]\n",
    "\n",
    "#     meta_clf_fold = LogisticRegression(\n",
    "#         solver=\"lbfgs\",\n",
    "#         penalty=\"l2\",\n",
    "#         C=1.0,\n",
    "#         max_iter=5000,\n",
    "#         random_state=RANDOM_STATE + fold\n",
    "#     )\n",
    "#     meta_clf_fold.fit(X_tr_m, y_tr_m)\n",
    "#     oof_meta_scores[va_idx] = meta_clf_fold.predict_proba(X_va_m)[:, 1]\n",
    "#     meta_test_folds[:, fold - 1] = meta_clf_fold.predict_proba(test_base_mean)[:, 1]\n",
    "\n",
    "# # Final meta on full OOF (optional fit, used for reporting and stability)\n",
    "# meta_clf.fit(oof_base, y)\n",
    "# meta_test_scores = meta_test_folds.mean(axis=1)\n",
    "\n",
    "# # --- Quick OOF report for the stacked meta predictor ---\n",
    "# oof_acc_default = accuracy_score(y, (oof_meta_scores >= 0.50).astype(int))\n",
    "# try:\n",
    "#     oof_auc = roc_auc_score(y, oof_meta_scores)\n",
    "# except Exception:\n",
    "#     oof_auc = np.nan\n",
    "\n",
    "# print(\"\\n[OOF][Meta LR] Accuracy @ 0.50 = {:.4f}\".format(oof_acc_default))\n",
    "# print(\"[OOF][Meta LR] ROC-AUC = {:.4f}\".format(oof_auc))\n",
    "# print(\"\\nReady for 3.3 threshold tuning (variables: oof_meta_scores, meta_test_scores, y)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "090599b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T23:34:06.369984Z",
     "iopub.status.busy": "2025-11-12T23:34:06.369619Z",
     "iopub.status.idle": "2025-11-12T23:34:06.378989Z",
     "shell.execute_reply": "2025-11-12T23:34:06.378010Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.023058,
     "end_time": "2025-11-12T23:34:06.380353",
     "exception": false,
     "start_time": "2025-11-12T23:34:06.357295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# import xgboost as xgb\n",
    "\n",
    "# # ===============================================================\n",
    "# # MULTI-SEED ENSEMBLE WRAPPER\n",
    "# # ===============================================================\n",
    "\n",
    "# SEEDS = [11, 42, 77, 99, 123]\n",
    "# results = []\n",
    "\n",
    "# for seed in SEEDS:\n",
    "#     print(\"\\n\" + \"=\"*80)\n",
    "#     print(f\"Running stacking with RANDOM_STATE = {seed}\")\n",
    "#     print(\"=\"*80)\n",
    "\n",
    "#     # global random seed\n",
    "#     RANDOM_STATE = seed\n",
    "#     np.random.seed(RANDOM_STATE)\n",
    "#     META_RANDOM_STATE = 42\n",
    "#     np.random.seed(META_RANDOM_STATE)\n",
    "#     FOLDS = 10\n",
    "\n",
    "#     # orginal block stars from here <------\n",
    "#     assert \"selected_cols\" in globals(), \"Run Cell 3.1 to define 'selected_cols'.\"\n",
    "#     assert \"train_reduced\" in globals() and \"test_reduced\" in globals(), \"Missing reduced frames from 3.1.\"\n",
    "    \n",
    "#     X_sel = train_reduced[selected_cols].to_numpy()\n",
    "#     X_test_sel = test_reduced[selected_cols].to_numpy()\n",
    "#     y = train_reduced[\"player_won\"].astype(int).to_numpy()\n",
    "    \n",
    "#     n_train = X_sel.shape[0]\n",
    "#     n_test  = X_test_sel.shape[0]\n",
    "    \n",
    "#     print(f\"[Stack LR+XGB+RF‚ÜíLR] Using {X_sel.shape[1]} selected features on {n_train} training rows.\")\n",
    "    \n",
    "#     # --- Base learners -------------------------------------------------------------------------\n",
    "#     # (1) Logistic Regression (scaled). No calibration needed.\n",
    "#     base_lr = make_pipeline(\n",
    "#         StandardScaler(),\n",
    "#         LogisticRegression(\n",
    "#             solver=\"liblinear\",\n",
    "#             penalty=\"l2\",\n",
    "#             C=0.5,\n",
    "#             max_iter=3000,\n",
    "#             random_state=RANDOM_STATE\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     # (2) XGBoost (with early stopping). We'll calibrate per-fold on the val fold.\n",
    "#     base_xgb_params = dict(\n",
    "#         n_estimators=2000,           # high cap, early stopping will cut it\n",
    "#         learning_rate=0.03,\n",
    "#         max_depth=6,\n",
    "#         subsample=0.8,\n",
    "#         colsample_bytree=0.8,\n",
    "#         reg_lambda=1.0,\n",
    "#         reg_alpha=0.0,\n",
    "#         objective=\"binary:logistic\",\n",
    "#         eval_metric=\"logloss\",\n",
    "#         random_state=RANDOM_STATE,\n",
    "#         n_jobs=-1,\n",
    "#         tree_method=\"hist\"\n",
    "#     )\n",
    "    \n",
    "#     # (3) Random Forest (regularized) + per-fold calibration\n",
    "#     base_rf = RandomForestClassifier(\n",
    "#         n_estimators=400,\n",
    "#         max_depth=10,\n",
    "#         min_samples_leaf=10,\n",
    "#         max_features=\"sqrt\",\n",
    "#         bootstrap=True,\n",
    "#         n_jobs=-1,\n",
    "#         random_state=RANDOM_STATE\n",
    "#     )\n",
    "    \n",
    "#     base_names  = [\"lr\", \"xgb\", \"rf\"]\n",
    "#     n_base      = len(base_names)\n",
    "    \n",
    "#     # --- OOF holders for base learners (level-1 features) --------------------------------------\n",
    "#     oof_base = np.zeros((n_train, n_base), dtype=float)\n",
    "#     test_base_folds = np.zeros((n_test, n_base, FOLDS), dtype=float)\n",
    "    \n",
    "#     skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "#     print(\"\\n[Per-fold validation summary]\")\n",
    "#     for fold, (tr_idx, va_idx) in enumerate(skf.split(X_sel, y), 1):\n",
    "#         X_tr, X_va = X_sel[tr_idx], X_sel[va_idx]\n",
    "#         y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "    \n",
    "#         # ---- Base 1: Logistic Regression (no calibration) ----\n",
    "#         lr_model = make_pipeline(\n",
    "#             StandardScaler(),\n",
    "#             LogisticRegression(\n",
    "#                 solver=\"liblinear\",\n",
    "#                 penalty=\"l2\",\n",
    "#                 C=0.5,\n",
    "#                 max_iter=3000,\n",
    "#                 random_state=RANDOM_STATE\n",
    "#             )\n",
    "#         )\n",
    "#         lr_model.fit(X_tr, y_tr)\n",
    "#         lr_va = lr_model.predict_proba(X_va)[:, 1]\n",
    "#         lr_te = lr_model.predict_proba(X_test_sel)[:, 1]\n",
    "    \n",
    "#         # ---- Base 2: XGBoost (early stopping) + sigmoid calibration on val ----\n",
    "#         xgb_model = xgb.XGBClassifier(**base_xgb_params)\n",
    "#         xgb_model.fit(\n",
    "#             X_tr, y_tr,\n",
    "#             eval_set=[(X_va, y_va)],\n",
    "#             verbose=False\n",
    "#         )\n",
    "    \n",
    "#         # predictions at best iteration (handle API differences safely)\n",
    "#         try:\n",
    "#             best_it = getattr(xgb_model, \"best_iteration\", None)\n",
    "#             if best_it is not None:\n",
    "#                 xgb_va_raw = xgb_model.predict_proba(X_va, iteration_range=(0, best_it + 1))[:, 1]\n",
    "#                 xgb_te_raw = xgb_model.predict_proba(X_test_sel, iteration_range=(0, best_it + 1))[:, 1]\n",
    "#             else:\n",
    "#                 xgb_va_raw = xgb_model.predict_proba(X_va)[:, 1]\n",
    "#                 xgb_te_raw = xgb_model.predict_proba(X_test_sel)[:, 1]\n",
    "#             used_best = best_it\n",
    "#         except Exception:\n",
    "#             xgb_va_raw = xgb_model.predict_proba(X_va)[:, 1]\n",
    "#             xgb_te_raw = xgb_model.predict_proba(X_test_sel)[:, 1]\n",
    "#             used_best = \"N/A\"\n",
    "    \n",
    "#         # calibrate on the validation fold (no leakage)\n",
    "#         xgb_cal = CalibratedClassifierCV(estimator=xgb_model, method=\"sigmoid\", cv=\"prefit\")\n",
    "#         xgb_cal.fit(X_va, y_va)\n",
    "#         xgb_va = xgb_cal.predict_proba(X_va)[:, 1]\n",
    "#         xgb_te = xgb_cal.predict_proba(X_test_sel)[:, 1]\n",
    "    \n",
    "#         # ---- Base 3: Random Forest + sigmoid calibration on val ----\n",
    "#         rf_model = RandomForestClassifier(\n",
    "#             n_estimators=400,\n",
    "#             max_depth=10,\n",
    "#             min_samples_leaf=10,\n",
    "#             max_features=\"sqrt\",\n",
    "#             bootstrap=True,\n",
    "#             n_jobs=-1,\n",
    "#             random_state=RANDOM_STATE + fold  # slight variation per fold\n",
    "#         )\n",
    "#         rf_model.fit(X_tr, y_tr)\n",
    "#         rf_cal = CalibratedClassifierCV(estimator=rf_model, method=\"sigmoid\", cv=\"prefit\")\n",
    "#         rf_cal.fit(X_va, y_va)\n",
    "#         rf_va = rf_cal.predict_proba(X_va)[:, 1]\n",
    "#         rf_te = rf_cal.predict_proba(X_test_sel)[:, 1]\n",
    "    \n",
    "#         # ---- Store OOF & per-fold test probs (level-1 design) ----\n",
    "#         oof_base[va_idx, 0] = lr_va\n",
    "#         oof_base[va_idx, 1] = xgb_va\n",
    "#         oof_base[va_idx, 2] = rf_va\n",
    "    \n",
    "#         test_base_folds[:, 0, fold - 1] = lr_te\n",
    "#         test_base_folds[:, 1, fold - 1] = xgb_te\n",
    "#         test_base_folds[:, 2, fold - 1] = rf_te\n",
    "    \n",
    "#         # ---- Fold metrics (on validation) ----\n",
    "#         # Report each base quickly (accuracy/AUC at 0.50)\n",
    "#         def _rep(name, p):\n",
    "#             acc = accuracy_score(y_va, (p >= 0.5).astype(int))\n",
    "#             try:\n",
    "#                 auc = roc_auc_score(y_va, p)\n",
    "#             except Exception:\n",
    "#                 auc = np.nan\n",
    "#             return acc, auc\n",
    "    \n",
    "#         acc_lr, auc_lr   = _rep(\"lr\",  lr_va)\n",
    "#         acc_xgb, auc_xgb = _rep(\"xgb\", xgb_va)\n",
    "#         acc_rf, auc_rf   = _rep(\"rf\",  rf_va)\n",
    "    \n",
    "#         print(f\"  [Fold {fold}] \"\n",
    "#               f\"LR  acc={acc_lr:.4f} | AUC={auc_lr:.4f}  ||  \"\n",
    "#               f\"XGB acc={acc_xgb:.4f} | AUC={auc_xgb:.4f} | best_iter={used_best}  ||  \"\n",
    "#               f\"RF  acc={acc_rf:.4f} | AUC={auc_rf:.4f}\")\n",
    "    \n",
    "#     # --- Aggregate test probs across folds for each base learner ---\n",
    "#     test_base_mean = test_base_folds.mean(axis=2)   # shape: (n_test, 3)\n",
    "    \n",
    "#     # --- Meta-learner on OOF base features (with second-level OOF for honest estimate) ----------\n",
    "#     meta_clf = LogisticRegression(\n",
    "#         solver=\"lbfgs\",\n",
    "#         penalty=\"l2\",\n",
    "#         C=1.0,\n",
    "#         max_iter=5000,\n",
    "#         random_state=META_RANDOM_STATE\n",
    "#     )\n",
    "    \n",
    "#     # Build true OOF for meta as well\n",
    "#     oof_meta_scores = np.zeros(n_train, dtype=float)\n",
    "#     meta_test_folds = np.zeros((n_test, FOLDS), dtype=float)\n",
    "    \n",
    "#     skf_meta = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=META_RANDOM_STATE + 1)\n",
    "#     for fold, (tr_idx, va_idx) in enumerate(skf_meta.split(oof_base, y), 1):\n",
    "#         X_tr_m, X_va_m = oof_base[tr_idx], oof_base[va_idx]\n",
    "#         y_tr_m, y_va_m = y[tr_idx], y[va_idx]\n",
    "    \n",
    "#         meta_clf_fold = LogisticRegression(\n",
    "#             solver=\"lbfgs\",\n",
    "#             penalty=\"l2\",\n",
    "#             C=1.0,\n",
    "#             max_iter=5000,\n",
    "#             random_state=META_RANDOM_STATE + fold\n",
    "#         )\n",
    "#         meta_clf_fold.fit(X_tr_m, y_tr_m)\n",
    "#         oof_meta_scores[va_idx] = meta_clf_fold.predict_proba(X_va_m)[:, 1]\n",
    "#         meta_test_folds[:, fold - 1] = meta_clf_fold.predict_proba(test_base_mean)[:, 1]\n",
    "    \n",
    "#     # Final meta on full OOF (optional fit, used for reporting and stability)\n",
    "#     meta_clf.fit(oof_base, y)\n",
    "#     meta_test_scores = meta_test_folds.mean(axis=1)\n",
    "    \n",
    "#     # --- Quick OOF report for the stacked meta predictor ---\n",
    "#     oof_acc_default = accuracy_score(y, (oof_meta_scores >= 0.50).astype(int))\n",
    "#     try:\n",
    "#         oof_auc = roc_auc_score(y, oof_meta_scores)\n",
    "#     except Exception:\n",
    "#         oof_auc = np.nan\n",
    "    \n",
    "#     print(\"\\n[OOF][Meta LR] Accuracy @ 0.50 = {:.4f}\".format(oof_acc_default))\n",
    "#     print(\"[OOF][Meta LR] ROC-AUC = {:.4f}\".format(oof_auc))\n",
    "\n",
    "#     results.append({\n",
    "#         \"seed\": seed,\n",
    "#         \"auc\": oof_auc,\n",
    "#         \"y\": y,\n",
    "#         \"oof_meta_scores\": oof_meta_scores,\n",
    "#         \"meta_test_scores\": meta_test_scores\n",
    "#     })\n",
    "\n",
    "# # ===============================================================\n",
    "# # BEST MODEL\n",
    "# # ===============================================================\n",
    "# best_result = max(results, key=lambda x: x[\"auc\"])\n",
    "# best_seed = best_result[\"seed\"]\n",
    "# best_auc = best_result[\"auc\"]\n",
    "\n",
    "# y = best_result[\"y\"]\n",
    "# oof_meta_scores = best_result[\"oof_meta_scores\"]\n",
    "# meta_test_scores = best_result[\"meta_test_scores\"]\n",
    "\n",
    "# print(\"\\n\" + \"=\"*90)\n",
    "# print(f\"Best model found with RANDOM_STATE = {best_seed}\")\n",
    "# print(f\"Best OOF AUC = {best_auc:.4f}\")\n",
    "# print(\"=\"*90)\n",
    "# print(\"\\nReady for 3.3 threshold tuning (variables: oof_meta_scores, meta_test_scores, y)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59817ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-12T23:34:06.402985Z",
     "iopub.status.busy": "2025-11-12T23:34:06.402624Z",
     "iopub.status.idle": "2025-11-12T23:55:56.139005Z",
     "shell.execute_reply": "2025-11-12T23:55:56.137080Z"
    },
    "papermill": {
     "duration": 1309.750372,
     "end_time": "2025-11-12T23:55:56.141074",
     "exception": false,
     "start_time": "2025-11-12T23:34:06.390702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================================================================\n",
      "Running stacking iteration 1\n",
      "LR_seed=99, XGB_seed=99, RF_seed=99\n",
      "==========================================================================================\n",
      "[Stack LR+XGB+RF‚ÜíLR] Using 60 selected features on 10000 training rows.\n",
      "\n",
      "[Per-fold validation summary]\n",
      "  [Fold 1] LR  acc=0.8310 | AUC=0.8916  ||  XGB acc=0.8190 | AUC=0.8849 | best_iter=None  ||  RF  acc=0.8130 | AUC=0.8784\n",
      "  [Fold 2] LR  acc=0.8280 | AUC=0.9036  ||  XGB acc=0.8260 | AUC=0.8988 | best_iter=None  ||  RF  acc=0.8200 | AUC=0.8926\n",
      "  [Fold 3] LR  acc=0.8460 | AUC=0.9128  ||  XGB acc=0.8400 | AUC=0.9134 | best_iter=None  ||  RF  acc=0.8350 | AUC=0.9015\n",
      "  [Fold 4] LR  acc=0.8540 | AUC=0.9167  ||  XGB acc=0.8360 | AUC=0.9135 | best_iter=None  ||  RF  acc=0.8190 | AUC=0.8980\n",
      "  [Fold 5] LR  acc=0.8480 | AUC=0.9241  ||  XGB acc=0.8380 | AUC=0.9193 | best_iter=None  ||  RF  acc=0.8410 | AUC=0.9126\n",
      "  [Fold 6] LR  acc=0.8380 | AUC=0.8998  ||  XGB acc=0.8290 | AUC=0.8873 | best_iter=None  ||  RF  acc=0.8100 | AUC=0.8827\n",
      "  [Fold 7] LR  acc=0.8330 | AUC=0.9101  ||  XGB acc=0.8340 | AUC=0.9034 | best_iter=None  ||  RF  acc=0.8170 | AUC=0.8922\n",
      "  [Fold 8] LR  acc=0.8340 | AUC=0.9046  ||  XGB acc=0.8410 | AUC=0.9061 | best_iter=None  ||  RF  acc=0.8190 | AUC=0.8937\n",
      "  [Fold 9] LR  acc=0.8350 | AUC=0.9003  ||  XGB acc=0.8390 | AUC=0.8956 | best_iter=None  ||  RF  acc=0.8210 | AUC=0.8911\n",
      "  [Fold 10] LR  acc=0.8440 | AUC=0.9074  ||  XGB acc=0.8460 | AUC=0.9063 | best_iter=None  ||  RF  acc=0.8270 | AUC=0.9020\n",
      "\n",
      "[OOF][Meta LR] Accuracy @ 0.50 = 0.8395\n",
      "[OOF][Meta LR] ROC-AUC = 0.9084\n",
      "\n",
      "==========================================================================================\n",
      "Running stacking iteration 2\n",
      "LR_seed=99, XGB_seed=99, RF_seed=200\n",
      "==========================================================================================\n",
      "[Stack LR+XGB+RF‚ÜíLR] Using 60 selected features on 10000 training rows.\n",
      "\n",
      "[Per-fold validation summary]\n",
      "  [Fold 1] LR  acc=0.8310 | AUC=0.8916  ||  XGB acc=0.8190 | AUC=0.8849 | best_iter=None  ||  RF  acc=0.8140 | AUC=0.8783\n",
      "  [Fold 2] LR  acc=0.8280 | AUC=0.9036  ||  XGB acc=0.8260 | AUC=0.8988 | best_iter=None  ||  RF  acc=0.8180 | AUC=0.8908\n",
      "  [Fold 3] LR  acc=0.8460 | AUC=0.9128  ||  XGB acc=0.8400 | AUC=0.9134 | best_iter=None  ||  RF  acc=0.8370 | AUC=0.9015\n",
      "  [Fold 4] LR  acc=0.8540 | AUC=0.9167  ||  XGB acc=0.8360 | AUC=0.9135 | best_iter=None  ||  RF  acc=0.8180 | AUC=0.8973\n",
      "  [Fold 5] LR  acc=0.8480 | AUC=0.9241  ||  XGB acc=0.8380 | AUC=0.9193 | best_iter=None  ||  RF  acc=0.8360 | AUC=0.9132\n",
      "  [Fold 6] LR  acc=0.8380 | AUC=0.8998  ||  XGB acc=0.8290 | AUC=0.8873 | best_iter=None  ||  RF  acc=0.8120 | AUC=0.8822\n",
      "  [Fold 7] LR  acc=0.8330 | AUC=0.9101  ||  XGB acc=0.8340 | AUC=0.9034 | best_iter=None  ||  RF  acc=0.8200 | AUC=0.8926\n",
      "  [Fold 8] LR  acc=0.8340 | AUC=0.9046  ||  XGB acc=0.8410 | AUC=0.9061 | best_iter=None  ||  RF  acc=0.8190 | AUC=0.8929\n",
      "  [Fold 9] LR  acc=0.8350 | AUC=0.9003  ||  XGB acc=0.8390 | AUC=0.8956 | best_iter=None  ||  RF  acc=0.8230 | AUC=0.8908\n",
      "  [Fold 10] LR  acc=0.8440 | AUC=0.9074  ||  XGB acc=0.8460 | AUC=0.9063 | best_iter=None  ||  RF  acc=0.8330 | AUC=0.9031\n",
      "\n",
      "[OOF][Meta LR] Accuracy @ 0.50 = 0.8400\n",
      "[OOF][Meta LR] ROC-AUC = 0.9084\n",
      "\n",
      "==========================================================================================\n",
      "Running stacking iteration 3\n",
      "LR_seed=99, XGB_seed=99, RF_seed=110\n",
      "==========================================================================================\n",
      "[Stack LR+XGB+RF‚ÜíLR] Using 60 selected features on 10000 training rows.\n",
      "\n",
      "[Per-fold validation summary]\n",
      "  [Fold 1] LR  acc=0.8310 | AUC=0.8916  ||  XGB acc=0.8190 | AUC=0.8849 | best_iter=None  ||  RF  acc=0.8130 | AUC=0.8776\n",
      "  [Fold 2] LR  acc=0.8280 | AUC=0.9036  ||  XGB acc=0.8260 | AUC=0.8988 | best_iter=None  ||  RF  acc=0.8200 | AUC=0.8925\n",
      "  [Fold 3] LR  acc=0.8460 | AUC=0.9128  ||  XGB acc=0.8400 | AUC=0.9134 | best_iter=None  ||  RF  acc=0.8380 | AUC=0.9015\n",
      "  [Fold 4] LR  acc=0.8540 | AUC=0.9167  ||  XGB acc=0.8360 | AUC=0.9135 | best_iter=None  ||  RF  acc=0.8210 | AUC=0.8978\n",
      "  [Fold 5] LR  acc=0.8480 | AUC=0.9241  ||  XGB acc=0.8380 | AUC=0.9193 | best_iter=None  ||  RF  acc=0.8420 | AUC=0.9125\n",
      "  [Fold 6] LR  acc=0.8380 | AUC=0.8998  ||  XGB acc=0.8290 | AUC=0.8873 | best_iter=None  ||  RF  acc=0.8150 | AUC=0.8825\n",
      "  [Fold 7] LR  acc=0.8330 | AUC=0.9101  ||  XGB acc=0.8340 | AUC=0.9034 | best_iter=None  ||  RF  acc=0.8190 | AUC=0.8922\n",
      "  [Fold 8] LR  acc=0.8340 | AUC=0.9046  ||  XGB acc=0.8410 | AUC=0.9061 | best_iter=None  ||  RF  acc=0.8180 | AUC=0.8938\n",
      "  [Fold 9] LR  acc=0.8350 | AUC=0.9003  ||  XGB acc=0.8390 | AUC=0.8956 | best_iter=None  ||  RF  acc=0.8210 | AUC=0.8912\n",
      "  [Fold 10] LR  acc=0.8440 | AUC=0.9074  ||  XGB acc=0.8460 | AUC=0.9063 | best_iter=None  ||  RF  acc=0.8280 | AUC=0.9027\n",
      "\n",
      "[OOF][Meta LR] Accuracy @ 0.50 = 0.8395\n",
      "[OOF][Meta LR] ROC-AUC = 0.9084\n",
      "\n",
      "==========================================================================================\n",
      "Running stacking iteration 4\n",
      "LR_seed=70, XGB_seed=80, RF_seed=200\n",
      "==========================================================================================\n",
      "[Stack LR+XGB+RF‚ÜíLR] Using 60 selected features on 10000 training rows.\n",
      "\n",
      "[Per-fold validation summary]\n",
      "  [Fold 1] LR  acc=0.8310 | AUC=0.8916  ||  XGB acc=0.8180 | AUC=0.8843 | best_iter=None  ||  RF  acc=0.8140 | AUC=0.8783\n",
      "  [Fold 2] LR  acc=0.8280 | AUC=0.9036  ||  XGB acc=0.8260 | AUC=0.8985 | best_iter=None  ||  RF  acc=0.8180 | AUC=0.8908\n",
      "  [Fold 3] LR  acc=0.8460 | AUC=0.9128  ||  XGB acc=0.8520 | AUC=0.9138 | best_iter=None  ||  RF  acc=0.8370 | AUC=0.9015\n",
      "  [Fold 4] LR  acc=0.8540 | AUC=0.9167  ||  XGB acc=0.8410 | AUC=0.9155 | best_iter=None  ||  RF  acc=0.8180 | AUC=0.8973\n",
      "  [Fold 5] LR  acc=0.8480 | AUC=0.9241  ||  XGB acc=0.8320 | AUC=0.9220 | best_iter=None  ||  RF  acc=0.8360 | AUC=0.9132\n",
      "  [Fold 6] LR  acc=0.8380 | AUC=0.8998  ||  XGB acc=0.8310 | AUC=0.8831 | best_iter=None  ||  RF  acc=0.8120 | AUC=0.8822\n",
      "  [Fold 7] LR  acc=0.8330 | AUC=0.9101  ||  XGB acc=0.8340 | AUC=0.9018 | best_iter=None  ||  RF  acc=0.8200 | AUC=0.8926\n",
      "  [Fold 8] LR  acc=0.8340 | AUC=0.9046  ||  XGB acc=0.8360 | AUC=0.9046 | best_iter=None  ||  RF  acc=0.8190 | AUC=0.8929\n",
      "  [Fold 9] LR  acc=0.8350 | AUC=0.9003  ||  XGB acc=0.8350 | AUC=0.8939 | best_iter=None  ||  RF  acc=0.8230 | AUC=0.8908\n",
      "  [Fold 10] LR  acc=0.8440 | AUC=0.9074  ||  XGB acc=0.8400 | AUC=0.9052 | best_iter=None  ||  RF  acc=0.8330 | AUC=0.9031\n",
      "\n",
      "[OOF][Meta LR] Accuracy @ 0.50 = 0.8392\n",
      "[OOF][Meta LR] ROC-AUC = 0.9084\n",
      "\n",
      "==========================================================================================\n",
      "Running stacking iteration 5\n",
      "LR_seed=65, XGB_seed=50, RF_seed=250\n",
      "==========================================================================================\n",
      "[Stack LR+XGB+RF‚ÜíLR] Using 60 selected features on 10000 training rows.\n",
      "\n",
      "[Per-fold validation summary]\n",
      "  [Fold 1] LR  acc=0.8310 | AUC=0.8916  ||  XGB acc=0.8200 | AUC=0.8834 | best_iter=None  ||  RF  acc=0.8170 | AUC=0.8782\n",
      "  [Fold 2] LR  acc=0.8280 | AUC=0.9036  ||  XGB acc=0.8330 | AUC=0.9006 | best_iter=None  ||  RF  acc=0.8190 | AUC=0.8929\n",
      "  [Fold 3] LR  acc=0.8460 | AUC=0.9128  ||  XGB acc=0.8430 | AUC=0.9129 | best_iter=None  ||  RF  acc=0.8340 | AUC=0.9016\n",
      "  [Fold 4] LR  acc=0.8540 | AUC=0.9167  ||  XGB acc=0.8340 | AUC=0.9175 | best_iter=None  ||  RF  acc=0.8190 | AUC=0.8985\n",
      "  [Fold 5] LR  acc=0.8480 | AUC=0.9241  ||  XGB acc=0.8440 | AUC=0.9216 | best_iter=None  ||  RF  acc=0.8390 | AUC=0.9124\n",
      "  [Fold 6] LR  acc=0.8380 | AUC=0.8998  ||  XGB acc=0.8360 | AUC=0.8853 | best_iter=None  ||  RF  acc=0.8110 | AUC=0.8822\n",
      "  [Fold 7] LR  acc=0.8330 | AUC=0.9101  ||  XGB acc=0.8280 | AUC=0.9000 | best_iter=None  ||  RF  acc=0.8160 | AUC=0.8919\n",
      "  [Fold 8] LR  acc=0.8340 | AUC=0.9046  ||  XGB acc=0.8320 | AUC=0.9055 | best_iter=None  ||  RF  acc=0.8200 | AUC=0.8926\n",
      "  [Fold 9] LR  acc=0.8350 | AUC=0.9003  ||  XGB acc=0.8380 | AUC=0.8941 | best_iter=None  ||  RF  acc=0.8210 | AUC=0.8902\n",
      "  [Fold 10] LR  acc=0.8440 | AUC=0.9074  ||  XGB acc=0.8390 | AUC=0.9045 | best_iter=None  ||  RF  acc=0.8310 | AUC=0.9022\n",
      "\n",
      "[OOF][Meta LR] Accuracy @ 0.50 = 0.8400\n",
      "[OOF][Meta LR] ROC-AUC = 0.9082\n",
      "\n",
      "==========================================================================================\n",
      "Running stacking iteration 6\n",
      "LR_seed=90, XGB_seed=75, RF_seed=180\n",
      "==========================================================================================\n",
      "[Stack LR+XGB+RF‚ÜíLR] Using 60 selected features on 10000 training rows.\n",
      "\n",
      "[Per-fold validation summary]\n",
      "  [Fold 1] LR  acc=0.8310 | AUC=0.8916  ||  XGB acc=0.8200 | AUC=0.8845 | best_iter=None  ||  RF  acc=0.8100 | AUC=0.8775\n",
      "  [Fold 2] LR  acc=0.8280 | AUC=0.9036  ||  XGB acc=0.8270 | AUC=0.8991 | best_iter=None  ||  RF  acc=0.8180 | AUC=0.8924\n",
      "  [Fold 3] LR  acc=0.8460 | AUC=0.9128  ||  XGB acc=0.8500 | AUC=0.9153 | best_iter=None  ||  RF  acc=0.8350 | AUC=0.9018\n",
      "  [Fold 4] LR  acc=0.8540 | AUC=0.9167  ||  XGB acc=0.8330 | AUC=0.9154 | best_iter=None  ||  RF  acc=0.8220 | AUC=0.8976\n",
      "  [Fold 5] LR  acc=0.8480 | AUC=0.9241  ||  XGB acc=0.8450 | AUC=0.9214 | best_iter=None  ||  RF  acc=0.8370 | AUC=0.9133\n",
      "  [Fold 6] LR  acc=0.8380 | AUC=0.8998  ||  XGB acc=0.8390 | AUC=0.8878 | best_iter=None  ||  RF  acc=0.8140 | AUC=0.8832\n",
      "  [Fold 7] LR  acc=0.8330 | AUC=0.9101  ||  XGB acc=0.8340 | AUC=0.9015 | best_iter=None  ||  RF  acc=0.8170 | AUC=0.8926\n",
      "  [Fold 8] LR  acc=0.8340 | AUC=0.9046  ||  XGB acc=0.8350 | AUC=0.9064 | best_iter=None  ||  RF  acc=0.8220 | AUC=0.8927\n",
      "  [Fold 9] LR  acc=0.8350 | AUC=0.9003  ||  XGB acc=0.8340 | AUC=0.8935 | best_iter=None  ||  RF  acc=0.8270 | AUC=0.8908\n",
      "  [Fold 10] LR  acc=0.8440 | AUC=0.9074  ||  XGB acc=0.8470 | AUC=0.9051 | best_iter=None  ||  RF  acc=0.8290 | AUC=0.9023\n",
      "\n",
      "[OOF][Meta LR] Accuracy @ 0.50 = 0.8400\n",
      "[OOF][Meta LR] ROC-AUC = 0.9084\n",
      "\n",
      "==========================================================================================\n",
      "Running stacking iteration 7\n",
      "LR_seed=60, XGB_seed=85, RF_seed=220\n",
      "==========================================================================================\n",
      "[Stack LR+XGB+RF‚ÜíLR] Using 60 selected features on 10000 training rows.\n",
      "\n",
      "[Per-fold validation summary]\n",
      "  [Fold 1] LR  acc=0.8310 | AUC=0.8916  ||  XGB acc=0.8180 | AUC=0.8848 | best_iter=None  ||  RF  acc=0.8140 | AUC=0.8782\n",
      "  [Fold 2] LR  acc=0.8280 | AUC=0.9036  ||  XGB acc=0.8290 | AUC=0.8993 | best_iter=None  ||  RF  acc=0.8170 | AUC=0.8921\n",
      "  [Fold 3] LR  acc=0.8460 | AUC=0.9128  ||  XGB acc=0.8490 | AUC=0.9168 | best_iter=None  ||  RF  acc=0.8350 | AUC=0.9025\n",
      "  [Fold 4] LR  acc=0.8540 | AUC=0.9167  ||  XGB acc=0.8360 | AUC=0.9163 | best_iter=None  ||  RF  acc=0.8140 | AUC=0.8985\n",
      "  [Fold 5] LR  acc=0.8480 | AUC=0.9241  ||  XGB acc=0.8350 | AUC=0.9195 | best_iter=None  ||  RF  acc=0.8380 | AUC=0.9135\n",
      "  [Fold 6] LR  acc=0.8380 | AUC=0.8998  ||  XGB acc=0.8340 | AUC=0.8852 | best_iter=None  ||  RF  acc=0.8130 | AUC=0.8823\n",
      "  [Fold 7] LR  acc=0.8330 | AUC=0.9101  ||  XGB acc=0.8270 | AUC=0.9013 | best_iter=None  ||  RF  acc=0.8150 | AUC=0.8921\n",
      "  [Fold 8] LR  acc=0.8340 | AUC=0.9046  ||  XGB acc=0.8370 | AUC=0.9069 | best_iter=None  ||  RF  acc=0.8180 | AUC=0.8939\n",
      "  [Fold 9] LR  acc=0.8350 | AUC=0.9003  ||  XGB acc=0.8340 | AUC=0.8950 | best_iter=None  ||  RF  acc=0.8230 | AUC=0.8913\n",
      "  [Fold 10] LR  acc=0.8440 | AUC=0.9074  ||  XGB acc=0.8430 | AUC=0.9054 | best_iter=None  ||  RF  acc=0.8300 | AUC=0.9025\n",
      "\n",
      "[OOF][Meta LR] Accuracy @ 0.50 = 0.8405\n",
      "[OOF][Meta LR] ROC-AUC = 0.9084\n",
      "\n",
      "==========================================================================================\n",
      "Running stacking iteration 8\n",
      "LR_seed=50, XGB_seed=55, RF_seed=160\n",
      "==========================================================================================\n",
      "[Stack LR+XGB+RF‚ÜíLR] Using 60 selected features on 10000 training rows.\n",
      "\n",
      "[Per-fold validation summary]\n",
      "  [Fold 1] LR  acc=0.8310 | AUC=0.8916  ||  XGB acc=0.8230 | AUC=0.8838 | best_iter=None  ||  RF  acc=0.8110 | AUC=0.8787\n",
      "  [Fold 2] LR  acc=0.8280 | AUC=0.9036  ||  XGB acc=0.8220 | AUC=0.9005 | best_iter=None  ||  RF  acc=0.8200 | AUC=0.8926\n",
      "  [Fold 3] LR  acc=0.8460 | AUC=0.9128  ||  XGB acc=0.8470 | AUC=0.9143 | best_iter=None  ||  RF  acc=0.8400 | AUC=0.9028\n",
      "  [Fold 4] LR  acc=0.8540 | AUC=0.9167  ||  XGB acc=0.8380 | AUC=0.9155 | best_iter=None  ||  RF  acc=0.8210 | AUC=0.8982\n",
      "  [Fold 5] LR  acc=0.8480 | AUC=0.9241  ||  XGB acc=0.8410 | AUC=0.9216 | best_iter=None  ||  RF  acc=0.8360 | AUC=0.9139\n",
      "  [Fold 6] LR  acc=0.8380 | AUC=0.8998  ||  XGB acc=0.8380 | AUC=0.8863 | best_iter=None  ||  RF  acc=0.8210 | AUC=0.8825\n",
      "  [Fold 7] LR  acc=0.8330 | AUC=0.9101  ||  XGB acc=0.8330 | AUC=0.9052 | best_iter=None  ||  RF  acc=0.8160 | AUC=0.8923\n",
      "  [Fold 8] LR  acc=0.8340 | AUC=0.9046  ||  XGB acc=0.8340 | AUC=0.9047 | best_iter=None  ||  RF  acc=0.8250 | AUC=0.8933\n",
      "  [Fold 9] LR  acc=0.8350 | AUC=0.9003  ||  XGB acc=0.8370 | AUC=0.8945 | best_iter=None  ||  RF  acc=0.8210 | AUC=0.8916\n",
      "  [Fold 10] LR  acc=0.8440 | AUC=0.9074  ||  XGB acc=0.8410 | AUC=0.9065 | best_iter=None  ||  RF  acc=0.8280 | AUC=0.9021\n",
      "\n",
      "[OOF][Meta LR] Accuracy @ 0.50 = 0.8409\n",
      "[OOF][Meta LR] ROC-AUC = 0.9085\n",
      "\n",
      "==========================================================================================\n",
      "Running stacking iteration 9\n",
      "LR_seed=80, XGB_seed=70, RF_seed=210\n",
      "==========================================================================================\n",
      "[Stack LR+XGB+RF‚ÜíLR] Using 60 selected features on 10000 training rows.\n",
      "\n",
      "[Per-fold validation summary]\n",
      "  [Fold 1] LR  acc=0.8310 | AUC=0.8916  ||  XGB acc=0.8190 | AUC=0.8842 | best_iter=None  ||  RF  acc=0.8150 | AUC=0.8781\n",
      "  [Fold 2] LR  acc=0.8280 | AUC=0.9036  ||  XGB acc=0.8270 | AUC=0.9001 | best_iter=None  ||  RF  acc=0.8200 | AUC=0.8922\n",
      "  [Fold 3] LR  acc=0.8460 | AUC=0.9128  ||  XGB acc=0.8420 | AUC=0.9151 | best_iter=None  ||  RF  acc=0.8340 | AUC=0.9009\n",
      "  [Fold 4] LR  acc=0.8540 | AUC=0.9167  ||  XGB acc=0.8380 | AUC=0.9176 | best_iter=None  ||  RF  acc=0.8190 | AUC=0.8981\n",
      "  [Fold 5] LR  acc=0.8480 | AUC=0.9241  ||  XGB acc=0.8440 | AUC=0.9195 | best_iter=None  ||  RF  acc=0.8380 | AUC=0.9132\n",
      "  [Fold 6] LR  acc=0.8380 | AUC=0.8998  ||  XGB acc=0.8340 | AUC=0.8836 | best_iter=None  ||  RF  acc=0.8140 | AUC=0.8819\n",
      "  [Fold 7] LR  acc=0.8330 | AUC=0.9101  ||  XGB acc=0.8370 | AUC=0.9032 | best_iter=None  ||  RF  acc=0.8140 | AUC=0.8919\n",
      "  [Fold 8] LR  acc=0.8340 | AUC=0.9046  ||  XGB acc=0.8340 | AUC=0.9044 | best_iter=None  ||  RF  acc=0.8190 | AUC=0.8935\n",
      "  [Fold 9] LR  acc=0.8350 | AUC=0.9003  ||  XGB acc=0.8340 | AUC=0.8941 | best_iter=None  ||  RF  acc=0.8280 | AUC=0.8909\n",
      "  [Fold 10] LR  acc=0.8440 | AUC=0.9074  ||  XGB acc=0.8380 | AUC=0.9046 | best_iter=None  ||  RF  acc=0.8330 | AUC=0.9025\n",
      "\n",
      "[OOF][Meta LR] Accuracy @ 0.50 = 0.8394\n",
      "[OOF][Meta LR] ROC-AUC = 0.9083\n",
      "\n",
      "==========================================================================================\n",
      "Running stacking iteration 10\n",
      "LR_seed=75, XGB_seed=65, RF_seed=190\n",
      "==========================================================================================\n",
      "[Stack LR+XGB+RF‚ÜíLR] Using 60 selected features on 10000 training rows.\n",
      "\n",
      "[Per-fold validation summary]\n",
      "  [Fold 1] LR  acc=0.8310 | AUC=0.8916  ||  XGB acc=0.8190 | AUC=0.8838 | best_iter=None  ||  RF  acc=0.8150 | AUC=0.8785\n",
      "  [Fold 2] LR  acc=0.8280 | AUC=0.9036  ||  XGB acc=0.8300 | AUC=0.8988 | best_iter=None  ||  RF  acc=0.8160 | AUC=0.8925\n",
      "  [Fold 3] LR  acc=0.8460 | AUC=0.9128  ||  XGB acc=0.8430 | AUC=0.9130 | best_iter=None  ||  RF  acc=0.8350 | AUC=0.9019\n",
      "  [Fold 4] LR  acc=0.8540 | AUC=0.9167  ||  XGB acc=0.8340 | AUC=0.9159 | best_iter=None  ||  RF  acc=0.8190 | AUC=0.8976\n",
      "  [Fold 5] LR  acc=0.8480 | AUC=0.9241  ||  XGB acc=0.8360 | AUC=0.9210 | best_iter=None  ||  RF  acc=0.8390 | AUC=0.9137\n",
      "  [Fold 6] LR  acc=0.8380 | AUC=0.8998  ||  XGB acc=0.8340 | AUC=0.8869 | best_iter=None  ||  RF  acc=0.8140 | AUC=0.8835\n",
      "  [Fold 7] LR  acc=0.8330 | AUC=0.9101  ||  XGB acc=0.8360 | AUC=0.9007 | best_iter=None  ||  RF  acc=0.8150 | AUC=0.8928\n",
      "  [Fold 8] LR  acc=0.8340 | AUC=0.9046  ||  XGB acc=0.8390 | AUC=0.9061 | best_iter=None  ||  RF  acc=0.8260 | AUC=0.8927\n",
      "  [Fold 9] LR  acc=0.8350 | AUC=0.9003  ||  XGB acc=0.8390 | AUC=0.8952 | best_iter=None  ||  RF  acc=0.8250 | AUC=0.8912\n",
      "  [Fold 10] LR  acc=0.8440 | AUC=0.9074  ||  XGB acc=0.8410 | AUC=0.9057 | best_iter=None  ||  RF  acc=0.8330 | AUC=0.9021\n",
      "\n",
      "[OOF][Meta LR] Accuracy @ 0.50 = 0.8395\n",
      "[OOF][Meta LR] ROC-AUC = 0.9084\n",
      "\n",
      "==========================================================================================\n",
      "Best model found with LR_seed=50, XGB_seed=55, RF_seed=160\n",
      "Best OOF AUC = 0.9085\n",
      "==========================================================================================\n",
      "\n",
      "Ready for 3.3 threshold tuning (variables: oof_meta_scores, meta_test_scores, y)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# ===============================================================\n",
    "# MULTI-SEED ENSEMBLE WRAPPER\n",
    "# ===============================================================\n",
    "\n",
    "SEEDS = [\n",
    "    (99, 99, 99),\n",
    "    (99,99, 200),\n",
    "    (99, 99, 110),\n",
    "    (70, 80, 200),\n",
    "    (65, 50, 250),\n",
    "    (90, 75, 180),\n",
    "    (60, 85, 220),\n",
    "    (50, 55, 160),\n",
    "    (80, 70, 210),\n",
    "    (75, 65, 190),\n",
    "]\n",
    "results = []\n",
    "\n",
    "for idx, (seed_lr, seed_xgb, seed_rf) in enumerate(SEEDS, 1):\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(f\"Running stacking iteration {idx}\")\n",
    "    print(f\"LR_seed={seed_lr}, XGB_seed={seed_xgb}, RF_seed={seed_rf}\")\n",
    "    print(\"=\"*90)\n",
    "\n",
    "    # global random seed\n",
    "    META_RANDOM_STATE = 42\n",
    "    np.random.seed(META_RANDOM_STATE)\n",
    "    FOLDS = 10\n",
    "\n",
    "    # orginal block stars from here <------\n",
    "    assert \"selected_cols\" in globals(), \"Run Cell 3.1 to define 'selected_cols'.\"\n",
    "    assert \"train_reduced\" in globals() and \"test_reduced\" in globals(), \"Missing reduced frames from 3.1.\"\n",
    "    \n",
    "    X_sel = train_reduced[selected_cols].to_numpy()\n",
    "    X_test_sel = test_reduced[selected_cols].to_numpy()\n",
    "    y = train_reduced[\"player_won\"].astype(int).to_numpy()\n",
    "    \n",
    "    n_train = X_sel.shape[0]\n",
    "    n_test  = X_test_sel.shape[0]\n",
    "    \n",
    "    print(f\"[Stack LR+XGB+RF‚ÜíLR] Using {X_sel.shape[1]} selected features on {n_train} training rows.\")\n",
    "    \n",
    "    # --- Base learners -------------------------------------------------------------------------\n",
    "    # (1) Logistic Regression (scaled). No calibration needed.\n",
    "    base_lr = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(\n",
    "            solver=\"liblinear\",\n",
    "            penalty=\"l2\",\n",
    "            C=0.5,\n",
    "            max_iter=3000,\n",
    "            random_state=seed_lr\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # (2) XGBoost (with early stopping). We'll calibrate per-fold on the val fold.\n",
    "    base_xgb_params = dict(\n",
    "        n_estimators=2000,           # high cap, early stopping will cut it\n",
    "        learning_rate=0.03,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        reg_alpha=0.0,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=seed_xgb,\n",
    "        n_jobs=-1,\n",
    "        tree_method=\"hist\"\n",
    "    )\n",
    "    \n",
    "    # (3) Random Forest (regularized) + per-fold calibration\n",
    "    base_rf = RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        max_depth=10,\n",
    "        min_samples_leaf=10,\n",
    "        max_features=\"sqrt\",\n",
    "        bootstrap=True,\n",
    "        n_jobs=-1,\n",
    "        random_state=seed_rf\n",
    "    )\n",
    "    \n",
    "    base_names  = [\"lr\", \"xgb\", \"rf\"]\n",
    "    n_base      = len(base_names)\n",
    "    \n",
    "    # --- OOF holders for base learners (level-1 features) --------------------------------------\n",
    "    oof_base = np.zeros((n_train, n_base), dtype=float)\n",
    "    test_base_folds = np.zeros((n_test, n_base, FOLDS), dtype=float)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    print(\"\\n[Per-fold validation summary]\")\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_sel, y), 1):\n",
    "        X_tr, X_va = X_sel[tr_idx], X_sel[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "    \n",
    "        # ---- Base 1: Logistic Regression (no calibration) ----\n",
    "        lr_model = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            LogisticRegression(\n",
    "                solver=\"liblinear\",\n",
    "                penalty=\"l2\",\n",
    "                C=0.5,\n",
    "                max_iter=3000,\n",
    "                random_state=seed_lr\n",
    "            )\n",
    "        )\n",
    "        lr_model.fit(X_tr, y_tr)\n",
    "        lr_va = lr_model.predict_proba(X_va)[:, 1]\n",
    "        lr_te = lr_model.predict_proba(X_test_sel)[:, 1]\n",
    "    \n",
    "        # ---- Base 2: XGBoost (early stopping) + sigmoid calibration on val ----\n",
    "        xgb_model = xgb.XGBClassifier(**base_xgb_params)\n",
    "        xgb_model.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            verbose=False\n",
    "        )\n",
    "    \n",
    "        # predictions at best iteration (handle API differences safely)\n",
    "        try:\n",
    "            best_it = getattr(xgb_model, \"best_iteration\", None)\n",
    "            if best_it is not None:\n",
    "                xgb_va_raw = xgb_model.predict_proba(X_va, iteration_range=(0, best_it + 1))[:, 1]\n",
    "                xgb_te_raw = xgb_model.predict_proba(X_test_sel, iteration_range=(0, best_it + 1))[:, 1]\n",
    "            else:\n",
    "                xgb_va_raw = xgb_model.predict_proba(X_va)[:, 1]\n",
    "                xgb_te_raw = xgb_model.predict_proba(X_test_sel)[:, 1]\n",
    "            used_best = best_it\n",
    "        except Exception:\n",
    "            xgb_va_raw = xgb_model.predict_proba(X_va)[:, 1]\n",
    "            xgb_te_raw = xgb_model.predict_proba(X_test_sel)[:, 1]\n",
    "            used_best = \"N/A\"\n",
    "    \n",
    "        # calibrate on the validation fold (no leakage)\n",
    "        xgb_cal = CalibratedClassifierCV(estimator=xgb_model, method=\"sigmoid\", cv=\"prefit\")\n",
    "        xgb_cal.fit(X_va, y_va)\n",
    "        xgb_va = xgb_cal.predict_proba(X_va)[:, 1]\n",
    "        xgb_te = xgb_cal.predict_proba(X_test_sel)[:, 1]\n",
    "    \n",
    "        # ---- Base 3: Random Forest + sigmoid calibration on val ----\n",
    "        rf_model = RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            max_depth=10,\n",
    "            min_samples_leaf=10,\n",
    "            max_features=\"sqrt\",\n",
    "            bootstrap=True,\n",
    "            n_jobs=-1,\n",
    "            random_state=seed_rf + fold  # slight variation per fold\n",
    "        )\n",
    "        rf_model.fit(X_tr, y_tr)\n",
    "        rf_cal = CalibratedClassifierCV(estimator=rf_model, method=\"sigmoid\", cv=\"prefit\")\n",
    "        rf_cal.fit(X_va, y_va)\n",
    "        rf_va = rf_cal.predict_proba(X_va)[:, 1]\n",
    "        rf_te = rf_cal.predict_proba(X_test_sel)[:, 1]\n",
    "    \n",
    "        # ---- Store OOF & per-fold test probs (level-1 design) ----\n",
    "        oof_base[va_idx, 0] = lr_va\n",
    "        oof_base[va_idx, 1] = xgb_va\n",
    "        oof_base[va_idx, 2] = rf_va\n",
    "    \n",
    "        test_base_folds[:, 0, fold - 1] = lr_te\n",
    "        test_base_folds[:, 1, fold - 1] = xgb_te\n",
    "        test_base_folds[:, 2, fold - 1] = rf_te\n",
    "    \n",
    "        # ---- Fold metrics (on validation) ----\n",
    "        # Report each base quickly (accuracy/AUC at 0.50)\n",
    "        def _rep(name, p):\n",
    "            acc = accuracy_score(y_va, (p >= 0.5).astype(int))\n",
    "            try:\n",
    "                auc = roc_auc_score(y_va, p)\n",
    "            except Exception:\n",
    "                auc = np.nan\n",
    "            return acc, auc\n",
    "    \n",
    "        acc_lr, auc_lr   = _rep(\"lr\",  lr_va)\n",
    "        acc_xgb, auc_xgb = _rep(\"xgb\", xgb_va)\n",
    "        acc_rf, auc_rf   = _rep(\"rf\",  rf_va)\n",
    "    \n",
    "        print(f\"  [Fold {fold}] \"\n",
    "              f\"LR  acc={acc_lr:.4f} | AUC={auc_lr:.4f}  ||  \"\n",
    "              f\"XGB acc={acc_xgb:.4f} | AUC={auc_xgb:.4f} | best_iter={used_best}  ||  \"\n",
    "              f\"RF  acc={acc_rf:.4f} | AUC={auc_rf:.4f}\")\n",
    "    \n",
    "    # --- Aggregate test probs across folds for each base learner ---\n",
    "    test_base_mean = test_base_folds.mean(axis=2)   # shape: (n_test, 3)\n",
    "    \n",
    "    # --- Meta-learner on OOF base features (with second-level OOF for honest estimate) ----------\n",
    "    meta_clf = LogisticRegression(\n",
    "        solver=\"lbfgs\",\n",
    "        penalty=\"l2\",\n",
    "        C=1.0,\n",
    "        max_iter=5000,\n",
    "        random_state=META_RANDOM_STATE\n",
    "    )\n",
    "    \n",
    "    # Build true OOF for meta as well\n",
    "    oof_meta_scores = np.zeros(n_train, dtype=float)\n",
    "    meta_test_folds = np.zeros((n_test, FOLDS), dtype=float)\n",
    "    \n",
    "    skf_meta = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=META_RANDOM_STATE + 1)\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf_meta.split(oof_base, y), 1):\n",
    "        X_tr_m, X_va_m = oof_base[tr_idx], oof_base[va_idx]\n",
    "        y_tr_m, y_va_m = y[tr_idx], y[va_idx]\n",
    "    \n",
    "        meta_clf_fold = LogisticRegression(\n",
    "            solver=\"lbfgs\",\n",
    "            penalty=\"l2\",\n",
    "            C=1.0,\n",
    "            max_iter=5000,\n",
    "            random_state=META_RANDOM_STATE + fold\n",
    "        )\n",
    "        meta_clf_fold.fit(X_tr_m, y_tr_m)\n",
    "        oof_meta_scores[va_idx] = meta_clf_fold.predict_proba(X_va_m)[:, 1]\n",
    "        meta_test_folds[:, fold - 1] = meta_clf_fold.predict_proba(test_base_mean)[:, 1]\n",
    "    \n",
    "    # Final meta on full OOF (optional fit, used for reporting and stability)\n",
    "    meta_clf.fit(oof_base, y)\n",
    "    meta_test_scores = meta_test_folds.mean(axis=1)\n",
    "    \n",
    "    # --- Quick OOF report for the stacked meta predictor ---\n",
    "    oof_acc_default = accuracy_score(y, (oof_meta_scores >= 0.50).astype(int))\n",
    "    try:\n",
    "        oof_auc = roc_auc_score(y, oof_meta_scores)\n",
    "    except Exception:\n",
    "        oof_auc = np.nan\n",
    "    \n",
    "    print(\"\\n[OOF][Meta LR] Accuracy @ 0.50 = {:.4f}\".format(oof_acc_default))\n",
    "    print(\"[OOF][Meta LR] ROC-AUC = {:.4f}\".format(oof_auc))\n",
    "\n",
    "    results.append({\n",
    "        \"seed\": f\"LR_seed={seed_lr}, XGB_seed={seed_xgb}, RF_seed={seed_rf}\",\n",
    "        \"auc\": oof_auc,\n",
    "        \"y\": y,\n",
    "        \"oof_meta_scores\": oof_meta_scores,\n",
    "        \"meta_test_scores\": meta_test_scores\n",
    "    })\n",
    "\n",
    "# ===============================================================\n",
    "# BEST MODEL\n",
    "# ===============================================================\n",
    "best_result = max(results, key=lambda x: x[\"auc\"])\n",
    "best_seed = best_result[\"seed\"]\n",
    "best_auc = best_result[\"auc\"]\n",
    "\n",
    "y = best_result[\"y\"]\n",
    "oof_meta_scores = best_result[\"oof_meta_scores\"]\n",
    "meta_test_scores = best_result[\"meta_test_scores\"]\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(f\"Best model found with {best_seed}\")\n",
    "print(f\"Best OOF AUC = {best_auc:.4f}\")\n",
    "print(\"=\"*90)\n",
    "print(\"\\nReady for 3.3 threshold tuning (variables: oof_meta_scores, meta_test_scores, y)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29643c2b",
   "metadata": {
    "_cell_guid": "ff38c3fc-7871-4c84-a702-d12a57e52704",
    "_uuid": "bdd6313f-2062-42fa-b307-393d08e9a535",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.035144,
     "end_time": "2025-11-12T23:55:56.227293",
     "exception": false,
     "start_time": "2025-11-12T23:55:56.192149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3.3 - Threshold tuning for the StackingClassifier (uses OOF probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "747d067c",
   "metadata": {
    "_cell_guid": "16776832-1ec2-414c-8bc4-2d9114e3aa43",
    "_uuid": "4ec6120f-48d6-44f2-83eb-5e69efd573cb",
    "execution": {
     "iopub.execute_input": "2025-11-12T23:55:56.270644Z",
     "iopub.status.busy": "2025-11-12T23:55:56.270311Z",
     "iopub.status.idle": "2025-11-12T23:55:56.457022Z",
     "shell.execute_reply": "2025-11-12T23:55:56.455805Z"
    },
    "papermill": {
     "duration": 0.205501,
     "end_time": "2025-11-12T23:55:56.458470",
     "exception": false,
     "start_time": "2025-11-12T23:55:56.252969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Stacking][OOF] Accuracy @ 0.50 = 0.8409\n",
      "[Stacking][Search] Coarse best: thr=0.473 | OOF acc=0.8419\n",
      "[Stacking][Best] Final OOF threshold = 0.473 | OOF Accuracy = 0.8419\n",
      "‚úÖ Created 'stack_pred_labels_tuned' for submission.\n"
     ]
    }
   ],
   "source": [
    "# === 3.3 Threshold tuning for the StackingClassifier (uses in-sample probs) ===\n",
    "# Inputs expected from 3.2: y, oof_meta_scores, meta_test_scores\n",
    "# Outputs: STACK_FINAL_THRESHOLD, STACK_FINAL_OOF_ACC, stack_pred_labels_tuned\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# --- Safety checks ---\n",
    "missing = [name for name in [\"y\", \"oof_meta_scores\", \"meta_test_scores\"] if name not in globals()]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Missing required objects from 3.2: {missing}. Please run Cell 3.2 first.\")\n",
    "\n",
    "# --- Baseline @ 0.50 ---\n",
    "oof_acc_default = accuracy_score(y, (oof_meta_scores >= 0.50).astype(int))\n",
    "print(f\"[Stacking][OOF] Accuracy @ 0.50 = {oof_acc_default:.4f}\")\n",
    "\n",
    "# --- Coarse search over thresholds ---\n",
    "ths_coarse = np.linspace(0.30, 0.70, 121)  # step 0.0033...\n",
    "accs_coarse = [accuracy_score(y, (oof_meta_scores >= t).astype(int)) for t in ths_coarse]\n",
    "best_idx_c = int(np.argmax(accs_coarse))\n",
    "best_thr_coarse = float(ths_coarse[best_idx_c])\n",
    "print(f\"[Stacking][Search] Coarse best: thr={best_thr_coarse:.3f} | OOF acc={accs_coarse[best_idx_c]:.4f}\")\n",
    "\n",
    "# --- Fine search around the coarse best ---\n",
    "fine_lo = max(0.0, best_thr_coarse - 0.05)\n",
    "fine_hi = min(1.0, best_thr_coarse + 0.05)\n",
    "ths_fine = np.arange(fine_lo, fine_hi + 1e-12, 0.001)\n",
    "\n",
    "accs_fine = [accuracy_score(y, (oof_meta_scores >= t).astype(int)) for t in ths_fine]\n",
    "best_idx_f = int(np.argmax(accs_fine))\n",
    "STACK_FINAL_THRESHOLD = float(ths_fine[best_idx_f])\n",
    "STACK_FINAL_OOF_ACC   = float(accs_fine[best_idx_f])\n",
    "\n",
    "print(f\"[Stacking][Best] Final OOF threshold = {STACK_FINAL_THRESHOLD:.3f} | OOF Accuracy = {STACK_FINAL_OOF_ACC:.4f}\")\n",
    "\n",
    "# --- Apply tuned threshold to TEST ---\n",
    "stack_pred_labels_tuned = (meta_test_scores >= STACK_FINAL_THRESHOLD).astype(int)\n",
    "print(\"‚úÖ Created 'stack_pred_labels_tuned' for submission.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb31309",
   "metadata": {
    "_cell_guid": "fe1e5039-65ab-41a2-b17e-d0b74be840f8",
    "_uuid": "fc400151-e3d6-481e-87dc-6e23ec10bb0b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01486,
     "end_time": "2025-11-12T23:55:56.489081",
     "exception": false,
     "start_time": "2025-11-12T23:55:56.474221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Creating the Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5eb31bb",
   "metadata": {
    "_cell_guid": "2a35849f-8198-4a64-9eb1-25bffb277291",
    "_uuid": "536ccc01-19ab-4d61-b21b-d403562a08dc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-11-12T23:55:56.521246Z",
     "iopub.status.busy": "2025-11-12T23:55:56.520653Z",
     "iopub.status.idle": "2025-11-12T23:55:56.550924Z",
     "shell.execute_reply": "2025-11-12T23:55:56.550192Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.047917,
     "end_time": "2025-11-12T23:55:56.552311",
     "exception": false,
     "start_time": "2025-11-12T23:55:56.504394",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to /kaggle/working/submission.csv\n",
      "Note: StackingClassifier (LR+XGB+RF ‚Üí LR meta), tuned thr=0.473\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battle_id</th>\n",
       "      <th>player_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   battle_id  player_won\n",
       "0          0           0\n",
       "1          1           1\n",
       "2          2           1\n",
       "3          3           1\n",
       "4          4           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === 4. Submission (StackingClassifier tuned threshold ONLY) ===\n",
    "import pandas as pd\n",
    "\n",
    "# Safety checks\n",
    "if \"stack_pred_labels_tuned\" not in globals():\n",
    "    raise RuntimeError(\"Missing 'stack_pred_labels_tuned'. Run Cell 3.3 first.\")\n",
    "if \"test_df\" not in globals() or \"battle_id\" not in test_df.columns:\n",
    "    raise RuntimeError(\"Missing 'test_df' with 'battle_id' column.\")\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"battle_id\": test_df[\"battle_id\"].values,\n",
    "    \"player_won\": stack_pred_labels_tuned.astype(int)\n",
    "})\n",
    "\n",
    "save_path = \"/kaggle/working/submission.csv\"\n",
    "submission.to_csv(save_path, index=False)\n",
    "note = f\"StackingClassifier (LR+XGB+RF ‚Üí LR meta), tuned thr={float(STACK_FINAL_THRESHOLD):.3f}\"\n",
    "\n",
    "print(f\"Submission saved to {save_path}\")\n",
    "print(f\"Note: {note}\")\n",
    "display(submission.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a767379a",
   "metadata": {
    "_cell_guid": "cd0077c1-c58f-4486-86d3-b2b38ecc0f55",
    "_uuid": "06a20782-709c-467d-b15a-c98f0653a2af",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015417,
     "end_time": "2025-11-12T23:55:56.583285",
     "exception": false,
     "start_time": "2025-11-12T23:55:56.567868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 5. Submitting Your Results\n",
    "\n",
    "Once you have generated your `submission.csv` file, there are two primary ways to submit it to the competition.\n",
    "\n",
    "---\n",
    "\n",
    "#### Method A: Submitting Directly from the Notebook\n",
    "\n",
    "This is the standard method for code competitions. It ensures that your submission is linked to the code that produced it, which is crucial for reproducibility.\n",
    "\n",
    "1.  **Save Your Work:** Click the **\"Save Version\"** button in the top-right corner of the notebook editor.\n",
    "2.  **Run the Notebook:** In the pop-up window, select **\"Save & Run All (Commit)\"** and then click the **\"Save\"** button. This will run your entire notebook from top to bottom and save the output, including your `submission.csv` file.\n",
    "3.  **Go to the Viewer:** Once the save process is complete, navigate to the notebook viewer page. \n",
    "4.  **Submit to Competition:** In the viewer, find the **\"Submit to Competition\"** section. This is usually located in the header of the output section or in the vertical \"...\" menu on the right side of the page. Clicking the **Submit** button this will submit your generated `submission.csv` file.\n",
    "\n",
    "After submitting, you will see your score in the **\"Submit to Competition\"** section or in the [Public Leaderboard](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?).\n",
    "\n",
    "---\n",
    "\n",
    "#### Method B: Manual Upload\n",
    "\n",
    "You can also generate your predictions and submission file using any environment you prefer (this notebook, Google Colab, or your local machine).\n",
    "\n",
    "1.  **Generate the `submission.csv` file** using your model.\n",
    "2.  **Download the file** to your computer.\n",
    "3.  **Navigate to the [Leaderboard Page](https://www.kaggle.com/competitions/fds-pokemon-battles-prediction-2025/leaderboard?)** and click on the **\"Submit Predictions\"** button.\n",
    "4.  **Upload Your File:** Drag and drop or select your `submission.csv` file to upload it.\n",
    "\n",
    "This method is quick, but keep in mind that for the final evaluation, you might be required to provide the code that generated your submission.\n",
    "\n",
    "Good luck!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13033998,
     "sourceId": 107555,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1637.642399,
   "end_time": "2025-11-12T23:55:59.422234",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-12T23:28:41.779835",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f4f475c48a346b0ae636ab416ddcdc8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_596670224beb43d7a1c1eeb4d288308a",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_91604b200beb48fdafdaa4b139d5937e",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá10000/10000‚Äá[00:29&lt;00:00,‚Äá311.30it/s]"
      }
     },
     "2dde147a17e24f0880a4fd463f167c9f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bfc39a41764b4cf8bd6a53200e20f859",
       "max": 5000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_aa590f2c300743e98fc306e653943325",
       "tabbable": null,
       "tooltip": null,
       "value": 5000
      }
     },
     "35515d49acfd4e63aa6fd88ae4425097": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3dc4867107464f858f054e912cc6c326": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cc2b405b3ceb469f891437a4d0ea274a",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_c43df040b5d44d1fbbfe7ea46b3d2f76",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá5000/5000‚Äá[00:14&lt;00:00,‚Äá340.00it/s]"
      }
     },
     "48642f33b7b54ff0a4c01435b9b8a68e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4e2a6a4120874aa3a83ca2cdd70ad542",
        "IPY_MODEL_2dde147a17e24f0880a4fd463f167c9f",
        "IPY_MODEL_3dc4867107464f858f054e912cc6c326"
       ],
       "layout": "IPY_MODEL_72412e82cc9548fc9511de681873e024",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4e2a6a4120874aa3a83ca2cdd70ad542": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ef1cdad0d0f44f308b384fb3f11a68ef",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_7c838d73c9c046fc97ced320fe2f31e7",
       "tabbable": null,
       "tooltip": null,
       "value": "Extracting‚Äáfeatures:‚Äá100%"
      }
     },
     "596670224beb43d7a1c1eeb4d288308a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72412e82cc9548fc9511de681873e024": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "72a6b19d435f40388cbcefef307fae4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c5e45a22e4c473798de52e598d76b17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_90c8bd5c1980473e82f2e8dad0e67cfd",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_da0ab7e48804424e9ebf2ffda4d0fe1a",
       "tabbable": null,
       "tooltip": null,
       "value": "Extracting‚Äáfeatures:‚Äá100%"
      }
     },
     "7c838d73c9c046fc97ced320fe2f31e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "90c8bd5c1980473e82f2e8dad0e67cfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "91604b200beb48fdafdaa4b139d5937e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "94ff3637279a4aeba64d98bc4aeda8cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a7ebe75b34b24dafa2e3a5550fb51824": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7c5e45a22e4c473798de52e598d76b17",
        "IPY_MODEL_d01a5edd1a5b4e0abbc009c86da6c0c1",
        "IPY_MODEL_0f4f475c48a346b0ae636ab416ddcdc8"
       ],
       "layout": "IPY_MODEL_72a6b19d435f40388cbcefef307fae4d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "aa590f2c300743e98fc306e653943325": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bfc39a41764b4cf8bd6a53200e20f859": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c43df040b5d44d1fbbfe7ea46b3d2f76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cc2b405b3ceb469f891437a4d0ea274a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d01a5edd1a5b4e0abbc009c86da6c0c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_35515d49acfd4e63aa6fd88ae4425097",
       "max": 10000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_94ff3637279a4aeba64d98bc4aeda8cf",
       "tabbable": null,
       "tooltip": null,
       "value": 10000
      }
     },
     "da0ab7e48804424e9ebf2ffda4d0fe1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ef1cdad0d0f44f308b384fb3f11a68ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
